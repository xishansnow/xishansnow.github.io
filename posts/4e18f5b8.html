<!DOCTYPE html><html class="hide-aside" lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>共形预测初学者教程 | 西山晴雪的知识笔记</title><meta name="keywords" content="神经网络,BayesNN,共形预测"><meta name="author" content="西山晴雪"><meta name="copyright" content="西山晴雪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="一篇关于共形预测的初学者教程">
<meta property="og:type" content="article">
<meta property="og:title" content="共形预测初学者教程">
<meta property="og:url" content="http://xishansnow.github.io/posts/4e18f5b8.html">
<meta property="og:site_name" content="西山晴雪的知识笔记">
<meta property="og:description" content="一篇关于共形预测的初学者教程">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xishansnow.github.io/img/007.png">
<meta property="article:published_time" content="2022-10-05T02:00:00.000Z">
<meta property="article:modified_time" content="2025-02-17T11:55:02.018Z">
<meta property="article:author" content="西山晴雪">
<meta property="article:tag" content="神经网络">
<meta property="article:tag" content="BayesNN">
<meta property="article:tag" content="共形预测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://xishansnow.github.io/img/007.png"><link rel="shortcut icon" href="/img/favi.jpg"><link rel="canonical" href="http://xishansnow.github.io/posts/4e18f5b8"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"12DC1Q07CH","apiKey":"7e4ac2a644127298a8a2e8170335afdb","indexName":"xishansnowblog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '共形预测初学者教程',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-17 19:55:02'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favi.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">389</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">411</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">117</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 贝叶斯方法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/4e1bbb89.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E4%BC%BC%E7%84%B6%E6%96%B9%E6%B3%95/"><i class="fa-fw fa-solid fa-chart-area"></i><span> 似然方法</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%BF%91%E4%BC%BC%E8%B4%9D%E5%8F%B6%E6%96%AF/"><i class="fa-fw fa-solid fa-cube"></i><span> 近似贝叶斯</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/MCMC/"><i class="fa-fw fa-solid fa-wand-magic-sparkles"></i><span> MCMC</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 变分推断</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 贝叶斯优化</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 概率图模型</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E7%BC%96%E7%A8%8B/"><i class="fa-fw fa-brands fa-codepen"></i><span> 概率编程</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-atom"></i><span> 高斯过程</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/b5b2c876.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"><i class="fa-fw fas fa-atom"></i><span> 高斯过程原理</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E6%96%AD/"><i class="fa-fw fas fa-cogs"></i><span> 高斯过程推断</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/"><i class="fa-fw fa-solid fa-magnet"></i><span> 可扩展高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 神经网络高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%AF%84%E6%B5%8B%E5%AF%B9%E6%AF%94/"><i class="fa-fw fa-solid fa-school"></i><span> 评测与数据集</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/"><i class="fa-fw fa-solid fa-cube"></i><span> 模型自动构建</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 随机模拟</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-ghost"></i><span> 不确定性DL</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/2b310e69.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A7%88"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 综述性文章</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%8D%95%E4%B8%80%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-atom"></i><span> 确定性神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-school"></i><span> 贝叶斯神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%B7%B1%E5%BA%A6%E9%9B%86%E6%88%90/"><i class="fa-fw fas fa-cogs"></i><span> 深度集成方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 数据增强方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%AF%B9%E6%AF%94%E8%AF%84%E6%B5%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 对比评测</span></a></li><li><a class="site-page child" href="/categories/%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E5%87%86/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 不确定性校准</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-map"></i><span> 时空随机场</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/82ad5ffe.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/"><i class="fa-fw fa-solid fa-map"></i><span> 时空随机场</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%8F%92%E5%80%BC/"><i class="fa-fw fa-solid fa-ghost"></i><span> 时空插值</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 回归分析</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 时空预报</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 数据同化</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 计算机实验模拟</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 时空监测网络设计</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E5%9C%BA%E7%BB%98%E5%88%B6/"><i class="fa-fw fa fa-anchor"></i><span> 场绘制专题</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-book-open"></i><span> 书籍</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="https://xishansnow.github.io/BayesianAnalysiswithPython2nd/index.html"><i class="fa-fw fa-solid  fa-landmark-dome"></i><span> 《Bayesian Analysis with Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/BayesianModelingandComputationInPython/index.html"><i class="fa-fw fa-solid  fa-graduation-cap"></i><span> 《Bayesian Modeling and Computation in Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/ElementsOfStatisticalLearning/index.html"><i class="fa-fw fa-solid  fa-book-atlas"></i><span> 《统计学习精要（ESL）》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/spatialSTAT_CN/index.html"><i class="fa-fw fa-solid  fa-layer-group"></i><span> 《空间统计学》</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://otexts.com/fppcn/index.html"><i class="fa-fw fa-solid  fa-cloud-sun-rain"></i><span> 《预测：方法与实践》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/MLAPP/index.html"><i class="fa-fw fa-solid  fa-robot"></i><span> 《机器学习的概率视角（MLAPP）》</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 索引</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 时间索引</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签索引</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类索引</span></a></li><li><a class="site-page child" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/"><i class="fa-fw fas fa-atlas"></i><span> 临时索引</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"><i class="fa-fw fas fa-utensils"></i><span> 常用软件</span></a></li><li><a class="site-page child" href="/link/paper/"><i class="fa-fw fas fa-book-open"></i><span> 学术工具</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 摄影作品</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/007.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">西山晴雪的知识笔记</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 贝叶斯方法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/4e1bbb89.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E4%BC%BC%E7%84%B6%E6%96%B9%E6%B3%95/"><i class="fa-fw fa-solid fa-chart-area"></i><span> 似然方法</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%BF%91%E4%BC%BC%E8%B4%9D%E5%8F%B6%E6%96%AF/"><i class="fa-fw fa-solid fa-cube"></i><span> 近似贝叶斯</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/MCMC/"><i class="fa-fw fa-solid fa-wand-magic-sparkles"></i><span> MCMC</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 变分推断</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 贝叶斯优化</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 概率图模型</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E7%BC%96%E7%A8%8B/"><i class="fa-fw fa-brands fa-codepen"></i><span> 概率编程</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-atom"></i><span> 高斯过程</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/b5b2c876.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"><i class="fa-fw fas fa-atom"></i><span> 高斯过程原理</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E6%96%AD/"><i class="fa-fw fas fa-cogs"></i><span> 高斯过程推断</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/"><i class="fa-fw fa-solid fa-magnet"></i><span> 可扩展高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 神经网络高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%AF%84%E6%B5%8B%E5%AF%B9%E6%AF%94/"><i class="fa-fw fa-solid fa-school"></i><span> 评测与数据集</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/"><i class="fa-fw fa-solid fa-cube"></i><span> 模型自动构建</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 随机模拟</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-ghost"></i><span> 不确定性DL</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/2b310e69.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A7%88"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 综述性文章</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%8D%95%E4%B8%80%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-atom"></i><span> 确定性神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-school"></i><span> 贝叶斯神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%B7%B1%E5%BA%A6%E9%9B%86%E6%88%90/"><i class="fa-fw fas fa-cogs"></i><span> 深度集成方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 数据增强方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%AF%B9%E6%AF%94%E8%AF%84%E6%B5%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 对比评测</span></a></li><li><a class="site-page child" href="/categories/%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E5%87%86/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 不确定性校准</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-map"></i><span> 时空随机场</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/82ad5ffe.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/"><i class="fa-fw fa-solid fa-map"></i><span> 时空随机场</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%8F%92%E5%80%BC/"><i class="fa-fw fa-solid fa-ghost"></i><span> 时空插值</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 回归分析</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 时空预报</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 数据同化</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 计算机实验模拟</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 时空监测网络设计</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E5%9C%BA%E7%BB%98%E5%88%B6/"><i class="fa-fw fa fa-anchor"></i><span> 场绘制专题</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-book-open"></i><span> 书籍</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="https://xishansnow.github.io/BayesianAnalysiswithPython2nd/index.html"><i class="fa-fw fa-solid  fa-landmark-dome"></i><span> 《Bayesian Analysis with Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/BayesianModelingandComputationInPython/index.html"><i class="fa-fw fa-solid  fa-graduation-cap"></i><span> 《Bayesian Modeling and Computation in Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/ElementsOfStatisticalLearning/index.html"><i class="fa-fw fa-solid  fa-book-atlas"></i><span> 《统计学习精要（ESL）》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/spatialSTAT_CN/index.html"><i class="fa-fw fa-solid  fa-layer-group"></i><span> 《空间统计学》</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://otexts.com/fppcn/index.html"><i class="fa-fw fa-solid  fa-cloud-sun-rain"></i><span> 《预测：方法与实践》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/MLAPP/index.html"><i class="fa-fw fa-solid  fa-robot"></i><span> 《机器学习的概率视角（MLAPP）》</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 索引</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 时间索引</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签索引</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类索引</span></a></li><li><a class="site-page child" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/"><i class="fa-fw fas fa-atlas"></i><span> 临时索引</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"><i class="fa-fw fas fa-utensils"></i><span> 常用软件</span></a></li><li><a class="site-page child" href="/link/paper/"><i class="fa-fw fas fa-book-open"></i><span> 学术工具</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 摄影作品</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">共形预测初学者教程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-10-05T02:00:00.000Z" title="发表于 2022-10-05 10:00:00">2022-10-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-17T11:55:02.018Z" title="更新于 2025-02-17 19:55:02">2025-02-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/BayesNN/">BayesNN</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/BayesNN/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E5%87%86/">不确定性校准</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">11.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>46分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><script src='https://unpkg.com/tippy.js@2.0.2/dist/tippy.all.min.js'></script>
<script src='/js/attachTooltips.js'></script>
<link rel='stylesheet' href='/css/tippy.css'>
<script src="https://unpkg.com/tippy.js@2.0.2/dist/tippy.all.min.js"></script>
<script src="/js/attachTooltips.js"></script>
<link rel="stylesheet" href="/css/tippy.css">
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>【摘 要】 黑盒机器学习模型现在常被应用于高风险环境中，例如医疗诊断，这需要量化不确定性以避免模型失败。共形预测是一种用户友好的范式，用于为上述高风险的预测创建统计上严格的不确定性集合（或区间）。至关重要的是，这些集合在数据分布不明确的意义上也是有效的：即使没有分布假设或模型假设，这些集合也具有明确的、非渐近的保证。可以将共形预测与任何已经训练好的模型（例如神经网络）一起使用，以生成能够按照用户指定概率（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>90</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">90\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">90%</span></span></span></span> ）包含基本事实的集合。共形预测易于理解、易于使用并且具备通用性，适用于计算机视觉、自然语言处理、深度强化学习等领域出现的各类问题。本文旨在通过一个自包含的文档，使读者能够理解共形预测和相关无分布不确定性量化技术工作原理。我们将引导读者了解共形预测的实用理论和示例，并描述其对复杂机器学习任务的扩展，包括结构化输出、分布偏移、时间序列、异常值、Dropout 模型等。</p>
<p>【原 文】 Angelopoulos, A. N. and Bates, S.(2021). “A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification”, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2107.07511">https://arxiv.org/abs/2107.07511</a>.</p>
<p>【阅后感】 共形预测用经验数据来确定新预测中信念的精确度。给定一个错误概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span> 和一套将真实标签 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 预测为估计值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 的方法，共形预测可以产生一个以概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>ε</mi></mrow><annotation encoding="application/x-tex">1 \varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mord mathnormal">ε</span></span></span></span> 包含 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 的标签集合（ 或区间 ），也就是说，共形预测能够构造一种含置信度的预测器，可以按照用户指定的错误率生成预测集合。共形预测的好处之一是可以逐类地应用，独立保证每个类的错误率。共形预测可以应用于任何能够产生 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>  的方法，如：最近邻方法、支持向量机、岭回归、神经网络等。共形预测非常适用于在线场景，在该场景中，标签将被连续地预测，每个标签都会在下一个标签之前被预测。而其中共形预测最新颖和最有价值的特性是：如果连续性样本是从相同的分布中独立采样的，那么连续性预测在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>ε</mi></mrow><annotation encoding="application/x-tex">1-\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span> 的时间里都是正确的，即便它们都是建立在累积数据集而非独立数据集基础之上。除了通过独立采样产生连续性样本的模型外，其他在线压缩模型也可以使用共形预测，其中最典型的是被广泛使用的高斯线性模型。</p>
<h2 id="1-什么是共形预测-？">1. 什么是共形预测 ？</h2>
<p>共形预测是为任意模型生成预测集合的直接方法。我们通过一个简短、实用的图像分类示例来介绍共形预测的一般性概念和解释。共形预测的顶层轮廓大致包含两步：</p>
<ul>
<li>
<p>预测：我们从一个已完成拟合的预测器（例如神经网络分类器）开始，并称该预测器为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>f</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{f}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1523em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 。<br>
为了从模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>f</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{f}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1523em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 和校准数据中构造预测集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span>，需要执行一个校准步骤（只需要几行代码）；参见 <code>图 2</code>。该校准步骤如下：</p>
</li>
<li>
<p>其次，我们不能保证 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出是好的；因为它们可能被任意过拟合或以其他方式而不可信。因此，我们没有直接使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出，而是使用校准集来调整它们的不足之处。</p>
</li>
</ul>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mn>1</mn><mo>−</mo><mi>α</mi><mo>≤</mo><mi mathvariant="double-struck">P</mi><mrow><mo fence="true">(</mo><msub><mi>Y</mi><mtext>test&nbsp;</mtext></msub><mo>∈</mo><mi mathvariant="script">C</mi><mrow><mo fence="true">(</mo><msub><mi>X</mi><mtext>test&nbsp;</mtext></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo>≤</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo>+</mo><mfrac><mn>1</mn><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></mfrac></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">1-\alpha \leq \mathbb{P}\left(Y_{\text {test }} \in \mathcal{C}\left(X_{\text {test }}\right)\right) \leq 1-\alpha+\frac{1}{n+1} \tag{1}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathbb">P</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test&nbsp;</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test&nbsp;</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.0908em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height:2.0908em;vertical-align:-0.7693em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>校准集包含模型在训练期间从未见过的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≈</mo><mn>500</mn></mrow><annotation encoding="application/x-tex">n \approx 500</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4831em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">500</span></span></span></span> 个新数据点，这使我们能够对其性能进行更诚实的评估。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20221005225051-ac34.webp" alt="预测集合示例"></p>
<figcaption>图 1：Imagenet 上的预测集合示例。我们展示了三个越来越难的狐鼠类样本，以及由共形预测得到的预测集合，即 $\mathcal{C}(X_{\text{test}})$。</figcaption>
<br>
<h3 id="3-2-校准集大小的影响">3.2 校准集大小的影响</h3>
<ul>
<li><strong>计算共形分值</strong>：
<ul>
<li>本例中我们将共形分值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo>−</mo><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow><mo fence="true">(</mo><msub><mi>X</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><msub><mi>Y</mi><mi>i</mi></msub></msub></mrow><annotation encoding="application/x-tex">s_i=1-\hat{f}\left(X_i\right)_{Y_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.3577em;vertical-align:-0.3998em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1786em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3998em;"><span></span></span></span></span></span></span></span></span></span> 定义为：『 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 减去真实类的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出』。也就是说，当真实类的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出越低时（ 即模型严重错误时 ）分值较高。</li>
</ul>
</li>
<li><strong>计算分位数</strong>：
<ul>
<li>依据分数集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">s_1, \ldots, s_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ，计算其 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⌈</mo><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo stretchy="false">⌉</mo><mi mathvariant="normal">/</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">\lceil(n+1)(1-\alpha)\rceil / n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⌈(</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)⌉</span><span class="mord">/</span><span class="mord mathnormal">n</span></span></span></span> 分位数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>q</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> ，其中 $ \lceil\cdot\rceil$ 是上限函数。 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>q</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 本质上是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">1-\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 分位数，此处做了一个小的修正。</li>
</ul>
</li>
<li><strong>构建预测集合</strong>：
<ul>
<li>对于每一个新的测试数据点（ 即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mtext>test</mtext></msub></mrow><annotation encoding="application/x-tex">X_{\text{test}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 已知，但 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mtext>test</mtext></msub></mrow><annotation encoding="application/x-tex">Y_{\text{test}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 未知 ），创建预测集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi><mrow><mo fence="true">(</mo><msub><mi>X</mi><mtext>test&nbsp;</mtext></msub><mo fence="true">)</mo></mrow><mo>=</mo><mrow><mo fence="true">{</mo><mi>y</mi><mo>:</mo><mover accent="true"><mi>f</mi><mo>^</mo></mover><msub><mrow><mo fence="true">(</mo><msub><mi>X</mi><mtext>test&nbsp;</mtext></msub><mo fence="true">)</mo></mrow><mi>y</mi></msub><mo>≥</mo><mn>1</mn><mo>−</mo><mover accent="true"><mi>q</mi><mo>^</mo></mover><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{C}\left( X_{\text {test }}\right)=\left\{ y:\hat{f}\left(X_{\text {test }}\right)_y \geq 1-\hat{q}\right\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test&nbsp;</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">{</span></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.0833em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test&nbsp;</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.0017em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">}</span></span></span></span></span></span> ，其中包括了具有足够高 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出值的所有可能类别（ 参见 <code>图 2</code> ）。</li>
</ul>
</li>
</ul>
<p>值得注意的是，无论使用什么模型、也无论数据的分布是否已知，该算法都能提供满足 <code>公式 (1)</code> 的预测集合。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20221005230818-3863.webp" alt="共形预测过程及其 Python 代码"></p>
<div class="note info no-icon flat"><p>🔔  备注：</p>
<p><strong>对预测集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span> 的解释</strong>。</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span> 可以被视为一个具有集合类型输出的函数，它接收一个图像，输出一个类别集合，如 <code>图 1</code> 所示。而模型的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出有助于生成该集合。此方法能够为每个特定输入自适应地构造不同的输出集。当模型不确定或图像本质上很难时，该预测集合会变大，而这是我们想要的性质，因为集合大小提供了模型确定性的指标。</li>
<li>此外，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi><mrow><mo fence="true">(</mo><msub><mi>X</mi><mtext>test&nbsp;</mtext></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{C}\left( X_{\text {test }}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test&nbsp;</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> 可以被解释为图像 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mtext>test&nbsp;</mtext></msub></mrow><annotation encoding="application/x-tex">X_{\text {test }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test&nbsp;</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>  可以分配到的一组似是而非的类。</li>
<li>最后，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span> 是有效的，满足 <code>公式 (1)</code> 。</li>
</ul>
<p>上述 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span> 的性质可以自然地适用于为回归等其他机器学习问题。</p>
<p>着眼于泛化问题，让我们详细回顾一下分类问题中发生的事情。</p>
<ul>
<li>首先，我们收到了一个模型，该模型具有内置但启发式的不确定性概念：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出。 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出试图测量每个类的条件概率；换句话说，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 向量的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 个条目估计 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mi>j</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(Y = j | X = x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>，即在已知输入图像 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 的条件下，是类别 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 的概率。<br>
在本文的前几节中，我们几乎只关注共形预测的数据拆分方法，但这不是唯一的方法。在完全共形预测中，我们不拆分数据，这提高了统计效率，因为本身不需要校准集。相反，所有数据都用于拟合模型。另一方面，完全共形预测需要为每个新的测试点和假定的标签重新训练模型，这可能是棘手的。尽管如此，如果数据稀缺且模型易于拟合，读者可能希望使用完全共形和相关方法。此外，对于某些简单类别的模型，可以使用计算技巧来加速完全共形预测并避免为每个假定的标签 y 拟合模型。例如，在线性回归中，Sherman-Morrison-Woodbury 公式可以使读者免于完全重新计算模型。关于全共形预测并使其高效的研究已有数十年的历史，该主题已被 [3] 和 [1] 涵盖。最近的发展见 [77, 78]。</li>
</ul>
<p>共形预测的许多统计扩展也出现了。此类扩展包括我们之前讨论过的风险控制 [4, 18] 和协变量偏移 [25] 的想法。一个重要且持续的工作领域是分布变化，我们的测试点与我们的校准数据具有不同的分布。例如，[93] 构建了一个对分数函数中已知 f 散度的变化具有鲁棒性的共形过程，并且 [31] 通过不断重新估计共形分位数。 [26] 开创的共形预测的加权版本提供了用于处理不可交换数据的工具，最显著的是缓慢变化的时间序列。除了分布变化之外，最近的统计扩展还解决了一些主题，例如为反事实和个体治疗效果创建可靠的共形预测区间 [94-96]、生存时间的协变量相关下限 [97]、保护校准隐私的预测集合数据[98]，以及处理相关数据[99-101]。</p>
<ul>
<li>首先，调整涉及共形分值的计算，当模型不确定增加时，该分值会增长；但共形分值本身并不构成有效的预测区间。在本例中，共形分值被定义为『 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 减去真实类的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出值』。但更广义含义上来说，共形分值可以是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 的任何函数。</li>
<li>然后，我们将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 近似为所有分值的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>α</mi></mrow><annotation encoding="application/x-tex">1 - \alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 分位数。在这种情况下，分位数有一个简单的解释：当设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.1</span></span></span></span> 时，至少 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>90</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">90\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">90%</span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出真实值高于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>q</mi></mrow><annotation encoding="application/x-tex">1 - q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 。</li>
</ul>
<p>利用上述事实，在测试时，我们获得了新图像 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mtext>test</mtext></msub></mrow><annotation encoding="application/x-tex">X_{\text{test}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出，并将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出高于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>q</mi></mrow><annotation encoding="application/x-tex">1 - q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 的所有类收集到预测集合  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mtext>test</mtext></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{C}(X_{\text{test}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 中。由于真实类 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Y</mi><mtext>test</mtext></msub></mrow><annotation encoding="application/x-tex">Y_{\text{test}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出能够保证处于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>q</mi></mrow><annotation encoding="application/x-tex">1 - q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 之上，也就是说概率至少为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>90</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">90\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">90%</span></span></span></span>，因此我们最终得到了 <code>公式 (1)</code> 中的保证。</p>
</div>
<h3 id="1-1-共形预测的说明">1.1 共形预测的说明</h3>
<p>正如我们在备注中所说，共形预测并不特定于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>softmax</mtext></mrow><annotation encoding="application/x-tex">\text{softmax}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">softmax</span></span></span></span></span> 输出或分类问题。事实上，共形预测可以看作是一种从任何模型中获取任何启发式不确定性概念并将其转换为严格概念的方法（见下图）。共形预测不关心潜在的预测问题是离散/连续还是分类/回归。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20221005235035-afd2.webp" alt="共形预测示意"></p>
<p>我们接下来概述一般输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 和输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span>（不一定是离散的）的共形预测。</p>
<ol>
<li>使用预训练模型识别不确定性的启发式概念。</li>
<li>定义分值函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∈</mo><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">s(x, y) \in \mathbb{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">R</span></span></span></span>（较大的分数表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 之间的一致性较差）。</li>
<li>计算共形分值集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>=</mo><mi>s</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>Y</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>s</mi><mi>n</mi></msub><mo>=</mo><mi>s</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>Y</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">s_1 = s(X_1, Y_1), \ldots, s_n = s(X_n, Y_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mo stretchy="false">⌈</mo><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo stretchy="false">⌉</mo></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{\lceil(n+1)(1−\alpha)\rceil}{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">⌈(</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="mclose mtight">)⌉</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 分位数，并将定义为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>q</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{q}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span>。</li>
<li>使用该分位数形成新样本的预测集合：</li>
</ol>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="script">C</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mtext>test</mtext></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">{</mo><mi>y</mi><mo>:</mo><mi>s</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mtext>test</mtext></msub><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>≤</mo><mover accent="true"><mi>q</mi><mo>^</mo></mover><mo stretchy="false">}</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(2)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathcal{C}(X_{\text{test}}) = \{y : s(X_{\text{test}}, y) \leq \hat{q}  \} \tag{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">test</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">}</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>和以前一样，这些集合满足 <code>公式 (1)</code> 中的有效性性质，适用于任何评分函数和数据分布。下面给出了覆盖范围保证的正式定理：</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20221005235921-9115.webp" alt="共形覆盖保证定理"></p>
<p>有关包含 <code>公式 (1)</code> 中上限的证明和陈述，请参见附录。我们注意到上面只是共形预测的一种特殊情况，称为『分裂共形预测（ Split Conformal Prediction ）』。这是共形预测最广泛使用的版本，它将是我们的主要关注点。为了完成完成图景，我们将在第 6 节后面全面描述共形预测，并在第 7 节中概述文献。</p>
<p><strong>评分函数的选择</strong></p>
<p>乍一看，这似乎好得令人难以置信，持怀疑态度的读者可能会问以下问题：</p>
<p>『 如何能够在底层模型不确定性的启发式概念非常糟糕的情况下，构建一个在统计上有效的预测集合？』</p>
<p>让我们给出一些直觉来补充 <code>附录 D</code> 证明中的数学理解。粗略地说，如果分数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 正确地将输入从模型误差的最低到最高幅度排序，那么对于简单输入，结果集合会更小，而对于困难的输入则更大。 如果分数不好，从某种意义上说，它们不接近这个排名，那么这些集合将毫无用处。例如，如果分数是随机噪声，那么集合将包含标签空间的随机样本，其中该随机样本足够大以提供有效的边缘覆盖。</p>
<p>这说明了关于共形预测的一个重要的基本事实：<strong>尽管保证始终成立，但预测集合的有用性主要由评分函数决定</strong>。</p>
<p>这应该不足为奇：评分函数包含了我们所知道的关于问题和数据的所有信息，包括底层模型本身。例如，在分类问题和回归问题上，应用共形预测之间的主要区别在于分数的选择。单个基础模型也有许多可能的评分函数，它们具有不同的性质。因此，构建正确的评分函数是一项重要的工程选择。接下来，我们将展示几个良好的评分函数示例。</p>
<h2 id="2-共形过程的示例">2 共形过程的示例</h2>
<p>在本节中，我们给出了在许多环境中应用的共形预测示例，目的是为读者提供一组实际部署和使用的技术。请注意，我们将在本节中仅关注一维 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>，较小的共形分数将对应于更多的模型信念（这样的分数称为不合格分数）。更丰富的设置，例如高维 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>、误差的复杂（或多个）概念，或者不同误差的成本不同，通常需要风险控制语言，如 <code>第 A 节</code> 所述。</p>
<h3 id="2-1-采用自适应预测集合的分类">2.1 采用自适应预测集合的分类</h3>
<h3 id="2-2-共形化的分位数回归">2.2 共形化的分位数回归</h3>
<h3 id="2-3-共形化的标量不确定性估计">2.3 共形化的标量不确定性估计</h3>
<h3 id="2-4-共形贝叶斯">2.4 共形贝叶斯</h3>
<div class="note info no-icon flat"><p>🔔  讨论</p>
<p>正如我们的示例所示，共形预测是一种简单实用的技术，具有许多用例。它也很容易实现并且计算量很小。此外，上述四个示例为用户设计具有各种最优性概念的评分函数提供了路线图，包括平均大小、适应性和贝叶斯风险。还有更多的事情要做——共形预测可以比现在看起来更广泛地应用。我们将在<code>第 4 节</code>概述共形预测对其他预测任务的扩展，例如异常值检测、图像分割、串行时间序列预测等。在讨论这些扩展之前，我们将在标准设置下深入探讨共形预测的诊断，包括条件覆盖的重要话题。</p>
</div>
<h2 id="3-评估共形预测">3 评估共形预测</h2>
<p>我们在最后两节中学习了如何形成满足严格统计保证的有效预测集合。现在我们将讨论如何评估它们。我们的评估将分为两类之一。</p>
<ol>
<li>评估适应性。非常重要的是要记住，具有最小平均集合大小的共形预测过程不一定是最好的。一个好的共形预测程序将以忠实反映模型不确定性的方式给出简单输入的小集和硬输入的大集。共形预测的覆盖保证并不暗示这种适应性，但在共形预测的实际部署中是不可协商的。我们将形式化适应性，探索其后果，并提出实用的算法来评估它。</li>
<li>正确性检查。正确性检查可帮助您测试是否正确实施了共形预测。我们将凭经验检查覆盖率是否满足定理 1。严格评估此属性是否成立需要仔细考虑真实数据集存在的有限样本可变性。我们为良性波动的大小制定了明确的公式——如果观察到覆盖范围中 1-α 的偏差大于这些公式所规定的，那么实施就存在问题。</li>
</ol>
<p>我们建议的许多评估都是计算密集型的，并且需要在不同的数据拆分上运行整个共形过程至少 100 次。当分数需要很长时间来计算时，这些评估的原生实现可能会很慢。通过一些简单的计算技巧和战略缓存，我们可以将这个过程加快几个数量级。因此，为了帮助读者，我们将数学描述与代码穿插在一起，以有效地实现这些计算。</p>
<h3 id="3-1-评估适应性">3.1 评估适应性</h3>
<p>此外，预测集合并不是无分布不确定性量化的唯一重要形式。一种替代形式是共形预测分布，它在回归问题 [76] 中输出响应空间 Y 上的概率分布。最近的工作还解决了通过直方图分箱 [102, 103] 校准不确定性的标量概念以具有概率意义的问题——这就像 Platt 缩放或等渗回归的严格版本。来自共形预测的工具还可用于通过检查评分函数在新数据点上的行为来识别数据分布发生变化的时间。例如，[24] 使用共形预测执行异常值检测，[59, 104] 检测时间序列数据中的变化点，[105] 测试两个数据集之间的协变量偏移，以及 [106] 跟踪预测变量在数据流，以识别其分布中的有害变化（增加风险的变化）何时发生。</p>
<h3 id="3-3-检查正确的覆盖率">3.3 检查正确的覆盖率</h3>
<h2 id="4-共形预测的扩展">4 共形预测的扩展</h2>
<h3 id="4-1-组平衡的共形预测">4.1 组平衡的共形预测</h3>
<h3 id="4-2-类条件的共形预测">4.2 类条件的共形预测</h3>
<h3 id="4-3-共形风险控制">4.3 共形风险控制</h3>
<h3 id="4-4-异常值检测">4.4 异常值检测</h3>
<h3 id="4-5-协变量偏移下的共形预测">4.5 协变量偏移下的共形预测</h3>
<h3 id="4-6-分布漂移下的共形预测">4.6 分布漂移下的共形预测</h3>
<h2 id="5-工作实例">5 工作实例</h2>
<h3 id="5-1-多标签分类">5.1 多标签分类</h3>
<h3 id="5-2-肿瘤分割">5.2 肿瘤分割</h3>
<h3 id="5-3-具有时间序列分布偏移的天气预报">5.3 具有时间序列分布偏移的天气预报</h3>
<h3 id="5-4-通过异常值检测识别恶性在线评论">5.4 通过异常值检测识别恶性在线评论</h3>
<h3 id="5-5-选择性分类">5.5 选择性分类</h3>
<h2 id="6-完全共形预测">6 完全共形预测</h2>
<h3 id="6-1-完全共形预测">6.1 完全共形预测</h3>
<h3 id="6-2-交叉共形预测、CV-和-Jackknife">6.2 交叉共形预测、CV+ 和 Jackknife+</h3>
<h2 id="7-共形预测的历史">7 共形预测的历史</h2>
<p>我们希望读者喜欢阅读我们温和的介绍中的技术内容。作为一个 dénouement，我们现在向共形预测的历史致敬。具体来说，我们将追溯与无分布的共形预测相关的技术的历史，即（1）与模型无关，（2）与数据分布无关，以及（3）在有限样本中有效。统计学中还有其他一些工作同样声称“无分布”一词，特别是当它被渐近解释时，例如置换检验 [41]、分位数回归 [9]、秩检验 [42-44]，甚至 bootstrap [45, 46]——以下不是这些主题的历史。相反，我们专注于共形预测的祖先和后代。</p>
<h3 id="7-1-缘起">7.1 缘起</h3>
<p>共形预测的故事开始于乌克兰第七大城市以北 63 公里处，位于利沃夫州的采矿小镇切尔沃诺赫拉德，弗拉基米尔·沃夫克 (Vladimir Vovk) 在那里度过了他的童年。弗拉基米尔的父母都是乌克兰血统的医疗专业人员，尽管多年来利沃夫地区多次易手。 Vovk 回忆说，在他早期的教育中，考试很少，成绩主要基于口头回答。他在学校表现出色，最终在乌克兰数学奥林匹克中获得第一名；他还获得了金牌，这意味着他是优秀的中学毕业生之一。可能是因为他早熟，他的数学老师会在课堂上占据他的位置，给他一本以前由 Kvant 的 Isaak Kikoin 和 Andrey Kolmogorov 编辑的杂志，他在那里学习了物理、数学和工程学——见图 18。弗拉基米尔最初参加了莫斯科第二医学研究所（现称为俄罗斯国立研究型医科大学）研究生物控制论，但最终对该计划感到失望，该计划过于强调医学并要求学习解剖学和生理学等课程（“太许多带有奇怪拉丁名字的骨头”）。因此，他再次参加了入学考试，并在莫斯科国立大学的 Mekh-Mat（机械和数学学院）重新开始了学校的学习。在那里的第三年，他成为了安德烈·科尔莫哥洛夫的学生。这是共形预测的种子第一次播下的时候。今天，Vladimir Vovk 与合作者 Alexander Gammerman、Vladimir Vapnik 等人一起被广泛认为是共形预测的共同发明者，我们将很快讨论他们的贡献。首先，我们将传递共形预测的一些历史根源，以及一些与 Vovk 相关的口述历史，如果不写，可能会被遗忘。</p>
<p>Kolmogorov 和 Vovk 在他在密歇根州立大学读本科的余下三年中大约每周见面一次。那时，Kolmogorov 对 Vovk 产生了兴趣，并鼓励他研究困难的数学问题。最终，Vovk 决定研究 Kolmogorov 感兴趣的一个主题：算法上的随机序列，然后被称为集体，并被 Kolmogorov 修改为伯努利序列。</p>
<p>集体的工作始于 20 世纪初，由 Gustav Fechner 的 Kollectivmasslehre [47] 开始，并由 von Mises [48]、Abraham Wald [49]、Alonzo Church [50] 等人显著发展。这些统计学家之间就 von Mises 的公理是否构成了概率的有效基础进行了长时间的辩论，而 Jean Ville 是一个值得注意的反对者 [51]。尽管冯·米塞斯的集体理论有些不复存在，但在此期间产生的数学思想继续对统计学产生广泛的影响，正如我们将看到的那样。对最初关于集体的辩论的更仔细的历史回顾存在于其他地方[50, 52-54]。我们专注于它与共形预测发展的联系。</p>
<p>Kolmogorov 对伯努利序列的兴趣一直持续到 1970 年代和 1980 年代，当时 Vovk 是他的学生。 Vovk 回忆说，在去火车站的路上，Kolmogorov 告诉他（不是用这些确切的话）：</p>
<p>“看看你周围；您不仅会看到无限的序列。有有限的序列。”</p>
<p>感觉有限情况实际上很重要，Kolmogorov 通过伯努利序列扩展了集体的想法。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20221006002411-d9fc.webp" alt="定义 1"></p>
<p>正如随机序列研究中的典型情况一样，底层对象本身并不是随机变量序列。相反，Kolmogorov 通过 Kolmogorov 复杂性量化了序列的“典型性”：他询问我们需要编写多长时间的程序才能将其与同一空间中的其他序列区分开来 [55-57]。 Vovk 关于随机序列的第一项工作修改了 Kolmogorov [58] 的定义，以更好地反映抛硬币等事件的随机性。 Vovk 在 [59] 的附录中讨论了伯努利序列的历史，包括 Martin-L ̈of 和 Levin 所做的重要工作。学习伯努利序列理论使 Vovk 更接近于理解有限样本可交换性及其在预测问题中的作用。</p>
<p>在进入现代之前，我们将最后说明早期概率学家的贡献。不合格分数的概念来自（局部）随机性缺陷的想法。考虑序列：<code>00000000000000000000000000000000000000000000000000000000000000000001</code></p>
<p>使用计算机，我们可以编写一个非常短的程序来识别序列中的“1”，因为它是非典型的——它具有很大的随机性缺陷。但是要识别序列中的任何特定“0”，我们必须指定它的位置，因为它非常典型——它有一个小的随机性缺陷。启发式的理解在这里就足够了，我们将随机性缺陷的正式定义推迟到 [60]，避免了图灵机和 Kolmogorov 复杂性的符号。当随机性缺陷很大时，一个点是非典型的，就像我们在第 2 节中讨论的分数一样。这些想法，连同现有的关于容差区间的统计文献 [61-64] 以及与 de Finetti 的可交换性定理相关的工作 [65- [70]形成了共形预测的种子：集体的粗略概念最终变成了可交换性，而随机性缺陷的想法最终变成了不整合。</p>
<h3 id="7-2-进入共形预测">7.2 进入共形预测</h3>
<p>我们现在称为共形预测的框架是由 Vladimir Vovk、Alexander Gammerman、Craig Saunders 和 Vladimir Vapnik 在 1996-1999 年孵化的，首先使用 e-values [71]，然后使用 pvalues [5, 72]。几十年来，Vovk 和合作者开发了共形预测的理论和应用。关键时刻包括：<br>
• 2002 年证明，在在线共形预测中，错误概率在时间步长上是独立的[73]；<br>
• 2002 年与 Harris Papadopoulos 和 Kostas Proedrou 一起开发的分裂共形预测器 [2]；<br>
• Glenn Shafer 在 2003 年 12 月 1 日用 Vovk [1] 编写随机世界中的算法学习时创造了术语“共形预测器”。<br>
• 2003 年 Venn Predictors [74] 的发展（Vovk 说这个想法是在 Dagstuhl 研讨会“Kolmogorov 复杂性与应用”期间在德国的一辆公共汽车上产生的）；<br>
• 2012 年共形和概率预测及其应用研讨会 (COPA) 的成立，由 Harris Papadopoulos 及其同事在希腊主办；<br>
• 2012 年创建交叉共形预测器 [39] 和 Venn-Abers 预测器 [75]；<br>
• 2017 年共形预测分布的发明[76]。</p>
<p>随机世界中的算法学习 [1]，作者 Vovk、Gammerman 和 Glenn Shafer，在第 2 章的参考书目和第 10 章的正文中包含对上述历史的进一步观点。此外，该书的网站链接到几十个关于共形预测和相关主题的技术报告。我们现在帮助读者了解其中的一些关键发展</p>
<p>最近的一些工作希望通过使用噪声对比先验 <sup class="refplus-num"><a href="#ref-94">[94]</a></sup> 或使用校准数据集 <sup class="refplus-num"><a href="#ref-95">[95]</a></sup> 来解决该问题。<sup class="refplus-num"><a href="#ref-96">[96]</a></sup> 的作者使用了 <code>concrete 分布</code> <sup class="refplus-num"><a href="#ref-97">[97]</a></sup> 来近似 <code>MC Dropout 方法</code> 中的 <code>Bernoulli</code> 参数 <sup class="refplus-num"><a href="#ref-85">[85]</a></sup>，允许对其进行优化，从而得到校准更好的后验方差。尽管做出了大量努力，在贝叶斯神经网络的变分推断框架内制定可靠且校准的不确定性估计任务仍然没有得到解决。</p>
<p>在完全共形和分裂共形之间，存在交叉共形预测。在交叉共形预测中，我们将数据分成 K 个折叠（非重叠子集）。对于第 k 个折叠，我们在折叠 1、…、k-1、k + 1、…、K 上训练我们的模型，然后计算折叠 k 的分数。交叉共形预测的优点是我们只需要训练模型 K 次。但是，保证比共形预测更脆弱；见 [39] 和 [79]。</p>
<p>共形预测最近在美国由 Jing Lei、Larry Wasserman 及其同事的开创性工作推广 [3, 80-83]。 Vovk 本人记得 Wasserman 的参与是该领域历史上具有里程碑意义的时刻。特别是，他们在回归 [83] 中进行无分布预测推理的一般框架是一项开创性的工作。在核密度估计和核回归的特殊情况下，他们还创建了完全共形预测的有效近似值 [3, 84]。 Jing Lei 还创建了 Lasso 和弹性网络程序的快速而准确的共形化 [85]。他们的另一个同样重要的贡献是将共形预测介绍给数千名研究人员，包括本文的作者，以及 Rina Barber、Emmanuel Candes、Aaditya Ramdas、Ryan Tibshirani，他们自己最近做出了基础性贡献。其中一些我们已经在第 2 节中涉及，例如自适应预测集合、共形分位数回归、协变量移位共形，以及共形预测作为索引嵌套集的想法 [86]。</p>
<p>该小组还在 Vovk、Lei 和 Wasserman 先前的工作的基础上做了基础工作，限制了无分布条件保证可以存在的条件 [87]，这些工作表明，对于任意连续分布，条件覆盖是不可能的 [3, 14, 83]。最近在 [88] 中也对这一事实进行了更细粒度的分析，表明当且仅当 Xtest 分布的有效支持大小小于样本大小的平方时，才能实现消失宽度间隔。</p>
<h3 id="7-3-当前趋势">7.3 当前趋势</h3>
<p>我们现在更广泛地讨论共形预测和无分布不确定性量化方面的最新工作，为我们在前几节中未讨论的主题提供指针。我们在这里引用的许多论文将是关于无分布方法的新研究的重要起点。</p>
<p>最近的许多论文都集中在设计共形程序以根据特定需求（如小集合大小 [6]、在特征空间区域之间大致平衡的覆盖范围 [4、7、15、27、87、89]）具有良好的实际性能，和跨类平衡的错误 [6, 23, 90, 91]。这通常涉及调整共形分数；我们在第 2 节中给出了许多此类调整的示例。良好的共形分数也可以用数据进行训练，以优化更复杂的需求 [92]。</p>
<p>贝叶斯神经网络通常比经典神经网络有更好的校准 <sup class="refplus-num"><a href="#ref-46">[46]</a></sup> <sup class="refplus-num"><a href="#ref-58">[58]</a></sup> <sup class="refplus-num"><a href="#ref-66">[66]</a></sup>，其预测出的不确定性与观测误差更加一致。与非贝叶斯神经网络相比，引入贝叶斯方法后模型既不会过度自信，也不会缺乏自信。</p>
<p>到目前为止，我们介绍了设计和训练贝叶斯神经网络的基本理论。但事实上，上述方法很难适用于目前深度学习中使用的大规模架构。最近的研究也表明，只有近似贝叶斯方法才能够得到一个较好的、正确校准的模型和不确定性估计 <sup class="refplus-num"><a href="#ref-46">[46]</a></sup>。</p>
<p>开发更好的不确定性估计器可以提高共形预测的实际有效性。关于这个主题的文献太广泛了，甚至无法开始讨论；相反，我们将分位数回归作为一个富有成效的工作的一个例子，它与第 2.2 节中的共形预测很好地融合在一起。</p>
<p>分位数回归首先在 [9] 中提出，并在 [107] 中扩展到局部多项式情况。在足够的规律性下，分位数回归均匀地收敛到真正的分位数函数[107-111]。 Koenker 和合作者 [112, 113] 编写了分位数回归的实用且可访问的参考资料。今天，积极的工作仍在继续，以分析分位数回归的统计特性及其在不同条件下的变体，例如在加法模型 [114] 中，或者在间隔的大小可能与错误覆盖事件相关时改善条件覆盖率 [16]。分位数回归手册 [113] 包含有关此类主题的更多详细信息，并为感兴趣的读者提供了分位数回归回忆录。由于分位数回归渐近地提供具有接近条件覆盖的区间，因此共形化版本也继承了这种良好的行为。</p>
<p>伴随着这样的统计进步，最近出现了共形预测的实际应用浪潮。在[4]中研究了大规模深度学习中的共形预测，重点是图像分类。共形预测的一个引人注目的用例是加快和降低复杂模型的测试时间评估的计算成本 [115, 116]。相同的研究人员在元学习设置中汇集了多个任务的信息，以形成用于小样本预测的紧密预测集合 [117]。更接近最终用户，我们知道共形预测的几个实际应用。 《华盛顿邮报》使用保角预测估计了 2020 年美国总统大选中民主党和共和党的杰出选票数量 [118]。医院的早期临床实验也强调了共形预测在该环境中的效用，尽管真正的部署仍有待实现 [119, 120]。当应用共形预测时，刑事司法系统中算法风险预测的公平性和可靠性会提高（在受控数据集上）[120-122]。最近开发了一个与 scikit-learn 兼容的开源库 MAPIE，用于构建共形预测区间。在共形预测和许多其他应用中，未来还有大量工作要做。</p>
<p>今天，无分布不确定性量化领域仍然很小，但同比增长迅速。机器学习部署的颁布已经引起了人们认为点预测是不够的，并表明我们仍然需要严格的统计推断来做出可靠的决策。世界各地的许多研究人员都关注这一事实，并使用共形预测等无分布的想法创建了新的算法和软件。这些开发项目数量众多且质量上乘，因此大多数评论都已过时。为了跟踪发布的内容，读者可能希望查看 Awesome Conformal Prediction 存储库，它提供了该区域中经常更新的资源列表。</p>
<p>我们将以给读者的个人笔记结束我们的温和介绍——你也可以成为这个故事的一部分。无分布不确定性量化的初级领域有足够的空间进行重大技术贡献。此外，这些概念实用且易于理解；它们可以很容易地在代码中被理解和实现。因此，我们鼓励读者尝试无分布不确定性量化；还有很多事情要做！</p>
<h3 id="参考文献">参考文献</h3>
<ul id="refplus"><li id="ref-1" data-num="1">[1]  V. Vovk, A. Gammerman, and G. Shafer, Algorithmic Learning in a Random World. Springer, 2005.</li><li id="ref-2" data-num="2">[2]  H. Papadopoulos, K. Proedrou, V. Vovk, and A. Gammerman, “Inductive confidence machines for regression,” in Machine Learning: European Conference on Machine Learning, 2002, pp. 345–356.</li><li id="ref-3" data-num="3">[3]  J. Lei and L. Wasserman, “Distribution-free prediction bands for non-parametric regression,” Journal of the Royal Statistical Society: Series B: Statistical Methodology, pp. 71–96, 2014.</li><li id="ref-4" data-num="4">[4]  A. N. Angelopoulos, S. Bates, J. Malik, and M. I. Jordan, “Uncertainty sets for image classifiers using conformal prediction,” in International Conference on Learning Representations, 2021.</li><li id="ref-5" data-num="5">[5]  V. Vovk, A. Gammerman, and C. Saunders, “Machine-learning applications of algorithmic randomness,” in International Conference on Machine Learning, 1999, pp. 444–453.</li><li id="ref-6" data-num="6">[6]  M. Sadinle, J. Lei, and L. Wasserman, “Least ambiguous set-valued classifiers with bounded error levels,” Journal of the American Statistical Association, vol. 114, pp. 223–234, 2019.</li><li id="ref-7" data-num="7">[7]  Y. Romano, M. Sesia, and E. J. Candes, “Classification with valid and adaptive coverage,” arXiv:2006.02544, 2020.</li><li id="ref-8" data-num="8">[8]  Y. Romano, E. Patterson, and E. Candes, “Conformalized quantile regression,” in Advances in Neural Information Processing Systems, vol. 32, 2019, pp. 3543–3553.</li><li id="ref-9" data-num="9">[9]  R. Koenker and G. Bassett Jr, “Regression quantiles,” Econometrica: Journal of the Econometric Society, vol. 46, no. 1, pp. 33–50, 1978.</li><li id="ref-10" data-num="10">[10]  A. N. Angelopoulos, A. P. Kohli, S. Bates, M. I. Jordan, J. Malik, T. Alshaabi, S. Upadhyayula, and Y. Romano, “Image-to-image regression with distribution-free uncertainty quantification and applications in imaging,” arXiv preprint arXiv:2202.05265, 2022.</li><li id="ref-11" data-num="11">[11]  P. Hoff, “Bayes-optimal prediction with frequentist coverage control,” arXiv:2105.14045, 2021.</li><li id="ref-12" data-num="12">[12]  L. Wasserman, “Frasian inference,” Statistical Science, vol. 26, no. 3, pp. 322–325, 2011.</li><li id="ref-13" data-num="13">[13]  T. Melluish, C. Saunders, I. Nouretdinov, and V. Vovk, “Comparing the bayes and typicalness frameworks,” in European Conference on Machine Learning, Springer, 2001, pp. 360–371.</li><li id="ref-14" data-num="14">[14]  V. Vovk, “Conditional validity of inductive conformal predictors,” in Proceedings of the Asian Conference on Machine Learning, vol. 25, 2012, pp. 475–490.</li><li id="ref-15" data-num="15">[15]  M. Cauchois, S. Gupta, and J. Duchi, “Knowing what you know: Valid and validated confidence sets in multiclass and multilabel prediction,” arXiv:2004.10181, 2020.</li><li id="ref-16" data-num="16">[16]  S. Feldman, S. Bates, and Y. Romano, “Improving conditional coverage via orthogonal quantile regression,” in Advances in Neural Information Processing Systems, 2021.</li><li id="ref-17" data-num="17">[17]  A. N. Angelopoulos, S. Bates, A. Fisch, L. Lei, and T. Schuster, “Conformal risk control,” arXiv preprint arXiv:2208.02814, 2022.</li><li id="ref-18" data-num="18">[18]  A. N. Angelopoulos, S. Bates, E. J. Candes, M. I. Jordan, and L. Lei, “Learn then test: Calibrating predictive algorithms to achieve risk control,” arXiv:2110.01052, 2021.</li><li id="ref-19" data-num="19">[19]  M. A. Pimentel, D. A. Clifton, L. Clifton, and L. Tarassenko, “A review of novelty detection,” Signal Processing, vol. 99, pp. 215–249, 2014.</li><li id="ref-20" data-num="20">[20]  R. A. Fisher, “Design of experiments,” British Medical Journal, vol. 1, no. 3923, p. 554, 1936.</li><li id="ref-21" data-num="21">[21]  E. J. Pitman, “Significance tests which may be applied to samples from any populations,” Supplement to the Journal of the Royal Statistical Society, vol. 4, no. 1, pp. 119–130, 1937.</li><li id="ref-22" data-num="22">[22]  V. Vovk, I. Nouretdinov, and A. Gammerman, “Testing exchangeability on-line,” in Proceedings of the 20th International Conference on Machine Learning (ICML-03), 2003, pp. 768–775.</li><li id="ref-23" data-num="23">[23]  L. Guan and R. Tibshirani, “Prediction and outlier detection in classification problems,” arXiv:1905.04396, 2019.</li><li id="ref-24" data-num="24">[24]  S. Bates, E. Candes, L. Lei, Y. Romano, and M. Sesia, “Testing for outliers with conformal p-values,” arXiv:2104.08279, 2021.</li><li id="ref-25" data-num="25">[25]  R. J. Tibshirani, R. Foygel Barber, E. Candes, and A. Ramdas, “Conformal prediction under covariate shift,” in Advances in Neural Information Processing Systems 32, 2019, pp. 2530–2540.</li><li id="ref-26" data-num="26">[26]  R. F. Barber, E. J. Candes, A. Ramdas, and R. J. Tibshirani, “Conformal prediction beyond exchangeability,” arXiv:2202.13415, 2022.</li><li id="ref-27" data-num="27">[27]  L. Guan, “Conformal prediction with localization,” arXiv:1908.08558, 2020.</li><li id="ref-28" data-num="28">[28]  T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll ́ar, and C. L. Zitnick, “Microsoft coco: Common objects in context,” in European conference on computer vision, Springer, 2014, pp. 740–755.</li><li id="ref-29" data-num="29">[29]  A. Malinin, N. Band, G. Chesnokov, Y. Gal, M. J. Gales, A. Noskov, A. Ploskonosov, L. Prokhorenkova, I. Provilkov, V. Raina, et al., “Shifts: A dataset of real distributional shift across multiple large-scale tasks,” arXiv preprint arXiv:2107.07455, 2021.</li><li id="ref-30" data-num="30">[30]  A. V. Dorogush, V. Ershov, and A. Gulin, “Catboost: Gradient boosting with categorical features support,” arXiv preprint arXiv:1810.11363, 2018.</li><li id="ref-31" data-num="31">[31]  I. Gibbs and E. Candes, “Adaptive conformal inference under distribution shift,” arXiv:2106.00170, 2021.</li><li id="ref-32" data-num="32">[32]  M. Zaffran, O. F ́eron, Y. Goude, J. Josse, and A. Dieuleveut, “Adaptive conformal predictions for time series,” in International Conference on Machine Learning, PMLR, 2022, pp. 25 834–25 866.</li><li id="ref-33" data-num="33">[33]  I. Gibbs and E. Candes, “Conformal inference for online prediction with arbitrary distribution shifts,” arXiv preprint arXiv:2208.08401, 2022.</li><li id="ref-34" data-num="34">[34]  C. Xu and Y. Xie, “Conformal prediction interval for dynamic time-series,” in International Conference on Machine Learning, PMLR, 2021, pp. 11 559–11 569.</li><li id="ref-35" data-num="35">[35]  L. Hanu and Unitary team, Detoxify, Github. https://github.com/unitaryai/detoxify, 2020.</li><li id="ref-36" data-num="36">[36]  J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” arXiv preprint arXiv:1810.04805, 2018.</li><li id="ref-37" data-num="37">[37]  P. W. Koh, S. Sagawa, H. Marklund, S. M. Xie, M. Zhang, A. Balsubramani, W. Hu, M. Yasunaga, R. L. Phillips, I. Gao, et al., “Wilds: A benchmark of in-the-wild distribution shifts,” in International Conference on Machine Learning, PMLR, 2021, pp. 5637–5664.</li><li id="ref-38" data-num="38">[38]  G. Shafer and V. Vovk, “A tutorial on conformal prediction,” Journal of Machine Learning Research, vol. 9, no. Mar, pp. 371–421, 2008.</li><li id="ref-39" data-num="39">[39]  V. Vovk, “Cross-conformal predictors,” Annals of Mathematics and Artificial Intelligence, vol. 74, no. 1-2, pp. 9–28, 2015.</li><li id="ref-40" data-num="40">[40]  R. F. Barber, “Is distribution-free inference possible for binary regression?” arXiv:2004.09477, 2020.</li><li id="ref-41" data-num="41">[41]  E. Chung and J. P. Romano, “Exact and asymptotically robust permutation tests,” The Annals of Statistics, vol. 41, no. 2, pp. 484–507, 2013.</li><li id="ref-42" data-num="42">[42]  H. B. Mann and D. R. Whitney, “On a test of whether one of two random variables is stochastically larger than the other,” The Annals of Mathematical Statistics, pp. 50–60, 1947.</li><li id="ref-43" data-num="43">[43]  E. L. Lehmann, “The power of rank tests,” The Annals of Mathematical Statistics, pp. 23–43, 1953.</li><li id="ref-44" data-num="44">[44]  Z. Sidak, P. K. Sen, and J. Hajek, Theory of rank tests. Elsevier, 1999.</li><li id="ref-45" data-num="45">[45]  B. Efron and R. J. Tibshirani, An introduction to the bootstrap. CRC press, 1994.</li><li id="ref-46" data-num="46">[46]  S. Chatterjee and P. Qiu, “Distribution-free cumulative sum control charts using bootstrap-based control limits,” The Annals of Applied Statistics, vol. 3, no. 1, pp. 349–369, 2009.</li><li id="ref-47" data-num="47">[47]  G. T. Fechner, Kollektivmasslehre. Engelmann, 1897.</li><li id="ref-48" data-num="48">[48]  R. von Mises, “Grundlagen der wahrscheinlichkeitsrechnung,” Mathematische Zeitschrift, vol. 5, no. 1, pp. 52–99, 1919.</li><li id="ref-49" data-num="49">[49]  A. Wald, “Die widerspruchfreiheit des kollectivbegriffes der wahrscheinlichkeitsrechnung,” Ergebnisse Eines Mathematischen Kolloquiums, vol. 8, no. 38-72, p. 37, 1937.</li><li id="ref-50" data-num="50">[50]  A. Church, “On the concept of a random sequence,” Bulletin of the American Mathematical Society, vol. 46, no. 2, pp. 130–135, 1940.</li><li id="ref-51" data-num="51">[51]  J. Ville, “Etude critique de la notion de collectif,” Bull. Amer. Math. Soc, vol. 45, no. 11, p. 824, 1939.</li><li id="ref-52" data-num="52">[52]  G. Shafer and V. Vovk, “The sources of Kolmogorov’s Grundbegriffe,” Statistical Science, vol. 21, no. 1, pp. 70–98, 2006.</li><li id="ref-53" data-num="53">[53]  V. Vovk, “Kolmogorov’s complexity conception of probability,” Synthese Library, pp. 51–70, 2001.</li><li id="ref-54" data-num="54">[54]  C. P. Porter, “Kolmogorov on the role of randomness in probability theory,” Mathematical Structures in Computer Science, vol. 24, no. 3, 2014.</li><li id="ref-55" data-num="55">[55]  A. N. Kolmogorov, “Three approaches to the quantitative definition of information,” Problems of Information Transmission, vol. 1, no. 1, pp. 1–7, 1965.</li><li id="ref-56" data-num="56">[56]  A. Kolmogorov, “Logical basis for information theory and probability theory,” IEEE Transactions on Information Theory, vol. 14, no. 5, pp. 662–664, 1968.</li><li id="ref-57" data-num="57">[57]  A. N. Kolmogorov, “Combinatorial foundations of information theory and the calculus of probabilities,” Russian Mathematical Surveys, vol. 38, no. 4, pp. 29–40, 1983.</li><li id="ref-58" data-num="58">[58]  V. G. Vovk, “On the concept of the Bernoulli property,” Russian Mathematical Surveys, vol. 41, no. 1, p. 247, 1986.</li><li id="ref-59" data-num="59">[59]  V. Vovk, “Testing randomness online,” Statistical Science, vol. 36, no. 4, pp. 595–611, 2021.</li><li id="ref-60" data-num="60">[60]  F. Mota, S. Aaronson, L. Antunes, and A. Souto, “Sophistication as randomness deficiency,” in International Workshop on Descriptional Complexity of Formal Systems, Springer, 2013, pp. 172181.</li><li id="ref-61" data-num="61">[61]  S. S. Wilks, “Determination of sample sizes for setting tolerance limits,” Annals of Mathematical Statistics, vol. 12, no. 1, pp. 91–96, 1941.</li><li id="ref-62" data-num="62">[62]  ——, “Statistical prediction with special reference to the problem of tolerance limits,” Annals of Mathematical Statistics, vol. 13, no. 4, pp. 400–409, 1942.</li><li id="ref-63" data-num="63">[63]  A. Wald, “An extension of Wilks’ method for setting tolerance limits,” Annals of Mathematical Statistics, vol. 14, no. 1, pp. 45–55, 1943.</li><li id="ref-64" data-num="64">[64]  J. W. Tukey, “Non-parametric estimation II. Statistically equivalent blocks and tolerance regions–the continuous case,” Annals of Mathematical Statistics, vol. 18, no. 4, pp. 529–539, 1947.</li><li id="ref-65" data-num="65">[65]  P. Diaconis and D. Freedman, “Finite exchangeable sequences,” The Annals of Probability, pp. 745764, 1980.</li><li id="ref-66" data-num="66">[66]  D. J. Aldous, “Exchangeability and related topics,” in  ́ Ecole d’  ́ Et ́e de Probabilit ́es de Saint-Flour XIII—1983, 1985, pp. 1–198.</li><li id="ref-67" data-num="67">[67]  B. De Finetti, “Funzione caratteristica di un fenomeno aleatorio,” in Atti del Congresso Internazionale dei Matematici: Bologna del 3 al 10 de Settembre di 1928, 1929, pp. 179–190.</li><li id="ref-68" data-num="68">[68]  D. A. Freedman, “Bernard Friedman’s urn,” The Annals of Mathematical Statistics, pp. 956–970, 1965.</li><li id="ref-69" data-num="69">[69]  E. Hewitt and L. J. Savage, “Symmetric measures on Cartesian products,” Transactions of the American Mathematical Society, vol. 80, no. 2, pp. 470–501, 1955.</li><li id="ref-70" data-num="70">[70]  J. F. Kingman, “Uses of exchangeability,” The Annals of Probability, vol. 6, no. 2, pp. 183–197, 1978.</li><li id="ref-71" data-num="71">[71]  A. Gammerman, V. Vovk, and V. Vapnik, “Learning by transduction,” Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, vol. 14, pp. 148–155, 1998.</li><li id="ref-72" data-num="72">[72]  C. Saunders, A. Gammerman, and V. Vovk, “Transduction with confidence and credibility,” 1999.</li><li id="ref-73" data-num="73">[73]  V. Vovk, “On-line confidence machines are well-calibrated,” in The 43rd Annual IEEE Symposium on Foundations of Computer Science, IEEE, 2002, pp. 187–196.</li><li id="ref-74" data-num="74">[74]  V. Vovk, G. Shafer, and I. Nouretdinov, “Self-calibrating probability forecasting.,” in Neural Information Processing Systems, 2003, pp. 1133–1140.</li><li id="ref-75" data-num="75">[75]  V. Vovk and I. Petej, “Venn-Abers predictors,” arXiv:1211.0025, 2012.</li><li id="ref-76" data-num="76">[76]  V. Vovk, J. Shen, V. Manokhin, and M.-g. Xie, “Nonparametric predictive distributions based on conformal prediction,” Machine Learning, pp. 1–30, 2017.</li><li id="ref-77" data-num="77">[77]  E. Ndiaye and I. Takeuchi, “Computing full conformal prediction set with approximate homotopy,” in Advances in Neural Information Processing Systems, 2019.</li><li id="ref-78" data-num="78">[78]  ——, “Root-finding approaches for computing conformal prediction set,” arXiv:2104.06648, 2021.</li><li id="ref-79" data-num="79">[79]  R. F. Barber, E. J. Candes, A. Ramdas, and R. J. Tibshirani, “Predictive inference with the jackknife+,” The Annals of Statistics, vol. 49, no. 1, pp. 486–507, 2021.</li><li id="ref-80" data-num="80">[80]  J. Lei, J. Robins, and L. Wasserman, “Efficient nonparametric conformal prediction regions,” arXiv:1111.1418, 2011.</li><li id="ref-81" data-num="81">[81]  ——, “Distribution-free prediction sets,” Journal of the American Statistical Association, vol. 108, no. 501, pp. 278–287, 2013.</li><li id="ref-82" data-num="82">[82]  B. P ́oczos, A. Singh, A. Rinaldo, and L. Wasserman, “Distribution-free distribution regression,” in Artificial Intelligence and Statistics, PMLR, 2013, pp. 507–515.</li><li id="ref-83" data-num="83">[83]  J. Lei, M. G’Sell, A. Rinaldo, R. J. Tibshirani, and L. Wasserman, “Distribution-free predictive inference for regression,” Journal of the American Statistical Association, vol. 113, no. 523, pp. 10941111, 2018.</li><li id="ref-84" data-num="84">[84]  J. Lei, A. Rinaldo, and L. Wasserman, “A conformal prediction approach to explore functional data,” Annals of Mathematics and Artificial Intelligence, vol. 74, pp. 29–43, 2015.</li><li id="ref-85" data-num="85">[85]  J. Lei, “Fast exact conformalization of the lasso using piecewise linear homotopy,” Biometrika, vol. 106, no. 4, pp. 749–764, 2019.</li><li id="ref-86" data-num="86">[86]  C. Gupta, A. K. Kuchibhotla, and A. Ramdas, “Nested conformal prediction and quantile out-of-bag ensemble methods,” Pattern Recognition, p. 108 496, 2021.</li><li id="ref-87" data-num="87">[87]  R. Foygel Barber, E. J. Candes, A. Ramdas, and R. J. Tibshirani, “The limits of distribution-free conditional predictive inference,” Information and Inference: A Journal of the IMA, vol. 10, no. 2, pp. 455–482, 2021.</li><li id="ref-88" data-num="88">[88]  Y. Lee and R. F. Barber, “Distribution-free inference for regression: Discrete, continuous, and in between,” arXiv:2105.14075, 2021.</li><li id="ref-89" data-num="89">[89]  R. Izbicki, G. Shimizu, and R. Stern, “Flexible distribution-free conditional predictive bands using density estimators,” in Proceedings of Machine Learning Research, vol. 108, PMLR, 2020, pp. 30683077.</li><li id="ref-90" data-num="90">[90]  J. Lei, “Classification with confidence,” Biometrika, vol. 101, no. 4, pp. 755–769, Oct. 2014.</li><li id="ref-91" data-num="91">[91]  Y. Hechtlinger, B. Poczos, and L. Wasserman, “Cautious deep learning,” arXiv:1805.09460, 2018.</li><li id="ref-92" data-num="92">[92]  D. Stutz, K. D. Dvijotham, A. T. Cemgil, and A. Doucet, “Learning optimal conformal classifiers,” in International Conference on Learning Representations, 2022.</li><li id="ref-93" data-num="93">[93]  M. Cauchois, S. Gupta, A. Ali, and J. C. Duchi, “Robust validation: Confident predictions even when distributions shift,” arXiv:2008.04267, 2020.</li><li id="ref-94" data-num="94">[94]  L. Lei and E. J. Candes, “Conformal inference of counterfactuals and individual treatment effects,” arXiv:2006.06138, 2020.</li><li id="ref-95" data-num="95">[95]  M. Yin, C. Shi, Y. Wang, and D. M. Blei, “Conformal sensitivity analysis for individual treatment effects,” arXiv:2112.03493, 2021.</li><li id="ref-96" data-num="96">[96]  V. Chernozhukov, K. W ̈ uthrich, and Y. Zhu, “An exact and robust conformal inference method for counterfactual and synthetic controls,” Journal of the American Statistical Association, pp. 1–16, 2021.</li><li id="ref-97" data-num="97">[97]  E. J. Candes, L. Lei, and Z. Ren, “Conformalized survival analysis,” arXiv:2103.09763, 2021.</li><li id="ref-98" data-num="98">[98]  A. N. Angelopoulos, S. Bates, T. Zrnic, and M. I. Jordan, “Private prediction sets,” arXiv:2102.06202, 2021.</li><li id="ref-99" data-num="99">[99]  V. Chernozhukov, K. W ̈ uthrich, and Z. Yinchu, “Exact and robust conformal inference methods for predictive machine learning with dependent data,” in Conference On Learning Theory, PMLR, 2018, pp. 732–749.</li><li id="ref-100" data-num="100">[100]  R. Dunn, L. Wasserman, and A. Ramdas, “Distribution-free prediction sets with random effects,” arXiv:1809.07441, 2018.</li><li id="ref-101" data-num="101">[101]  R. I. Oliveira, P. Orenstein, T. Ramos, and J. V. Romano, “Split conformal prediction for dependent data,” arXiv:2203.15885, 2022.</li><li id="ref-102" data-num="102">[102]  C. Gupta and A. Ramdas, “Distribution-free calibration guarantees for histogram binning without sample splitting,” in International Conference on Machine Learning, vol. 139, 2021, pp. 3942–3952.</li><li id="ref-103" data-num="103">[103]  S. Park, S. Li, O. Bastani, and I. Lee, “PAC confidence predictions for deep neural network classifiers,” in International Conference on Learning Representations, 2021.</li><li id="ref-104" data-num="104">[104]  D. Volkhonskiy, E. Burnaev, I. Nouretdinov, A. Gammerman, and V. Vovk, “Inductive conformal martingales for change-point detection,” in Conformal and Probabilistic Prediction and Applications, PMLR, 2017, pp. 132–153.</li><li id="ref-105" data-num="105">[105]  X. Hu and J. Lei, “A distribution-free test of covariate shift using conformal prediction,” arXiv:2010.07147, 2020.</li><li id="ref-106" data-num="106">[106]  A. Podkopaev and A. Ramdas, “Tracking the risk of a deployed model and detecting harmful distribution shifts,” arXiv:2110.06177, 2021.</li><li id="ref-107" data-num="107">[107]  P. Chaudhuri, “Global nonparametric estimation of conditional quantile functions and their derivatives,” Journal of Multivariate Analysis, vol. 39, no. 2, pp. 246–269, 1991.</li><li id="ref-108" data-num="108">[108]  I. Steinwart and A. Christmann, “Estimating conditional quantiles with the help of the pinball loss,” Bernoulli, vol. 17, no. 1, pp. 211–225, 2011.</li><li id="ref-109" data-num="109">[109]  I. Takeuchi, Q. V. Le, T. D. Sears, and A. J. Smola, “Nonparametric quantile estimation,” Journal of Machine Learning Research, vol. 7, pp. 1231–1264, 2006.</li><li id="ref-110" data-num="110">[110]  K. Q. Zhou, S. L. Portnoy, et al., “Direct use of regression quantiles to construct confidence sets in linear models,” The Annals of Statistics, vol. 24, no. 1, pp. 287–306, 1996.</li><li id="ref-111" data-num="111">[111]  K. Q. Zhou and S. L. Portnoy, “Statistical inference on heteroscedastic models based on regression quantiles,” Journal of Nonparametric Statistics, vol. 9, no. 3, pp. 239–260, 1998.</li><li id="ref-112" data-num="112">[112]  R. Koenker, Quantile Regression. Cambridge University Press, 2005.</li><li id="ref-113" data-num="113">[113]  R. Koenker, V. Chernozhukov, X. He, and L. Peng, “Handbook of quantile regression,” 2018.</li><li id="ref-114" data-num="114">[114]  R. Koenker, “Additive models for quantile regression: Model selection and confidence bandaids,” Brazilian Journal of Probability and Statistics, vol. 25, no. 3, pp. 239–262, 2011.</li><li id="ref-115" data-num="115">[115]  A. Fisch, T. Schuster, T. S. Jaakkola, and R. Barzilay, “Efficient conformal prediction via cascaded inference with expanded admission,” in International Conference on Learning Representations, 2021.</li><li id="ref-116" data-num="116">[116]  T. Schuster, A. Fisch, T. Jaakkola, and R. Barzilay, “Consistent accelerated inference via confident adaptive transformers,” Empirical Methods in Natural Language Processing, 2021.</li><li id="ref-117" data-num="117">[117]  A. Fisch, T. Schuster, T. Jaakkola, and D. Barzilay, “Few-shot conformal prediction with auxiliary tasks,” in International Conference on Machine Learning, vol. 139, 2021, pp. 3329–3339.</li><li id="ref-118" data-num="118">[118]  J. Cherian and L. Bronner, “How the Washington Post estimates outstanding votes for the 2020 presidential election,” Washington Post, 2021, https://s3.us-east-1.amazonaws.com/elex-models-prod/2020general/write-up/election model writeup.pdf.</li><li id="ref-119" data-num="119">[119]  C. Lu and J. Kalpathy-Cramer, “Distribution-free federated learning with conformal predictions,” arXiv:2110.07661, 2021.</li><li id="ref-120" data-num="120">[120]  C. Lu, A. Lemay, K. Chang, K. Hoebel, and J. Kalpathy-Cramer, “Fair conformal predictors for applications in medical imaging,” arXiv:2109.04392, 2021.</li><li id="ref-121" data-num="121">[121]  Y. Romano, R. F. Barber, C. Sabatti, and E. Candes, “With malice toward none: Assessing uncertainty via equalized coverage,” Harvard Data Science Review, vol. 2, no. 2, Apr. 30, 2020.</li><li id="ref-122" data-num="122">[122]  A. K. Kuchibhotla and R. A. Berk, “Nested conformal prediction sets for classification with applications to probation data,” arXiv:2104.09358, 2021.</li><li id="ref-123" data-num="123">[123]  S. Bates, A. Angelopoulos, L. Lei, J. Malik, and M. Jordan, “Distribution-free, risk-controlling prediction sets,” Journal of the Association for Computing Machinery, vol. 68, no. 6, Sep. 2021.</li><li id="ref-124" data-num="124">[124]  F. Bretz, W. Maurer, W. Brannath, and M. Posch, “A graphical approach to sequentially rejective multiple test procedures,” Statistics in Medicine, vol. 28, no. 4, pp. 586–604, 2009.</li></ul>
<!-- 假设我们有一些图像作为输入，并且它们每个都包含 $K$ 个类中的一个类。我们从输出类估计概率的分类器 $\hat{f}(x) \in [0,1]^K$ 开始（ 即模型输出为 $\text{softmax}$ 分数 ）。保留适度数量（如 $500$ 个）的独立同分布样本集合作为校准数据（ $\left(X_1, Y_1\right), \ldots,\left(X_n, Y_n\right)$ ）。我们的目标是：利用上述 $\hat{f}$ 和校准数据，为新的输入构建一个由所有可能标签构成的预测集合 $\mathcal{C}\left(X_{\text {test }}\right) \subset\{1, \ldots, K\}$，该预测集合内的所有标签都满足下式的概率约束要求： -->

    <style>
    #refplus, #refplus li{ 
        padding:0;
        margin:0;
        list-style:none;
    }；
    </style>
    <script src="https://unpkg.com/@popperjs/core@2"></script>
    <script src="https://unpkg.com/tippy.js@6"></script>
    <script>
    document.querySelectorAll(".refplus-num").forEach((ref) => {
        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');
        let refel = document.querySelector(refid);
        let refnum = refel.dataset.num;
        let ref_content = refel.innerText.replace(`[${refnum}]`,'');
        tippy(ref, {
            content: ref_content,
        });
    });
    </script>
    </article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://xishansnow.github.io">西山晴雪</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://xishansnow.github.io/posts/4e18f5b8.html">http://xishansnow.github.io/posts/4e18f5b8.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://xishansnow.github.io" target="_blank">西山晴雪的知识笔记</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a><a class="post-meta__tags" href="/tags/BayesNN/">BayesNN</a><a class="post-meta__tags" href="/tags/%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B/">共形预测</a></div><div class="post_share"><div class="social-share" data-image="/img/007.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/c0fb1f85.html"><img class="prev-cover" src="/img/book_06.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">扩散模型-北大综述</div></div></a></div><div class="next-post pull-right"><a href="/posts/6d76fe1d.html"><img class="next-cover" src="/img/coffe_02.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">高斯过程混合模型</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/61b49ab8.html" title="神经网络与概率图模型"><img class="cover" src="/img/book_14.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-05</div><div class="title">神经网络与概率图模型</div></div></a></div><div><a href="/posts/e9d86c3f.html" title="神经网络--变分自编码器与 GAN"><img class="cover" src="/img/coffe_03.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-10</div><div class="title">神经网络--变分自编码器与 GAN</div></div></a></div><div><a href="/posts/9d2e33ad.html" title="神经网络--卷积与循环神经网络"><img class="cover" src="/img/book_16.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-15</div><div class="title">神经网络--卷积与循环神经网络</div></div></a></div><div><a href="/posts/9b150274.html" title="损失函数、代价函数、目标函数的区别 "><img class="cover" src="/img/book_14.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-11</div><div class="title">损失函数、代价函数、目标函数的区别 </div></div></a></div><div><a href="/posts/b4fb33a5.html" title=" 机器学习方法分类 "><img class="cover" src="/img/coffe_01.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-11</div><div class="title"> 机器学习方法分类 </div></div></a></div><div><a href="/posts/839b65d0.html" title="变分自编码器索引帖"><img class="cover" src="/img/coffe_10.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-03</div><div class="title">变分自编码器索引帖</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B-%EF%BC%9F"><span class="toc-text">1. 什么是共形预测 ？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%A0%A1%E5%87%86%E9%9B%86%E5%A4%A7%E5%B0%8F%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">3.2 校准集大小的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-text">1.1 共形预测的说明</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%85%B1%E5%BD%A2%E8%BF%87%E7%A8%8B%E7%9A%84%E7%A4%BA%E4%BE%8B"><span class="toc-text">2 共形过程的示例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E9%87%87%E7%94%A8%E8%87%AA%E9%80%82%E5%BA%94%E9%A2%84%E6%B5%8B%E9%9B%86%E5%90%88%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-text">2.1 采用自适应预测集合的分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%85%B1%E5%BD%A2%E5%8C%96%E7%9A%84%E5%88%86%E4%BD%8D%E6%95%B0%E5%9B%9E%E5%BD%92"><span class="toc-text">2.2 共形化的分位数回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E5%85%B1%E5%BD%A2%E5%8C%96%E7%9A%84%E6%A0%87%E9%87%8F%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E4%BC%B0%E8%AE%A1"><span class="toc-text">2.3 共形化的标量不确定性估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E5%85%B1%E5%BD%A2%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-text">2.4 共形贝叶斯</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%AF%84%E4%BC%B0%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">3 评估共形预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E8%AF%84%E4%BC%B0%E9%80%82%E5%BA%94%E6%80%A7"><span class="toc-text">3.1 评估适应性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%A3%80%E6%9F%A5%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%A6%86%E7%9B%96%E7%8E%87"><span class="toc-text">3.3 检查正确的覆盖率</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B%E7%9A%84%E6%89%A9%E5%B1%95"><span class="toc-text">4 共形预测的扩展</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E7%BB%84%E5%B9%B3%E8%A1%A1%E7%9A%84%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">4.1 组平衡的共形预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E7%B1%BB%E6%9D%A1%E4%BB%B6%E7%9A%84%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">4.2 类条件的共形预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%85%B1%E5%BD%A2%E9%A3%8E%E9%99%A9%E6%8E%A7%E5%88%B6"><span class="toc-text">4.3 共形风险控制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E5%BC%82%E5%B8%B8%E5%80%BC%E6%A3%80%E6%B5%8B"><span class="toc-text">4.4 异常值检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E5%8D%8F%E5%8F%98%E9%87%8F%E5%81%8F%E7%A7%BB%E4%B8%8B%E7%9A%84%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">4.5 协变量偏移下的共形预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%E5%88%86%E5%B8%83%E6%BC%82%E7%A7%BB%E4%B8%8B%E7%9A%84%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">4.6 分布漂移下的共形预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%B7%A5%E4%BD%9C%E5%AE%9E%E4%BE%8B"><span class="toc-text">5 工作实例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB"><span class="toc-text">5.1 多标签分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E8%82%BF%E7%98%A4%E5%88%86%E5%89%B2"><span class="toc-text">5.2 肿瘤分割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E5%85%B7%E6%9C%89%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E5%B8%83%E5%81%8F%E7%A7%BB%E7%9A%84%E5%A4%A9%E6%B0%94%E9%A2%84%E6%8A%A5"><span class="toc-text">5.3 具有时间序列分布偏移的天气预报</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E9%80%9A%E8%BF%87%E5%BC%82%E5%B8%B8%E5%80%BC%E6%A3%80%E6%B5%8B%E8%AF%86%E5%88%AB%E6%81%B6%E6%80%A7%E5%9C%A8%E7%BA%BF%E8%AF%84%E8%AE%BA"><span class="toc-text">5.4 通过异常值检测识别恶性在线评论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-%E9%80%89%E6%8B%A9%E6%80%A7%E5%88%86%E7%B1%BB"><span class="toc-text">5.5 选择性分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E5%AE%8C%E5%85%A8%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">6 完全共形预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E5%AE%8C%E5%85%A8%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">6.1 完全共形预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E4%BA%A4%E5%8F%89%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B%E3%80%81CV-%E5%92%8C-Jackknife"><span class="toc-text">6.2 交叉共形预测、CV+ 和 Jackknife+</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B%E7%9A%84%E5%8E%86%E5%8F%B2"><span class="toc-text">7 共形预测的历史</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E7%BC%98%E8%B5%B7"><span class="toc-text">7.1 缘起</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E8%BF%9B%E5%85%A5%E5%85%B1%E5%BD%A2%E9%A2%84%E6%B5%8B"><span class="toc-text">7.2 进入共形预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-%E5%BD%93%E5%89%8D%E8%B6%8B%E5%8A%BF"><span class="toc-text">7.3 当前趋势</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-text">参考文献</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 西山晴雪</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script></div></body></html>