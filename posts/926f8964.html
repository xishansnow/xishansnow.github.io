<!DOCTYPE html><html class="hide-aside" lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>🔥  神经网络中的不确定性研究综述 | 西山晴雪的知识笔记</title><meta name="keywords" content="贝叶斯神经网络,深度集成,不确定性神经网络,单一确定性神经网络,数据增强,不确定性校准,不确定性评测,概览"><meta name="author" content="西山晴雪"><meta name="copyright" content="西山晴雪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="神经网络中的不确定性研究综述">
<meta property="og:type" content="article">
<meta property="og:title" content="🔥  神经网络中的不确定性研究综述">
<meta property="og:url" content="http://xishansnow.github.io/posts/926f8964.html">
<meta property="og:site_name" content="西山晴雪的知识笔记">
<meta property="og:description" content="神经网络中的不确定性研究综述">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xishansnow.github.io/img/coffe_13.png">
<meta property="article:published_time" content="2022-03-22T02:00:00.000Z">
<meta property="article:modified_time" content="2025-02-17T11:55:02.015Z">
<meta property="article:author" content="西山晴雪">
<meta property="article:tag" content="贝叶斯神经网络">
<meta property="article:tag" content="深度集成">
<meta property="article:tag" content="不确定性神经网络">
<meta property="article:tag" content="单一确定性神经网络">
<meta property="article:tag" content="数据增强">
<meta property="article:tag" content="不确定性校准">
<meta property="article:tag" content="不确定性评测">
<meta property="article:tag" content="概览">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://xishansnow.github.io/img/coffe_13.png"><link rel="shortcut icon" href="/img/favi.jpg"><link rel="canonical" href="http://xishansnow.github.io/posts/926f8964"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"12DC1Q07CH","apiKey":"7e4ac2a644127298a8a2e8170335afdb","indexName":"xishansnowblog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '🔥  神经网络中的不确定性研究综述',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-17 19:55:02'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favi.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">389</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">411</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">117</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 贝叶斯方法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/4e1bbb89.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E4%BC%BC%E7%84%B6%E6%96%B9%E6%B3%95/"><i class="fa-fw fa-solid fa-chart-area"></i><span> 似然方法</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%BF%91%E4%BC%BC%E8%B4%9D%E5%8F%B6%E6%96%AF/"><i class="fa-fw fa-solid fa-cube"></i><span> 近似贝叶斯</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/MCMC/"><i class="fa-fw fa-solid fa-wand-magic-sparkles"></i><span> MCMC</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 变分推断</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 贝叶斯优化</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 概率图模型</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E7%BC%96%E7%A8%8B/"><i class="fa-fw fa-brands fa-codepen"></i><span> 概率编程</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-atom"></i><span> 高斯过程</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/b5b2c876.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"><i class="fa-fw fas fa-atom"></i><span> 高斯过程原理</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E6%96%AD/"><i class="fa-fw fas fa-cogs"></i><span> 高斯过程推断</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/"><i class="fa-fw fa-solid fa-magnet"></i><span> 可扩展高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 神经网络高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%AF%84%E6%B5%8B%E5%AF%B9%E6%AF%94/"><i class="fa-fw fa-solid fa-school"></i><span> 评测与数据集</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/"><i class="fa-fw fa-solid fa-cube"></i><span> 模型自动构建</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 随机模拟</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-ghost"></i><span> 不确定性DL</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/2b310e69.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A7%88"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 综述性文章</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%8D%95%E4%B8%80%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-atom"></i><span> 确定性神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-school"></i><span> 贝叶斯神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%B7%B1%E5%BA%A6%E9%9B%86%E6%88%90/"><i class="fa-fw fas fa-cogs"></i><span> 深度集成方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 数据增强方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%AF%B9%E6%AF%94%E8%AF%84%E6%B5%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 对比评测</span></a></li><li><a class="site-page child" href="/categories/%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E5%87%86/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 不确定性校准</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-map"></i><span> 时空随机场</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/82ad5ffe.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/"><i class="fa-fw fa-solid fa-map"></i><span> 时空随机场</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%8F%92%E5%80%BC/"><i class="fa-fw fa-solid fa-ghost"></i><span> 时空插值</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 回归分析</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 时空预报</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 数据同化</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 计算机实验模拟</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 时空监测网络设计</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E5%9C%BA%E7%BB%98%E5%88%B6/"><i class="fa-fw fa fa-anchor"></i><span> 场绘制专题</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-book-open"></i><span> 书籍</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="https://xishansnow.github.io/BayesianAnalysiswithPython2nd/index.html"><i class="fa-fw fa-solid  fa-landmark-dome"></i><span> 《Bayesian Analysis with Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/BayesianModelingandComputationInPython/index.html"><i class="fa-fw fa-solid  fa-graduation-cap"></i><span> 《Bayesian Modeling and Computation in Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/ElementsOfStatisticalLearning/index.html"><i class="fa-fw fa-solid  fa-book-atlas"></i><span> 《统计学习精要（ESL）》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/spatialSTAT_CN/index.html"><i class="fa-fw fa-solid  fa-layer-group"></i><span> 《空间统计学》</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://otexts.com/fppcn/index.html"><i class="fa-fw fa-solid  fa-cloud-sun-rain"></i><span> 《预测：方法与实践》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/MLAPP/index.html"><i class="fa-fw fa-solid  fa-robot"></i><span> 《机器学习的概率视角（MLAPP）》</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 索引</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 时间索引</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签索引</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类索引</span></a></li><li><a class="site-page child" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/"><i class="fa-fw fas fa-atlas"></i><span> 临时索引</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"><i class="fa-fw fas fa-utensils"></i><span> 常用软件</span></a></li><li><a class="site-page child" href="/link/paper/"><i class="fa-fw fas fa-book-open"></i><span> 学术工具</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 摄影作品</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/coffe_13.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">西山晴雪的知识笔记</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 贝叶斯方法</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/4e1bbb89.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E4%BC%BC%E7%84%B6%E6%96%B9%E6%B3%95/"><i class="fa-fw fa-solid fa-chart-area"></i><span> 似然方法</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%BF%91%E4%BC%BC%E8%B4%9D%E5%8F%B6%E6%96%AF/"><i class="fa-fw fa-solid fa-cube"></i><span> 近似贝叶斯</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/MCMC/"><i class="fa-fw fa-solid fa-wand-magic-sparkles"></i><span> MCMC</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 变分推断</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 贝叶斯优化</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 概率图模型</span></a></li><li><a class="site-page child" href="/categories/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BB%9F%E8%AE%A1/%E6%A6%82%E7%8E%87%E7%BC%96%E7%A8%8B/"><i class="fa-fw fa-brands fa-codepen"></i><span> 概率编程</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-atom"></i><span> 高斯过程</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/b5b2c876.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"><i class="fa-fw fas fa-atom"></i><span> 高斯过程原理</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E6%A8%A1%E5%9E%8B%E6%8E%A8%E6%96%AD/"><i class="fa-fw fas fa-cogs"></i><span> 高斯过程推断</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7/"><i class="fa-fw fa-solid fa-magnet"></i><span> 可扩展高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 神经网络高斯过程</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%AF%84%E6%B5%8B%E5%AF%B9%E6%AF%94/"><i class="fa-fw fa-solid fa-school"></i><span> 评测与数据集</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA/"><i class="fa-fw fa-solid fa-cube"></i><span> 模型自动构建</span></a></li><li><a class="site-page child" href="/categories/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 随机模拟</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-ghost"></i><span> 不确定性DL</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/2b310e69.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A7%88"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 综述性文章</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%8D%95%E4%B8%80%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-atom"></i><span> 确定性神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><i class="fa-fw fas fa-school"></i><span> 贝叶斯神经网络方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%B7%B1%E5%BA%A6%E9%9B%86%E6%88%90/"><i class="fa-fw fas fa-cogs"></i><span> 深度集成方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 数据增强方法</span></a></li><li><a class="site-page child" href="/categories/BayesNN/%E5%AF%B9%E6%AF%94%E8%AF%84%E6%B5%8B/"><i class="fa-fw fa-solid fa-magnet"></i><span> 对比评测</span></a></li><li><a class="site-page child" href="/categories/%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E5%87%86/"><i class="fa-fw fa-solid fa-gas-pump"></i><span> 不确定性校准</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-map"></i><span> 时空随机场</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/posts/82ad5ffe.html"><i class="fa-fw fa-solid fa-pen-nib"></i><span> 索引帖</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/"><i class="fa-fw fa-solid fa-map"></i><span> 时空随机场</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E6%8F%92%E5%80%BC/"><i class="fa-fw fa-solid fa-ghost"></i><span> 时空插值</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E7%A9%BA%E9%97%B4%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 回归分析</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 时空预报</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E6%97%B6%E7%A9%BA%E5%9B%9E%E5%BD%92/"><i class="fa-fw fa-brands fa-deezer"></i><span> 数据同化</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 计算机实验模拟</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E9%9A%8F%E6%9C%BA%E6%A8%A1%E6%8B%9F/"><i class="fa-fw fa-solid fa-layer-group"></i><span> 时空监测网络设计</span></a></li><li><a class="site-page child" href="/categories/GeoAI/%E5%9C%BA%E7%BB%98%E5%88%B6/"><i class="fa-fw fa fa-anchor"></i><span> 场绘制专题</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-book-open"></i><span> 书籍</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="https://xishansnow.github.io/BayesianAnalysiswithPython2nd/index.html"><i class="fa-fw fa-solid  fa-landmark-dome"></i><span> 《Bayesian Analysis with Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/BayesianModelingandComputationInPython/index.html"><i class="fa-fw fa-solid  fa-graduation-cap"></i><span> 《Bayesian Modeling and Computation in Python》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/ElementsOfStatisticalLearning/index.html"><i class="fa-fw fa-solid  fa-book-atlas"></i><span> 《统计学习精要（ESL）》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/spatialSTAT_CN/index.html"><i class="fa-fw fa-solid  fa-layer-group"></i><span> 《空间统计学》</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://otexts.com/fppcn/index.html"><i class="fa-fw fa-solid  fa-cloud-sun-rain"></i><span> 《预测：方法与实践》</span></a></li><li><a class="site-page child" href="https://xishansnow.github.io/MLAPP/index.html"><i class="fa-fw fa-solid  fa-robot"></i><span> 《机器学习的概率视角（MLAPP）》</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-compass"></i><span> 索引</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fa-solid fa-timeline"></i><span> 时间索引</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签索引</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类索引</span></a></li><li><a class="site-page child" href="/categories/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/"><i class="fa-fw fas fa-atlas"></i><span> 临时索引</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-link"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/"><i class="fa-fw fas fa-utensils"></i><span> 常用软件</span></a></li><li><a class="site-page child" href="/link/paper/"><i class="fa-fw fas fa-book-open"></i><span> 学术工具</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 摄影作品</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">🔥  神经网络中的不确定性研究综述</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-22T02:00:00.000Z" title="发表于 2022-03-22 10:00:00">2022-03-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-17T11:55:02.015Z" title="更新于 2025-02-17 19:55:02">2025-02-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/BayesNN/">BayesNN</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/BayesNN/%E7%BB%BC%E8%BF%B0%E6%A6%82%E8%A7%88/">综述概览</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">58.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>222分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><script src='https://unpkg.com/tippy.js@2.0.2/dist/tippy.all.min.js'></script>
<script src='/js/attachTooltips.js'></script>
<link rel='stylesheet' href='/css/tippy.css'>
<script src="https://unpkg.com/tippy.js@2.0.2/dist/tippy.all.min.js"></script>
<script src="/js/attachTooltips.js"></script>
<link rel="stylesheet" href="/css/tippy.css">
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>【摘 要】 在过去十年中，神经网络几乎触及了每一个科学领域，并成为各种现实世界应用的关键部分。由于越来越多的传播和使用，人们对神经网络预测结果的信心也变得越来越重要。但基础的神经网络要么无法提供不确定性估计，要么存在过于自信或信心不足的问题。为了克服这个问题，许多研究人员致力于理解和量化神经网络中的预测不确定性。前人已经确定了不同类型和来源的不确定性，并提出了各种估计和量化神经网络中不确定性的方法。本文全面概述了神经网络中的不确定性估计，回顾了该领域的最新进展，突出了当前的挑战，并确定了潜在的研究机会。它旨在为任何对神经网络中的不确定性估计感兴趣的人提供一个宽泛的概述和介绍，而不预先假定读者具备该领域的先验知识。为此，论文首先对不确定性来源这一关键因素进行了全面介绍，并将其分为（可还原的） <strong>模型不确定性</strong> 和（不可还原的） <strong>数据不确定性</strong> 。介绍了基于<code>单一确定性神经网络</code>、<code>贝叶斯神经网络</code>、<code>神经网络集成</code>、<code>测试时数据增强</code> 四种不确定性的建模方法，讨论了这些领域的不同分支及最新发展。在实际应用方面，我们讨论了各种不确定性的测量方法，以及神经网络的校准方法，概述了现有基线和可用成果。来自医学图像分析、机器人、地球观测等领域的不同例子，引申出了神经网络实际应用对不确定性的需求和挑战。此外，本文还讨论了用于任务和安全等关键现实世界应用神经网络中不确定性估计方法的实际局限性，并展望了更广泛使用此类方法的下一步发展方向。</p>
<p>【原 文】 Gawlikowski, Jakob, et al. “A survey of uncertainty in deep neural networks.” arxiv preprint arXiv:2107.03342 (2021).</p>
<p>【阅后感】 本文比较全面地回顾了与神经网络的预测不确定性相关的话题：从不确定性的来源与分类开始，到估计不确定性的方法，再到不确定性的量化评估和校准方法，内容全面而精炼，值得深入阅读。其中个人觉得值得阅读的有几点：（1）系统梳理了不确定性来源和类型，这在之前的文章中几乎都是一笔带过的，但这对正确理解不确定性具有提纲挈领的作用；（2）不确定性的深度神经网络估计方法更为全面，之前的综述主要围绕贝叶斯神经网络方法展开，少量提到了其他方法（如：深度集成），而本文更系统地将估计方法分为四类：单一确定性神经网络、深度集成网络、贝叶斯神经网络、测试时数据增强，梳理地更全面；（3）在最近几年比较热门的不确定性计量和校准方面涉及的内容比较多，这是之前文章所缺乏的；（4）将最近一两年有关不确定性测试基线的最新进展也囊括进来了，反映出作者在这个方面上跟踪很及时；(5) 重要的是，作者来自空间数据科学领域。</p>
<h2 id="1-概述">1 概述</h2>
<p>在过去十年中，<code>深度神经网络 (DNN)</code> 取得了巨大进步，促进其应用于各种研究领域，其中包括对复杂系统进行建模或理解，例如地球观测、医学图像分析或机器人技术。尽管深度神经网络在医学图像分析 <sup class="refplus-num"><a href="#ref-1">[1]</a></sup><sup class="refplus-num"><a href="#ref-2">[2]</a></sup><sup class="refplus-num"><a href="#ref-3">[3]</a></sup><sup class="refplus-num"><a href="#ref-4">[4]</a></sup><sup class="refplus-num"><a href="#ref-5">[5]</a></sup><sup class="refplus-num"><a href="#ref-6">[6]</a></sup> 、自动车辆控制 <sup class="refplus-num"><a href="#ref-7">[7]</a></sup><sup class="refplus-num"><a href="#ref-8">[8]</a></sup><sup class="refplus-num"><a href="#ref-9">[9]</a></sup><sup class="refplus-num"><a href="#ref-10">[10]</a></sup> 等高风险领域很有吸引力，但在注重任务安全问题的现实应用中部署仍然有限。造成这种限制的主要因素是：</p>
<ul>
<li>
<p>深度神经网络的推断模型<code>缺乏表现力和透明度</code>，使得人们很难相信他们的结果 <sup class="refplus-num"><a href="#ref-2">[2]</a></sup></p>
</li>
<li>
<p>无法区分<code>分布内样本</code>和<code>分布外样本</code> <sup class="refplus-num"><a href="#ref-11">[11]</a></sup><sup class="refplus-num"><a href="#ref-12">[12]</a></sup> ，对<code>分布偏移</code>比较敏感 <sup class="refplus-num"><a href="#ref-13">[13]</a></sup></p>
</li>
<li>
<p>缺少为深度神经网络的决策 <sup class="refplus-num"><a href="#ref-14">[14]</a></sup> 和过度自信的预测 <sup class="refplus-num"><a href="#ref-15">[15]</a></sup><sup class="refplus-num"><a href="#ref-16">[16]</a></sup> 提供可靠不确定性估计的方法</p>
</li>
<li>
<p>对<code>对抗性样本</code>不敏感，使深度神经网络更容易受到破坏 <sup class="refplus-num"><a href="#ref-17">[17]</a></sup><sup class="refplus-num"><a href="#ref-18">[18]</a></sup><sup class="refplus-num"><a href="#ref-19">[19]</a></sup></p>
</li>
</ul>
<p>上述因素主要源于数据中已经包含的不确定性（ <strong>数据不确定性</strong> ）或缺乏对神经网络的了解（ <strong>模型不确定性</strong> ）。为了克服这些限制，提供不确定性估计是必不可少的，以便<code>预测不确定性</code>可以被忽略或传递给人类专家来做出相应决策 <sup class="refplus-num"><a href="#ref-20">[20]</a></sup>。</p>
<div class="note info flat"><p><strong>预测不确定性</strong> 在本文中为一个独立、完整的术语，中文理解为 “预测结果的不确定性” 或 “预测输出的不确定性”，英文翻译为 “Uncertainty of Prediction”，专指某个机器学习模型的预测输出中存在的不确定性，也是本文讨论的主要对象。获得预测不确定性的方法比较多（ 见 <code>第 3 节</code> ），但从贝叶斯视角来看可以划分为贝叶斯方法和非贝叶斯方法，前者的主要特点是先得到模型参数的后验分布，而后通过边缘化得到预测；而后者会采用各种方法直接估计预测输出的不确定性，例如目前 SOTA 的深度集成方法对不同子模型的输出做平均后得出预测，还有些方法假设预测输出服从某种分布，而后通过最优化计算得到该分布的参数。</p>
<p>不过 <code>Wilson 等</code> 在一篇 <a href="ef4c963d.html">博客</a> 中也提出，深度集成方法不仅不是非贝叶斯方法，反而恰恰说明了贝叶斯方法的有效性，因为贝叶斯方法的最大特点就是边缘化而非后验分布，而深度集成方法恰恰是在对可能的模型做边缘化，以得到更为可靠的预测。</p>
</div>
<p>提供不确定性估计不仅对高风险领域的安全决策很重要，在数据源高度不均匀且标记数据很少的领域中也至关重要，例如遥感 <sup class="refplus-num"><a href="#ref-21">[21]</a></sup><sup class="refplus-num"><a href="#ref-22">[22]</a></sup> 。也适用于不确定性已经成为学习技术关键组成的领域，例如在主动学习 <sup class="refplus-num"><a href="#ref-23">[23]</a></sup><sup class="refplus-num"><a href="#ref-24">[24]</a></sup><sup class="refplus-num"><a href="#ref-25">[25]</a></sup><sup class="refplus-num"><a href="#ref-26">[26]</a></sup> 或强化学习 <sup class="refplus-num"><a href="#ref-20">[20]</a></sup><sup class="refplus-num"><a href="#ref-27">[27]</a></sup><sup class="refplus-num"><a href="#ref-28">[28]</a></sup><sup class="refplus-num"><a href="#ref-29">[29]</a></sup> 中，不确定性估计非常重要。</p>
<p>近年来，研究人员对估计深度神经网络中的不确定性表现出越来越大的兴趣 <sup class="refplus-num"><a href="#ref-30">[30]</a></sup><sup class="refplus-num"><a href="#ref-20">[20]</a></sup><sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-33">[33]</a></sup><sup class="refplus-num"><a href="#ref-34">[34]</a></sup><sup class="refplus-num"><a href="#ref-35">[35]</a></sup><sup class="refplus-num"><a href="#ref-36">[36]</a></sup>。估计预测不确定性的最常见方法是将<strong>模型引起的不确定性</strong> 和 <strong>数据引起的不确定性</strong> 分开建模。前者通过改进深度神经网络模型可以减少，但后者是无法减少的。对这种分离后的不确定性进行建模的最重要方法大致有四种：<code>贝叶斯推断</code> <sup class="refplus-num"><a href="#ref-30">[30]</a></sup><sup class="refplus-num"><a href="#ref-20">[20]</a></sup><sup class="refplus-num"><a href="#ref-37">[37]</a></sup><sup class="refplus-num"><a href="#ref-9">[9]</a></sup><sup class="refplus-num"><a href="#ref-38">[38]</a></sup>、<code>集成方法</code> <sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-39">[39]</a></sup><sup class="refplus-num"><a href="#ref-40">[40]</a></sup>、<code>测试时数据增强</code><sup class="refplus-num"><a href="#ref-41">[41]</a></sup><sup class="refplus-num"><a href="#ref-42">[42]</a></sup> 、包含<strong>显式不确定性建模</strong>或<strong>附加不确定性估计组件</strong>的<code>单一确定性神经网络</code> <sup class="refplus-num"><a href="#ref-43">[43]</a></sup><sup class="refplus-num"><a href="#ref-44">[44]</a></sup><sup class="refplus-num"><a href="#ref-45">[45]</a></sup><sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-46">[46]</a></sup>。</p>
<p>能够估计预测不确定性不足以支撑安全地决策，还需要确保不确定性估计的可靠性。为此，已经进行了大量深度神经网络可靠程度（或称为校准性质）的研究工作，出现了多种不确定性估计的重校准方法 <sup class="refplus-num"><a href="#ref-15">[15]</a></sup><sup class="refplus-num"><a href="#ref-47">[47]</a></sup><sup class="refplus-num"><a href="#ref-48">[48]</a></sup>。</p>
<div class="note warning modern"><p><strong>模型引起的不确定性</strong> 也被称为 <strong>模型不确定性</strong> 或 <strong>认知不确定性</strong> 。</p>
<p><strong>数据引起的不确定性</strong> 也被称为 <strong>数据不确定性</strong> 、<strong>偶然不确定性</strong> 或 <strong>任意不确定性</strong>。</p>
</div>
<p>已经有几部文献介绍和概述了统计建模中的不确定性：</p>
<ul>
<li><code>Ghanem 等</code> <sup class="refplus-num"><a href="#ref-49">[49]</a></sup> 出版了一本关于不确定性量化的手册，其中包括对不确定性量化中不同概念的广泛且详细的描述，但没有明确关注神经网络的应用。</li>
<li><code>Gal</code> <sup class="refplus-num"><a href="#ref-50">[50]</a></sup> 和 <code>Kendall</code> <sup class="refplus-num"><a href="#ref-51">[51]</a></sup> 的论文很好地概述了贝叶斯神经网络，特别是关注了 <code>MC Dropout</code> 方法及其在计算机视觉任务中的应用。</li>
<li><code>Malinin</code> <sup class="refplus-num"><a href="#ref-52">[52]</a></sup> 的论文包含了对<code>先验神经网络</code>的介绍和见解。</li>
<li><code>Wang 等</code>贡献了关于贝叶斯深度学习的两项调研报告 <sup class="refplus-num"><a href="#ref-53">[53]</a></sup><sup class="refplus-num"><a href="#ref-54">[54]</a></sup>。他们介绍了贝叶斯神经网络 (BNN) 的通用框架和概念描述，随后更新了用于神经网络中不确定性估计的贝叶斯方法，特别是推荐系统、主题模型。</li>
<li>在 <sup class="refplus-num"><a href="#ref-55">[55]</a></sup> 中，通过呈现和比较基于 <code>softmax</code> 输出、神经网络集成、贝叶斯神经网络和自编码器在 MNIST 数据集上的不确定性估计，给出了对深度学习中不确定性量化的评估。</li>
<li>关于不确定性估计方法在现实应用中的实用性，<code>Gustafsson 等</code> <sup class="refplus-num"><a href="#ref-56">[56]</a></sup> 引入了一个框架来测试现实世界计算机视觉应用程序所需的鲁棒性，并比较了两种流行的方法，即 <code>MC Dropout</code> 和 <code>集成方法</code>。</li>
<li><code>Ḧullermeier 等</code> <sup class="refplus-num"><a href="#ref-57">[57]</a></sup> 提出了神经网络中 <code>任意不确定性</code> 和 <code>认知不确定性</code> 概念，并讨论了不同的概念来建模和量化它们。</li>
<li>与此相对，<code>Abdar 等</code> <sup class="refplus-num"><a href="#ref-58">[58]</a></sup> 概述了神经网络中的不确定性估计方法，并为不同的应用领域提供了广泛的参考资料列表，并讨论了开放挑战。</li>
</ul>
<p>在本文工作中，我们对在涉及神经网络不确定性的所有概念几乎都进行了概述，并紧扣现实世界应用中的适用性。我们的目标是为读者提供 <strong>从 “不确定性来源” 到 “需要进行不确定性估计的应用”</strong> 全过程的清晰线索。此外，我们指出了当前方法的一些局限性，并讨论了未来要解决的进一步挑战。</p>
<p>本调研报告主要面向已经熟悉深度学习概念并计划将不确定性估计纳入其预测的人。但对于已经熟悉该主题的人来说，这篇报告提供了对神经网络中不确定性的整体概念及其在不同领域应用的概述。</p>
<p>总体上来说，我们全面讨论了：</p>
<ul>
<li>不确定性的来源和类型（<code>第 2 节</code>）</li>
<li>估计深度神经网络中不确定性的最新研究和方法（<code>第 3 节</code>）</li>
<li>用于评估不确定性估计质量的测量方法（<code>第 4 节</code>）</li>
<li>校准深度神经网络的最新研究和方法（<code>第 5 节</code>）</li>
<li>对常用评估数据集、可用基准和实现的概述（<code>第 6 节</code>）</li>
<li>使用不确定性估计的实际应用概述（<code>第 7 节</code>）</li>
<li>关于当前挑战和未来进一步研究方向的讨论（<code>第 8 节</code>）</li>
</ul>
<p>一般来说，如果没有特殊说明，DNN 的不确定性估计和校准方法可应用于所有回归、分类和分割问题。为了更深入地研究这些方法的应用，建议进一步阅读参考文献。</p>
<h2 id="2-深度神经网络的不确定性">2 深度神经网络的不确定性</h2>
<p>神经网络是一个由权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>（即模型参数）参数化的非线性函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">f_{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，它从可观测的输入集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">X</mi></mrow><annotation encoding="application/x-tex">\mathbb{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">X</span></span></span></span> 映射到可观测的输出集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">Y</mi></mrow><annotation encoding="application/x-tex">\mathbb{Y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">Y</span></span></span></span>，即</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mi>f</mi><mi>θ</mi></msub><mo>:</mo><mi mathvariant="double-struck">X</mi><mo>→</mo><mi mathvariant="double-struck">Y</mi><mspace width="1em"></mspace><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>y</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(1)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">f_{\theta}: \mathbb{X} \rightarrow \mathbb{Y} \quad f_\theta(x) = y  \tag{1}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathbb">Y</span><span class="mspace" style="margin-right:1em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>对于有监督的情况，应当有一组有限的训练数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi><mo>⊆</mo><mi mathvariant="double-struck">D</mi><mo>=</mo><mi mathvariant="double-struck">X</mi><mo>×</mo><mi mathvariant="double-struck">Y</mi></mrow><annotation encoding="application/x-tex">\mathcal{D} \subseteq \mathbb{D} = \mathbb{X} \times  \mathbb{Y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⊆</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7722em;vertical-align:-0.0833em;"></span><span class="mord mathbb">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">Y</span></span></span></span> ，其中包含 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个数据样本点和对应的目标响应，即：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="script">D</mi><mo>=</mo><mo stretchy="false">(</mo><mi mathvariant="script">X</mi><mo separator="true">,</mo><mi mathvariant="script">Y</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mrow><mo fence="true">{</mo><msub><mi>x</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>n</mi></msub><mo fence="true">}</mo></mrow><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mo>⊆</mo><mi mathvariant="double-struck">D</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(2)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathcal{D}  = (\mathcal{X} ,\mathcal{Y} ) =\left \{x_n,y_n \right \}^N_{n=1} \subseteq \mathbb{D}  \tag{2}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathcal" style="margin-right:0.14643em;">X</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">Y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">}</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">⊆</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">D</span></span><span class="tag"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>对于新数据点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup><mo>∈</mo><mi mathvariant="double-struck">X</mi></mrow><annotation encoding="application/x-tex">x^\ast \in \mathbb{X}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord mathbb">X</span></span></span></span>，在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span> 上训练的神经网络被用于预测相应的目标 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo><mo>=</mo><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">f_\theta(x^\ast) = y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>。</p>
<p>为了分析不确定性，我们剖析了从 <strong>原始信息获取</strong> 到 <strong>（含不确定性估计的）神经网络预测</strong> 的四个环节：</p>
<p>1）数据采集过程：环境中某些信息的出现和对该信息的测量观测（如 <code>鸟叫</code> 和 <code>音频记录</code>）。</p>
<p>2）深度神经网络的构建过程：神经网络的设计和训练。</p>
<p>3）使用的推断模型：用于推断的模型（例如 <code>贝叶斯神经网络</code> 或 <code>神经网络集成</code>）。</p>
<p>4）对预测不确定性的建模：对神经网络和数据引起的不确定性进行建模和估计。</p>
<div class="note info flat"><p><code>注：</code><br>
熟悉贝叶斯统计的人通常会将推断理解为对模型参数的推断，但本文中更多指对预测结果的推断。</p>
</div>
<p>在实践中，上述四个环节包含了若干潜在的不确定性（和误差）来源，会影响神经网络的最终预测。对深度神经网络的预测不确定性而言，我们认为最重要的五个因素是：</p>
<ul>
<li><code>因素 I</code>：现实世界的变化性</li>
<li><code>因素 II</code>：观测系统固有的误差</li>
<li><code>因素 III</code>：DNN 模型架构自身的误差</li>
<li><code>因素 IV</code>：DNN 训练过程中产生的误差</li>
<li><code>因素 V</code>：未知数据引起的误差</li>
</ul>
<p>下面将详细地描述上述四个步骤，并剖析其中的不确定性来源，解释不确定性在整个过程中的传播方式。最后，我们介绍了神经网络的<code>预测不确定性</code>模型，并介绍了神经网络考虑的主要不确定性类型。本节的目标是对神经网络中存在的不确定性给出一个严谨的概览。为简单起见，我们仅描述和讨论其数学性质，而对这些性质的深入理解与各领域的应用方法有关，不在本文范畴内。</p>
<h3 id="2-1-预测不确定性的来源">2.1 预测不确定性的来源</h3>
<h4 id="2-1-1-数据采集环节">2.1.1 数据采集环节</h4>
<p>在监督学习背景下，数据采集可以被理解为：<strong>测量值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 和目标变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 的生成过程</strong>。这些数据被用于表达某个（现实世界）空间 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Ω</span></span></span></span> 中出现的情况 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span></span></span> 。在现实世界中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span></span></span> 可以是一只鸟，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 是这只鸟的照片，而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 是一个标记为 “鸟” 的标签。测量过程中可能会出现随机噪声，信息也可能会丢失。</p>
<p>我们通过以下方式对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 中的这种随机性进行建模：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>x</mi><mo>∣</mo><mi>ω</mi><mo>∼</mo><msub><mi>p</mi><mrow><mi>x</mi><mo>∣</mo><mi>ω</mi></mrow></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(3)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">x \mid \omega \sim p_{x \mid \omega}  \tag{3}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>等效地，可以推导出目标变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 的随机性描述，其值要么来自于另一次测量，要么来自某个标记过程。而这两种情况也都可能受到噪声和误差影响，我们将其表述为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>y</mi><mo>∣</mo><mi>ω</mi><mo>∼</mo><msub><mi>p</mi><mrow><mi>y</mi><mo>∣</mo><mi>ω</mi></mrow></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(4)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">y \mid \omega \sim p_{y \mid \omega} \tag{4}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">4</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>神经网络在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个依据真实世界中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>ω</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">\omega_1, ..., \omega_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 观测的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>∣</mo><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x \mid \omega_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∣</mo><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y \mid \omega_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 基础上进行训练，即数据集为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="script">D</mi><mo>=</mo><msubsup><mrow><mo fence="true">{</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(5)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathcal{D} =\left \{ x_i, y_i \right \}^N_{i=1} \tag{5}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">}</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">5</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>在采集训练数据时，有两个因素可能会导致依据这些数据训练的神经网络出现预测不确定性。</p>
<p>首先，样本空间 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Ω</span></span></span></span> 应该被 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>ω</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">\omega_1,...,\omega_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 对应的训练数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub></mrow><annotation encoding="application/x-tex">x_1,...,x_N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 充分覆盖。为此，必须广泛考虑到不在训练集中的所有新样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>， 即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup><mo mathvariant="normal">≠</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x^\ast \neq x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 。按照工作过程，下面需要根据训练好的神经网络模型来估计 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 对应的新目标 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>，这直接导致了不确定性的第一个因素：</p>
<blockquote>
<p><strong>因素 I：现实世界的变化性</strong></p>
<p>大多数现实世界环境是高度可变的，并且几乎不断受到变化的影响。这些变化会影响参数，例如温度、照明、杂波以及物理对象的大小和形状。环境的变化也会影响物体的表达，例如雨后的植物与干旱后的植物看起来非常不同。当现实世界的情况与训练集相比发生变化时，被称为<code>分布偏移（ Distribution Shift ）</code>。神经网络对分布变化很敏感，这可能导致神经网络性能发生显著变化。</p>
</blockquote>
<div class="note info flat"><p>个人理解：<br>
分布偏移可以被理解为采集或观测的训练数据与现实情况之间由于时间等因素发生了偏差，根据不全面的训练数据得到的模型无法完整体现现实世界。</p>
</div>
<p>第二种情况与测量系统有关，它会直接影响样本与对应目标之间的相关性。测量系统生成描述 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\omega_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的信息 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，但可能没有足够的信息来学习从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的映射。这意味着现实世界中可能存在高度不同的信息 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\omega_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\omega_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>（例如城市和森林），导致非常相似的测量值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">x_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> （例如温度），或类似的相应目标 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">y_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>（例如将两个样本都标记为森林的含噪声标签）。这导致了第二种不确定因素：</p>
<blockquote>
<p><strong>因素 II：测量系统的误差和噪声</strong></p>
<p>测量本身可能是神经网络预测的不确定性来源。这可能是源于：</p>
<ul>
<li>测量设备本身受限（例如图像分辨率）、测量错误、并不充分可用的信息模态导致。</li>
<li>测量过程中的噪声（例如传感器噪声）、运动或机械应力等导致不精确的测量。</li>
<li>错误标签也是不确定性的来源，也可被视为测量系统中的误差和噪声，被称为标签噪声，会降低训练期间对真值的预测置信度，进而影响整个模型。<br>
…</li>
</ul>
</blockquote>
<h4 id="2-1-2-模型构建环节">2.1.2 模型构建环节</h4>
<p>深度神经网络的设计涵盖了神经网络的显式建模及其随机训练过程。由神经网络的设计和训练引起的对问题结构的假设被称为归纳偏好 <sup class="refplus-num"><a href="#ref-59">[59]</a></sup>。我们梳理了建模者在神经网络设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span> 中关于网络结构（例如参数数量、层数、激活函数等）和训练过程（例如优化算法、正则化、增强等）的所有决策，发现神经网络预测中不确定性的第三个和第四个因素：</p>
<blockquote>
<p><strong>因素 III：模型架构中的误差</strong></p>
<p>神经网络的结构对其性能有直接影响，因此也对其预测不确定性产生影响。例如，参数数量会影响记忆容量，这可能导致对训练数据的欠拟合或过拟合。关于神经网络中的不确定性，更深的神经网络往往对其 <code>softmax</code> 输出过于自信，这意味着它们在概率得分最高的类别上，给予了过多可能性 <sup class="refplus-num"><a href="#ref-15">[15]</a></sup>。</p>
</blockquote>
<p>对于给定的神经网络设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span> 和训练数据集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span>，神经网络的训练本身是一个随机的过程，因此结果神经网络 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是基于如下随机变量的（ 这种随机的表现形式是：每次得到的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 都不同 ）：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>θ</mi><mo>∣</mo><mi>D</mi><mo separator="true">,</mo><mi>s</mi><mo>∼</mo><msub><mi>p</mi><mrow><mi>θ</mi><mo>∣</mo><mi>D</mi><mo separator="true">,</mo><mi>s</mi></mrow></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(6)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\theta \mid D,s \sim p_{\theta \mid D,s} \tag{6}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7858em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">6</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>该过程的随机性，还与一些随机决策有关，包括：数据随机排序、随机初始化、随机正则化、Dropout 等。神经网络的损失是高度非线性的，训练过程中的随机性通常会导致不同的局部最优解 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>θ</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\theta^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> ，并产生不同的模型 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup>。此外，批量大小、学习率和训练时的迭代期数等参数，也会影响训练并导致不同的模型。</p>
<p>根据基础任务不同，这些多样化的模型对单个样本的预测可能存在显著差异，甚至会导致整体模型性能上的差异。这种对训练过程的敏感性产生了神经网络预测不确定性的第四个因素：</p>
<blockquote>
<p><strong>因素 IV：训练过程中的误差</strong></p>
<p>神经网络的训练过程包括许多必须定义的参数（批量大小、优化器、学习率、停止标准、正则化等），以及训练过程中的随机决策（批量生成和权重初始化等）。所有这些决策都会影响局部最优解，因此两个训练过程不太可能产生相同的模型参数化。正如数据采集中描述的那样，一个不平衡的或在数据分布的单一区域覆盖率较低的训练数据集，也会给神经网络的参数学习带来不确定性。通过使用数据增强以增加多样性，或者通过平衡单一类别或区域对损失函数的影响，都可以弱化这种不确定性。</p>
</blockquote>
<p>由于训练过程基于给定的训练数据集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span>，因此数据获取过程中的误差（例如标签噪声）也可能导致训练过程中的误差。</p>
<h4 id="2-1-3-预测推断环节">2.1.3 预测推断环节</h4>
<p>推断描述了神经网络对新数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 的输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 的预测。此时，神经网络已经针对特定任务进行了训练。因此，不是该任务输入的样本会存在误差，这也是不确定性的来源之一：</p>
<blockquote>
<p><strong>因素 V：未知数据导致的误差</strong></p>
<p>尤其是在分类任务中，在来自世界 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">W_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的样本上训练的神经网络，也能够处理来自完全不同的世界 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">W_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的样本，而这会导致误差。例如，当一个在猫和狗的图像上训练的神经网络接收到一个鸟的样本点时，就会发生这种情况。此时，不确定性的来源并不在于数据采集过程（因为我们假设样本均是有效的），而是因为样本来自于两个不同的任务或者领域。</p>
</blockquote>
<h3 id="2-2-预测不确定性的构成">2.2 预测不确定性的构成</h3>
<p>作为建模者，人们主要对最终传播到预测结果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 上的不确定性感兴趣，我们称之为 <code>预测不确定性</code>。它应当包含上述各环节传播过来的所有不确定性内容。在贝叶斯范式中，某个新输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 的预测结果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 的概率分布由下式给出：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∫</mo><mi mathvariant="normal">Ω</mi></msub><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><mi>ω</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>ω</mi><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo><mi>d</mi><mi>ω</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(7)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(y^\ast \mid x^\ast) = \int_\Omega p(y^\ast \mid \omega)p(\omega \mid x^\ast)d\omega \tag{7}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2719em;vertical-align:-0.9119em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.4336em;"><span style="top:-1.7881em;margin-left:-0.4445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">Ω</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span><span class="tag"><span class="strut" style="height:2.2719em;vertical-align:-0.9119em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">7</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>并且最大后验估计（MAP）由下式给出：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msup><mi>y</mi><mo>∗</mo></msup><mo>=</mo><munder><mo><mi>arg</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo></mo><mi>y</mi></munder><mtext> </mtext><mtext> </mtext><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(8)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">y^\ast =\mathop{\arg\max}\limits_{y} \,\, p(y \mid x^\ast) \tag{8}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9331em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.7805em;vertical-align:-1.0305em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.2056em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">max</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0305em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:1.7805em;vertical-align:-1.0305em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">8</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>对于贝叶斯方法来说，需要对模型参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">ω</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{\omega}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03704em;">ω</span></span></span></span></span></span> 建模，需要基于训练数据集 $$D = { x_i,y_i }^N_{i=1}$$ 获得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">ω</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{\omega}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:0.03704em;">ω</span></span></span></span></span></span> 的近似表示。这样新样本点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 在 <code>式（7）</code> 和 <code>式（8）</code> 中对应的 <code>预测分布</code> 和 <code>MAP 估计</code> 可以在已知样本基础上进行预测：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∫</mo><mi>D</mi></msub><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo separator="true">,</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(9)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(y^\ast \mid x^\ast) =\int_D p(y^\ast \mid (x,y),x^\ast) d(x,y)  \tag{9}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2719em;vertical-align:-0.9119em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.4336em;"><span style="top:-1.7881em;margin-left:-0.4445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9119em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:2.2719em;vertical-align:-0.9119em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">9</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>和</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msup><mi>y</mi><mo>∗</mo></msup><mo>=</mo><munder><mo><mi>arg</mi><mo>⁡</mo><mi>max</mi><mo>⁡</mo></mo><mi>y</mi></munder><mtext> </mtext><mtext> </mtext><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>D</mi><mo separator="true">,</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(10)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">y^\ast = \mathop{\arg \max} \limits_{y} \,\, p(y \mid D,x^\ast)  \tag{10}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9331em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.7805em;vertical-align:-1.0305em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.2056em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">max</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0305em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:1.7805em;vertical-align:-1.0305em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">10</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>一般来说，<code>式 (9)</code> 中给出的预测分布（代表了<code>预测不确定性</code>）是未知的，只能根据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span> 中给定的数据进行估计。而近年神经网络领域针对该估计方法形成了许多技术、方法和工具集。</p>
<div class="note info flat"><p><code>式 (7)</code> 实际上对应了贝叶斯方法，即先推断模型参数的后验分布，而后通过边缘化求得预测分布，该预测分布中包含了所有不确定性，而 <code>式 (8)</code> 是其中确定性最高的那套参数的点估计预测结果。 <code>式 (9)</code> 和 <code>式 (10)</code> 则代表了非贝叶斯方法，此类方法期望通过样本直接得到预测分布和点估计。</p>
</div>
<p>通过上述分析可以比较清楚地看出，神经网络中的不确定性既受模型相关误差的影响，又受输入数据相关误差的影响。因此与最终预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 相关的预测不确定性通常从结构上可以被分为： <strong>数据不确定性</strong> （ 也称为统计或任意不确定性 <sup class="refplus-num"><a href="#ref-57">[57]</a></sup> ）和 <strong>模型不确定性</strong> （ 也称系统或认知不确定性<sup class="refplus-num"><a href="#ref-57">[57]</a></sup> ）。而根据底层方法不同，有时将 <strong>分布不确定性</strong> 单列，用于对训练数据未覆盖的区域样本（分布外样本）引起的不确定性进行建模 <sup class="refplus-num"><a href="#ref-32">[32]</a></sup>。</p>
<h4 id="2-2-1-数据与模型不确定性">2.2.1 数据与模型不确定性</h4>
<p><strong>模型不确定性</strong> 涵盖了由模型缺陷引起的不确定性，无论是由于训练过程中的误差、模型结构不充分，还是由于未知样本或训练数据集覆盖不佳而导致的知识缺乏。</p>
<p>与此相对， <strong>数据不确定性</strong> 则与直接源自数据的不确定性有关。 <strong>数据不确定性</strong> 是因为数据样本在表示真实世界时的信息缺失引起的，但它也遵循 <code>式 (7)</code> 中所述的分布。例如，在回归任务中，输入和目标测量中的噪声会导致神经网络无法学习和纠正数据不确定性。在分类任务中，无法 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">100\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">100%</span></span></span></span> 地确定为某一类的样本，也同样会导致预测中的数据不确定性。信息缺失是测量系统的结果，而非模型导致的结果。典型数据不确定性如：通过 <code>低分辨率图像</code> 或 <code>存在误差的标签</code> 来表示现实世界。</p>
<p>分析一下涉及神经网络预测的五个不确定性因素，可以发现：</p>
<ul>
<li><strong>模型不确定性</strong> 涵盖了 <code>因素 I</code>、<code>因素 III</code>、<code>因素 IV</code> 和 <code>因素 V</code></li>
<li><strong>数据不确定性</strong> 仅与<code>因素 II</code> 相关</li>
</ul>
<div class="note info flat"><p><a href="35513.html">《安全的人工智能需要贝叶斯深度学习》</a> 一文提出，在多任务学习中存在另外一种本文没有提到的数据不确定，即在相同输入数据集情况下，由于任务不同而导致的不确定性，并因此将数据不确定性划分为两类：</p>
<ul>
<li>
<p>异质的不确定性（或数据依赖型不确定性）：此类不确定性依赖于输入数据，且会被传导至模型的预测结果中。</p>
</li>
<li>
<p>同质的不确定性（或任务依赖型不确定性）：此类不确定性不依赖于输入数据，而依赖于具体任务。不同任务之间的此类不确定性存在不同，但对于同一任务中的所有输入数据而言，此类不确定性是一个常量。任务依赖型不确定性不会被传导至模型输出，但可用于描述和任务有关不确定性，例如，该文作者建议将任务不确定性的估计结果用于多任务加权损失函数的构造。</p>
</li>
</ul>
</div>
<p>尽管（理论上）可以通过改进架构、学习过程或训练数据集来减少 <strong>模型不确定性</strong>，但通常无法减少 <strong>数据不确定性</strong> <sup class="refplus-num"><a href="#ref-60">[60]</a></sup>。因此，一个能够处理不确定输入，并能够消除或量化 <strong>模型不确定性</strong> ，同时能够正确预测 <strong>数据不确定性</strong> 的深度神经网络，对于各种现实世界中对任务和安全敏感的应用而言至关重要。</p>
<p>贝叶斯统计框架为推断深度学习中的不确定性提供了一种实用工具 <sup class="refplus-num"><a href="#ref-61">[61]</a></sup>。在贝叶斯建模中， <strong>模型不确定性</strong> 被形式化为模型参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 上的概率分布，而 <strong>数据不确定性</strong> 被形式化为模型输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 上的概率分布，即给定参数化模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 时，预测输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 上的分布可由下式给出：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mo>∫</mo><munder><munder><mrow><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mrow><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></munder><munder><munder><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mrow><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></munder><mi>d</mi><mi>θ</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(11)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(y^\ast \mid x^\ast,D) =\int \underbrace{p(y^\ast \mid x^\ast,\theta)}_{Data} \underbrace{p(\theta \mid D)}_{Model} d\theta \tag{11}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9441em;vertical-align:-1.5841em;"></span><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.4237em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z" /></svg></span><span class="brace-center" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z" /></svg></span><span class="brace-right" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z" /></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5763em;"><span></span></span></span></span></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.4159em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z" /></svg></span><span class="brace-center" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z" /></svg></span><span class="brace-right" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z" /></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5841em;"><span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span class="tag"><span class="strut" style="height:2.9441em;vertical-align:-1.5841em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">11</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span> 被称为<strong>模型参数的后验分布</strong>，简称后验，描述了给定训练数据集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span> 时，模型参数的不确定性，可以用于表征模型不确定性。后验分布通常难以处理，集成方法试图通过学习几个不同的参数设置并在结果模型上进行平均来近似后验 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup> ，而贝叶斯推断则使用贝叶斯定理 <sup class="refplus-num"><a href="#ref-62">[62]</a></sup> 对其进行表述：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>D</mi><mo>∣</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(12)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(\theta \mid D) = \frac{p(D \mid \theta)p(\theta)}{p(D)} \tag{12}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">12</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 被称为<strong>模型参数的先验分布</strong>，简称先验，因为它不考虑任何信息，而是考虑关于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 的一般知识。</p>
<p>式中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>D</mi><mo>∣</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(D \mid \theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 为<strong>似然函数</strong>，简称似然，表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span> 是由被 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 参数化的模型生成的可能性。许多损失函数受似然函数启发或与似然函数有关，例如，寻求最大对数似然的损失函数就有 <code>交叉熵</code> 或 <code>均方误差</code> 等 <sup class="refplus-num"><a href="#ref-63">[63]</a></sup>。</p>
<p>即使使用 <code>式（12）</code> 中给出的表述，<code>式（11）</code> 中的预测分布仍然难以处理，因为仍然要做边缘化的积分。为了克服此问题，提出了多种直接或者间接计算近似预测分布的方法，将在 <code>第 3 节</code> 进行介绍。</p>
<h4 id="2-2-2-分布不确定性">2.2.2 分布不确定性</h4>
<p>根据估计和量化预测不确定性的方法不同，有时可以将 <code>式 (11)</code> 中的预测分布公式做进一步分解，划分为 <code>数据</code>、<code>分布</code> 和 <code>模型</code> 三个部分 <sup class="refplus-num"><a href="#ref-32">[32]</a></sup>：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mo>∫</mo><mo>∫</mo><munder><munder><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>μ</mi><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mrow><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></munder><munder><munder><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>μ</mi><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mrow><mi>D</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>b</mi><mi>u</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>a</mi><mi>l</mi></mrow></munder><munder><munder><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mrow><mi>M</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></munder><mi>d</mi><mi>μ</mi><mi>d</mi><mi>θ</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(13)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(y^\ast \mid x^\ast,D) = \int \int \underbrace{p(y \mid \mu)}_{Data} \underbrace{p(\mu \mid x^\ast,\theta)}_{Distributional} \underbrace{p(\theta \mid D)}_{Model} d \mu d\theta  \tag{13}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9441em;vertical-align:-1.5841em;"></span><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫∫</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.4237em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z" /></svg></span><span class="brace-center" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z" /></svg></span><span class="brace-right" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z" /></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5763em;"><span></span></span></span></span></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.4159em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">ib</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">na</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z" /></svg></span><span class="brace-center" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z" /></svg></span><span class="brace-right" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z" /></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5841em;"><span></span></span></span></span></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.4159em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13
 35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688
 0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7
-331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z" /></svg></span><span class="brace-center" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214
c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14
 53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3
 11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0
-5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z" /></svg></span><span class="brace-right" style="height:0.548em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3
 28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237
-174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z" /></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5841em;"><span></span></span></span></span></span><span class="mord mathnormal">d</span><span class="mord mathnormal">μ</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span class="tag"><span class="strut" style="height:2.9441em;vertical-align:-1.5841em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">13</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><code>式（13）</code> 中的 <code>Distributional 部分</code> 表示了实际神经网络输出中存在的不确定性，例如，对于分类任务，这可能是一个 <code>Dirichlet 分布</code>，它是 <code>softmax</code> 输出的类别分布上的分布。</p>
<p><strong>分布不确定性</strong> 通常指由输入数据的分布变化引起的不确定性（如：训练数据和测试数据可能不在同一个分布域内）; <strong>模型不确定性</strong> 指构建和训练深度神经网络过程中引起的不确定性。如 <code>式（13）</code> 中建模的那样， <strong>模型不确定性</strong> 会影响对 <strong>分布不确定性</strong> 的估计，进而影响对 <strong>数据不确定性</strong> 的估计。</p>
<p>虽然本文中介绍的大多数方法仅区分 <strong>模型不确定性</strong> 和 <strong>数据不确定性</strong> ，但一些专门用于检测分布外样本的方法，通常目标就是要明确 <strong>分布不确定性</strong> <sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-64">[64]</a></sup>。<code>第 3 节</code> 会更详细地介绍量化神经网络中不确定性的多种方法， <code>第 4 节</code> 中介绍了评估不同类型不确定性的方法。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220324181825-3397.webp" alt=""></p>
<blockquote>
<p><strong>图 1：分类和回归模型的数据、模型和分布不确定性</strong></p>
</blockquote>
<h3 id="2-3-按照输入分布域做分类">2.3 按照输入分布域做分类</h3>
<p>依据最终用于预测的输入数据所在分布域不同，还可以将预测不确定性分为三大类：</p>
<h4 id="2-3-1-域内不确定性">2.3.1 域内不确定性</h4>
<p><code>域内不确定性</code> <sup class="refplus-num"><a href="#ref-65">[65]</a></sup> 表示与 “从某个与训练数据分布相同的分布中抽取的” 输入相关的不确定性。域内不确定性源于深度神经网络由于缺乏域内知识而无法对域内样本做出解释。从建模者角度来看，域内不确定性是由设计误差（ <strong>模型不确定性</strong> ）和手头问题的复杂性（ <strong>数据不确定性</strong> ）共同引起的。根据对这两个不确定性来源的分析，可以通过提高训练数据（集）或训练过程的质量来减少域内不确定性 <sup class="refplus-num"><a href="#ref-57">[57]</a></sup>。</p>
<h4 id="2-3-2-域偏移不确定性">2.3.2 域偏移不确定性</h4>
<p>域偏移不确定性 <sup class="refplus-num"><a href="#ref-13">[13]</a></sup> 表示与 “从某个训练数据分布的偏移版本中抽取的” 输入相关的不确定性。分布变化往往是由 <code>训练数据覆盖范围不足</code> 或/和 <code>现实世界固有的变化性</code> 造成的。由于深度神经网络无法根据训练时看到的样本对域偏移样本做出解释，因此域偏移会增加深度神经网络的预测不确定性。有一部分导致域偏移不确定性的误差可以被建模，进而被弱化。例如，深度神经网络可以学习被遮挡的样本，以减少由遮挡引起的域偏移不确定性 <sup class="refplus-num"><a href="#ref-66">[66]</a></sup>。然而，很难对导致域偏移不确定性的所有误差进行建模，例如运动噪声 <sup class="refplus-num"><a href="#ref-60">[60]</a></sup>。从建模者的角度来看，域偏移不确定性是由外部或环境因素引起的，可以通过在训练数据集中增加覆盖偏移域的样本，来减少域偏移不确定性。</p>
<h4 id="2-3-3-域外不确定性">2.3.3 域外不确定性</h4>
<p>域外不确定性 <sup class="refplus-num"><a href="#ref-67">[67]</a></sup><sup class="refplus-num"><a href="#ref-68">[68]</a></sup><sup class="refplus-num"><a href="#ref-69">[69]</a></sup><sup class="refplus-num"><a href="#ref-70">[70]</a></sup> 表示与 “从某个未知数据分布的子空间中抽取的” 输入相关的不确定性。未知数据分布与训练数据分布不同，而且相差甚远。深度神经网络可以从域偏移样本中提取域内知识，但无法从域外样本中提取域内知识。例如，域偏移不确定性描述的是 “用一个学习了猫和狗分类的神经网络预测一张模糊狗照片” 的情况，而域外不确定性描述的是 “用一个学习了猫和狗分类的神经网络预测一只鸟” 的情况。域外不确定性源于深度神经网络由于缺乏域外知识而无法对域外样本做出解释。从建模者的角度来看，域外不确定性是因为从神经网络不打算给出预测的区域输入的样本引起的，或由于训练数据不足导致。</p>
<div class="note info flat"><p>因为 <strong>模型不确定性</strong> 可以捕获由于缺乏知识而导致的不确定性内容，因此可以用来捕获域内、域偏移和域外不确定性。与此相对，<strong>数据不确定性</strong> 仅捕获由训练数据本身引起的不确定性，因此只能用来捕获域内不确定性，例如重叠样本、系统性标签的噪声等。</p>
</div>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220323213935-c6e2.webp" alt=""></p>
<blockquote>
<p>图 1：分类和回归模型的数据、模型和分布不确定性</p>
</blockquote>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220325111204-8d02.webp" alt=""></p>
<blockquote>
<p>图 2：该图展示了神经网络 pipeline 的不同环节，采用了一个对地观测的示例 – 利用光学遥感图像进行土地覆盖分类（此处为居民地和森林）。黄色框中突出显示了影响预测不确定性的多种因素。<code>因素 I</code> 表现为被云层覆盖的树木、不同类型/颜色的树木等不断变化的环境。<code>因素 II</code> 表现为测量不充分或错误标记，导致无法直接用于区分居民地和森林。在实际中，此类图像的分辨率可能很低，这也是 <code>因素 II</code> 的一部分。<code>因素 III</code> 和 <code>因素 IV</code> 代表了由网络结构和随机训练过程引起的不确定性。相比之下，<code>因素 V</code> 表示为向经过训练的神经网络提供了未知类型的图像（此处用牛和猪表示）。</p>
</blockquote>
<h2 id="3-预测不确定性的估计方法">3 预测不确定性的估计方法</h2>
<p>如 <code>第 2 节</code> 所述，有若干因素会导致模型和数据的不确定性，并最终传播到深度神经网络的预测结果。这种不确定性来源的多样性，使得几乎所有应用都无法完全消除神经网络的不确定性。尤其是在使用真实世界数据的实际应用中，训练数据只是所有可能输入数据的子集，这意味着深度神经网络域与实际数据域之间存在不匹配，而且是不可避免的。</p>
<p>很难精确计算深度神经网络的<code>预测不确定性</code>，因为通常无法准确地对各种不确定性建模，有些不确定性甚至是未知的。因此，深度神经网络的预测不确定性的估计方法已经成为一个流行且重要的研究领域。</p>
<p>通常 <strong>数据不确定性</strong> 在预测时能够被以某种方式反映出来，例如：分类神经网络的 <code>softmax</code> 层输出的类概率、回归神经网络中显式输出的标准差 <sup class="refplus-num"><a href="#ref-60">[60]</a></sup> 等。与此同时，有研究引入了对 <strong>模型不确定性</strong> 的建模，试图将其与 <strong>数据不确定性</strong> 分开，以便获得对 <strong>数据不确定性</strong> 更准确的表示 <sup class="refplus-num"><a href="#ref-60">[60]</a></sup><sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-31">[31]</a></sup>。</p>
<p>根据深度神经网络的数量（单个或多个）和性质（确定性或随机性），预测不确定性的估计方法大致可以分为四种不同类型：</p>
<ul>
<li><strong>单一确定性神经网络方法</strong>：该方法在单一的某个确定性神经网络中，通过前向传递给出神经网络的预测不确定性，是最简单直接、效率最高的一种方法。在该方法中，预测不确定性可能通过额外的外部方法给出，或者由神经网络直接预测给出。</li>
<li><strong>贝叶斯神经网络方法</strong>：涵盖所有类型的随机深度神经网络，所谓随机，指同一样本的两次前向传递通常会导致不同的结果。</li>
<li><strong>神经网络集成方法</strong>：在推断时结合了几种不同确定性神经网络的预测，并通过加权平均等方式给出最终预测。</li>
<li><strong>测试时增强方法</strong>：基于单一确定性神经网络做出预测，但在测试时，通过对输入数据的增强，生成多个可用于评估预测（不）确定性的预测结果。</li>
</ul>
<p>下面介绍这四种类型的主要思想和进一步的扩展，并讨论它们的主要性质。在 <code>图 3</code> 中，给出了不同类型和方法的概览。在 <code>图 4</code> 中，展示了用于区分不同类型方法的基本原理。<code>表 1</code> 总结了本文工作中所涉及方法的主要属性，例如复杂性、计算工作量、内存消耗、灵活性等。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/bayes_20220323_132058_91b1.webp" alt=""></p>
<blockquote>
<p>图 3：本文涉及的四种不同类型的不确定性量化方法概览。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-71">[71]</a></sup><sup class="refplus-num"><a href="#ref-72">[72]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-46">[46]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-36">[36]</a></sup><sup class="refplus-num"><a href="#ref-35">[35]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-32">[32]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>5</mn></msup></mrow><annotation encoding="application/x-tex">^5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-44">[44]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>7</mn></msup></mrow><annotation encoding="application/x-tex">^7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-35">[35]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>8</mn></msup></mrow><annotation encoding="application/x-tex">^8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-73">[73]</a></sup><sup class="refplus-num"><a href="#ref-74">[74]</a></sup>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>9</mn></msup></mrow><annotation encoding="application/x-tex">^9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">9</span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-75">[75]</a></sup><sup class="refplus-num"><a href="#ref-30">[30]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>10</mn></msup></mrow><annotation encoding="application/x-tex">^{10}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">10</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-76">[76]</a></sup><sup class="refplus-num"><a href="#ref-77">[77]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>11</mn></msup></mrow><annotation encoding="application/x-tex">^{11}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">11</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-20">[20]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>12</mn></msup></mrow><annotation encoding="application/x-tex">^{12}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-78">[78]</a></sup><sup class="refplus-num"><a href="#ref-79">[79]</a></sup><sup class="refplus-num"><a href="#ref-80">[80]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>13</mn></msup></mrow><annotation encoding="application/x-tex">^{13}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-81">[81]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>14</mn></msup></mrow><annotation encoding="application/x-tex">^{14}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">14</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-82">[82]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>15</mn></msup></mrow><annotation encoding="application/x-tex">^{15}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">15</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-83">[83]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>16</mn></msup></mrow><annotation encoding="application/x-tex">^{16}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">16</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-63">[63]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>17</mn></msup></mrow><annotation encoding="application/x-tex">^{17}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">17</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-84">[84]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>18</mn></msup></mrow><annotation encoding="application/x-tex">^{18}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">18</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-31">[31]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>19</mn></msup></mrow><annotation encoding="application/x-tex">^{19}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">19</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-85">[85]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>20</mn></msup></mrow><annotation encoding="application/x-tex">^{20}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">20</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-86">[86]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>21</mn></msup></mrow><annotation encoding="application/x-tex">^{21}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">21</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-87">[87]</a></sup><sup class="refplus-num"><a href="#ref-88">[88]</a></sup><sup class="refplus-num"><a href="#ref-89">[89]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>22</mn></msup></mrow><annotation encoding="application/x-tex">^{22}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-90">[90]</a></sup><sup class="refplus-num"><a href="#ref-45">[45]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>23</mn></msup></mrow><annotation encoding="application/x-tex">^{23}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-39">[39]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>24</mn></msup></mrow><annotation encoding="application/x-tex">^{24}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">24</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-40">[40]</a></sup> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>25</mn></msup></mrow><annotation encoding="application/x-tex">^{25}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">25</span></span></span></span></span></span></span></span></span></span></span></span> <sup class="refplus-num"><a href="#ref-91">[91]</a></sup></p>
</blockquote>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/bayes_20220323_132719_5e79.webp" alt=""></p>
<blockquote>
<p>图 4：四种神经网络预测的不确定性建模基本原理。对于给定的输入样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>，每种方法都提供预测输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 及其对应的 模型不确定性 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\sigma_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 数据不确定性 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\sigma_{data}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。A) 单一确定性模型，B) 贝叶斯神经网络，B) 集成方法， D) 测试时数据增强。均值和标准差仅用于保持可视化的简洁。在实践中，可以使用其他表示方法。对于确定性方法，对概率分布参数的预测做了特殊标记 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Ξ</mi></mrow><annotation encoding="application/x-tex">Ξ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Ξ</span></span></span></span> ，其他基于预测神经网络的方法则没有。</p>
</blockquote>
<br>
<blockquote>
<p><strong>表 1 ：本文涉及的四种方法一览表</strong>（<code>贝叶斯神经网络</code>、<code>集成方法</code>、<code>单一确定性神经网络</code>、<code>测试时数据增强</code>）。表中的 <code>High/Low</code> 标签是相对于其他方法并基于其背后的思想给出的。</p>
</blockquote>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/bayes_20220323_132337_6bbe.webp" alt=""></p>
<h3 id="3-1-单一确定性神经网络方法">3.1 单一确定性神经网络方法</h3>
<p>确定性神经网络的参数是确定性的，同一输入的重复前向传递会提供相同的结果。我们梳理和总结了 “基于单一确定性神经网络的前向传递来计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 的预测不确定性” 的所有方法。</p>
<div class="note info flat"><p>（1）<code>确定性</code> 是相对于 <code>随机性</code> 而言的。在确定性神经网络中，权重被视为未知的确切值；（2）<code>单一性</code>主要是相对于集成方法的多个神经网络而言的，指仅存在一个神经网络模型。</p>
</div>
<p>在文献中能够找到的方法可以粗略分为两类：</p>
<ul>
<li><code>内蕴不确定估计方法</code>：在单一确定性神经网络中，不确定性被显式地建模和训练 <sup class="refplus-num"><a href="#ref-44">[44]</a></sup><sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-92">[92]</a></sup><sup class="refplus-num"><a href="#ref-64">[64]</a></sup><sup class="refplus-num"><a href="#ref-93">[93]</a></sup> ，不需要附加组件来做不确定性估计；</li>
<li><code>外接不确定性估计方法</code>：使用附加组件来获得对神经网络预测不确定性的估计 <sup class="refplus-num"><a href="#ref-46">[46]</a></sup><sup class="refplus-num"><a href="#ref-36">[36]</a></sup><sup class="refplus-num"><a href="#ref-71">[71]</a></sup><sup class="refplus-num"><a href="#ref-72">[72]</a></sup>。</li>
</ul>
<p>对于前者，不确定性估计会影响神经网络的训练过程和预测。后者通常应用于已经训练好的神经网络，由于训练好的神经网络并没有被附加组件修改，所以该方法对神经网络的预测没有影响。</p>
<h4 id="3-1-1-内蕴不确定性估计法">3.1.1 内蕴不确定性估计法</h4>
<p>大多数内蕴不确定性估计方法的基本思路是：“直接估计预测输出的概率分布的参数”，而不是仅逐点地做最大后验估计（此处指传统神经网络的点估计预测结果）。通常，此类神经网络的损失函数会采用 <code>真实分布</code> 和 <code>预测分布</code> 之间的预期散度，例如 <sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-94">[94]</a></sup> 。</p>
<div class="note info flat"><p>疑惑： 以下两个英文有何不同？</p>
<p><code>真实分布 ( true distribution ) </code> 是指什么？ <code>预测分布（predictive distribution）</code> 和 <code>预测分布（predicted distribution）</code> 又是指什么？</p>
</div>
<p>我们可以将 <code>神经网络输出结果的预测分布</code> 解释为对<strong>模型不确定性</strong>的估计，此方法其实是在试图模仿对神经网络参数的贝叶斯建模行为，只是其建模对象不是神经网络参数的分布，而是神经网络输出结果的分布。该方法用参数化方法对预测分布进行近似建模，在训练得到参数的最优解后，用参数化的近似分布代替  <code>预测分布</code>  并用于计算神经网络输出的期望值，该值可以作为预测结果的最终点估计。</p>
<div class="note info flat"><p>经反复理解并查阅原文文献后，此处的“预测分布（ <code>predicted distribution</code> ）”，与传统贝叶斯方法中的 “预测分布（<code>predictive distribution</code>）” 含义相同。在后者中，会通过对模型参数的后验分布做边缘化，以求解响应变量的概率分布，即预测分布；更进一步地基于该预测分布求期望值作为点估计。而此处的思想是不对模型参数建模，而是直接对神经网络的预测分布做参数化近似建模（ 有点像施加在输出变量上的变分推断 ），通过训练求解近似分布的最优参数，进而用近似分布代替预测分布求解期望值作为点估计。由于该方法没有对模型参数建模，其神经网络权重是确定性的而非随机性的，因此是非贝叶斯的。</p>
</div>
<p><strong>（1） 分类任务</strong></p>
<p>对于分类任务，神经网络的输出通常为最后一层输出的类概率。对于多分类任务，类概率是 <code>softmax</code> 函数的结果：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">softmax</mi><mo>⁡</mo><mo>:</mo><msup><mi mathvariant="double-struck">R</mi><mi>K</mi></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>→</mo><mrow><mo fence="true">{</mo><mi>z</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>K</mi></msup><mo>∣</mo><msub><mi>z</mi><mi>i</mi></msub><mo>≥</mo><mn>0</mn><mo separator="true">,</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>z</mi><mi>k</mi></msub><mo>=</mo><mn>1</mn><mo fence="true">}</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">softmax</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>z</mi><msub><mo stretchy="false">)</mo><mi>j</mi></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>z</mi><mi>j</mi></msub><mo fence="true">)</mo></mrow></mrow><mrow><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>z</mi><mi>k</mi></msub><mo fence="true">)</mo></mrow></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable></mtd><mtd width="50%"></mtd><mtd><mtext>(14)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\operatorname{softmax}: \mathbb{R}^{K} &amp;\rightarrow\left\{z \in \mathbb{R}^{K} \mid z_{i} \geq 0, \sum_{k=1}^{K} z_{k}=1\right\}\\
\operatorname{softmax}(z)_{j} &amp;=\frac{\exp \left(z_{j}\right)}{\sum_{k=1}^{K} \exp \left(z_{k}\right)}
\end{aligned} \tag{14}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:6.3284em;vertical-align:-2.9142em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.4142em;"><span style="top:-5.4142em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mop"><span class="mord mathrm">softmax</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.3851em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mop"><span class="mord mathrm">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.9142em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.4142em;"><span style="top:-5.4142em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">1</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">}</span></span></span></span></span><span style="top:-2.3851em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.1288em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1709em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.9142em;"><span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:6.3284em;vertical-align:-2.9142em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">14</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>对于二分类任务，则类概率通常是 <code>sigmoid 函数</code> 的结果：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>&nbsp;sigmoid&nbsp;</mtext><mo>:</mo><mi mathvariant="double-struck">R</mi><mo>→</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi mathvariant="normal">sigmoid</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi>z</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable></mtd><mtd width="50%"></mtd><mtd><mtext>(15)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
&amp;\text { sigmoid }: \mathbb{R} \rightarrow[0,1] \\
&amp;\operatorname{sigmoid}(z)=\frac{1}{1+\exp (-z)}
\end{aligned}\tag{15}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.0574em;vertical-align:-1.7787em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.2787em;"><span style="top:-4.7602em;"><span class="pstrut" style="height:3.3214em;"></span><span class="mord"></span></span><span style="top:-2.7787em;"><span class="pstrut" style="height:3.3214em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7787em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.2787em;"><span style="top:-4.7602em;"><span class="pstrut" style="height:3.3214em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">&nbsp;sigmoid&nbsp;</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathbb">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span><span style="top:-2.7787em;"><span class="pstrut" style="height:3.3214em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm">sigmoid</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.7787em;"><span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:4.0574em;vertical-align:-1.7787em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">15</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>上述类概率本身已经可以被解释为对 <strong>数据不确定性</strong> 的预测。但广受争议的情况是：神经网络通常过于自信，<code>softmax</code> 的输出校准不佳，导致不确定性估计并不准确 <sup class="refplus-num"><a href="#ref-95">[95]</a></sup><sup class="refplus-num"><a href="#ref-67">[67]</a></sup><sup class="refplus-num"><a href="#ref-44">[44]</a></sup><sup class="refplus-num"><a href="#ref-92">[92]</a></sup>。此外，<code>softmax</code> 的输出无法对 <strong>模型不确定性</strong> 进行细分 ，而如果不显式地分析 <strong>模型不确定性</strong>，就可能导致对分布外样本的错误分类给出高置信度（ 即 “很有信心地说错话而不自知” ）。</p>
<div class="note info flat"><p>之所以这样说，是因为在贝叶斯方法中，只将不确定性分为 <code>数据不确定性</code> 和 <code>模型不确定性</code>，而<code>分布不确定性</code>被视为模型不确定性的一部分。因此，如果仅笼统地对模型不确定性进行估计，其结果往往会给<code>分布外样本</code>带来过高地预测置信度。</p>
</div>
<p>举例来说，一个针对猫和狗训练的神经网络，在输入鸟的图像（ 即一个分布外样本 ）时，可能不会产生 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">50\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">50%</span></span></span></span> 狗和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">50\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">50%</span></span></span></span> 猫的类概率。因为神经网络从图像中提取的特征既不适合猫，也不适合狗，但可能相对更适合猫。如果不区分分布外样本，原始训练结果会很自信地将更多概率放在了猫上。</p>
<div class="note info flat"><p>注：这也是该文的主要出发点之一，即有效的分布外样本检测能力。</p>
</div>
<p>文献表明，<code>ReLu</code> 和 <code>softmax</code> 组合的神经网络，会使神经网络变得更加自信，因为分布外样本和训练集之间的差距会变得更大 <sup class="refplus-num"><a href="#ref-96">[96]</a></sup> 。<code>图 5</code> 显示了一个示例，其中 MNIST 的数字图像经过旋转后，产生了具有高 <code>softmax</code> 输出类概率的错误预测。 <code>Hein 等</code> 进一步研究了这种现象 <sup class="refplus-num"><a href="#ref-96">[96]</a></sup>， 提出了一种规避这种情况的方法，即在远离训练数据的区域强制使用均匀的<code>预测分布</code>。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220323231329-1a4e.webp" alt=""></p>
<blockquote>
<p><strong>图 5：从 MNIST 手写数字训练的 <code>LeNet</code> 网络得到的预测，在测试样本的不同旋转上进行评估</strong>。可以清楚地看到，对于某些旋转，由于混淆（例如：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn></mrow><annotation encoding="application/x-tex">8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8</span></span></span></span> 混淆）或在训练中未看到的表示，神经网络对错误分类给予了很高的置信度。此例说明分类网络在数据分布发生变化的情况下，会导致过度自信的错误预测。</p>
</blockquote>
<p>有几种方法 <sup class="refplus-num"><a href="#ref-44">[44]</a></sup><sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-94">[94]</a></sup><sup class="refplus-num"><a href="#ref-64">[64]</a></sup> 几乎一致地引入了 <code>logits</code> 的幅度值，但采用了 <code>Dirichlet 分布</code>。 <code>Dirichlet 分布</code> 是类别分布的共轭先验，可以被解释为类别分布上的分布。<code>Dirichlet 分布</code>的概率密度定义为：</p>
<div class="note info flat"><p>此处解释似乎有些问题：</p>
<p><code>Dirichlet 分布</code> 是连续型随机变量的概率密度，而 <code>类别分布（Catelogorical 分布）</code> 是离散型随机变量的概率质量，<code>当某个模型的似然为类别分布时，Dirichlet 分布为其共轭先验，因此可以得到后验的封闭形式解</code>。此处实际上是将确定性神经网络的输出视为服从 <code>类别分布</code> 的随机向量，而将 <code>Dirichlet 分布</code> 视为模型参数，通过贝叶斯方法在训练数据基础上推断得到其后验分布后，通过边缘化最终得出似然的概率分布。</p>
</div>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">Dir</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>μ</mi><mo>∣</mo><mi>α</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">Γ</mi><mrow><mo fence="true">(</mo><msub><mi>α</mi><mn>0</mn></msub><mo fence="true">)</mo></mrow></mrow><mrow><munderover><mo>∏</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi mathvariant="normal">Γ</mi><mrow><mo fence="true">(</mo><msub><mi>α</mi><mi>c</mi></msub><mo fence="true">)</mo></mrow></mrow></mfrac><munderover><mo>∏</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msubsup><mi>μ</mi><mi>c</mi><mrow><msub><mi>α</mi><mi>c</mi></msub><mo>−</mo><mn>1</mn></mrow></msubsup><mo separator="true">,</mo><mspace width="1em"></mspace><msub><mi>α</mi><mi>c</mi></msub><mo>&gt;</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>α</mi><mn>0</mn></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>c</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>α</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\operatorname{Dir}(\mu \mid \alpha)=\frac{\Gamma\left(\alpha_{0}\right)}{\prod_{c=1}^{K} \Gamma\left(\alpha_{c}\right)} \prod_{c=1}^{K} \mu_{c}^{\alpha_{c}-1}, \quad \alpha_{c}&gt;0, \alpha_{0}=\sum_{c=1}^{K} \alpha_{c}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">Dir</span></span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.1288em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">Γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1709em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.0037em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Γ</span></span></span></span> 是伽马函数，向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>α</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_1,...,\alpha_K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 被称为聚集参数，标量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">α_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 为精度。在实践中，聚集参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>α</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_1,...,\alpha_K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 通过对 <code>logits</code> 值应用严格的正变换（例如指数函数）得出。如 <code>图 6</code> 所示，较高的聚集参数值会导致更尖锐的 <code>Dirichlet 分布</code>。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220323231402-c633.webp" alt=""></p>
<blockquote>
<p><strong>图 6：<code>Dirichlet 分布</code> 在类别分布上的预期行为</strong>。</p>
<p>采用单纯形可视化显示了三个类别的三种可能的 <code>Dirichlet 分布</code>。单纯形的每个节点代表一个类别。在 (a) 中，接近上节点的尖锐 <code>Dirichlet 分布</code>，表示了对类别分布的某种倾向性预测。在 (b) 中，接近单纯形中心的尖锐 <code>Dirichlet 分布</code>，表示了比较高的数据不确定性，和较低的分布不确定性。在 © 中，一个平坦的 <code>Dirichlet 分布</code> 表明分布不确定性很高。</p>
</blockquote>
<p>在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 分类的类别分布中，所有类别概率的集合等价于一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 维的标准单纯形（因为所有类概率之和为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> ，剩下一个类的概率可以推算得出 ）。该单纯形中的每个点代表一个概率向量，而多个节点的任意（凸）组合代表了一个概率质量被分配到多个类上的类别分布。</p>
<p><code>Malinin 等</code> <sup class="refplus-num"><a href="#ref-32">[32]</a></sup> 认为，较高的模型不确定性应该导致较低的预测精度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\alpha_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 值，并因此导致整个单纯形上的平坦分布（<code>图 6c</code>），因为此时的神经网络其实对数据并不了解。与此相反， 数据不确定性应该由更清晰但也更集中的分布 ( 如 <code>图 6a</code> 和 <code>图 6b</code> ) 来表示，因为数据不确定性是神经网络能够学习和处理的，只是无法给出明确的类别偏好，<code>图 6</code> 显示了三种不同的预期行为。 <code>Dirichlet 分布</code> 可以用于多种方法，如 <code>先验神经网络</code> <sup class="refplus-num"><a href="#ref-43">[43]</a></sup><sup class="refplus-num"><a href="#ref-32">[32]</a></sup> 和 <code>证据神经网络</code> <sup class="refplus-num"><a href="#ref-97">[97]</a></sup><sup class="refplus-num"><a href="#ref-44">[44]</a></sup>。这两种神经网络都输出 <code>Dirichlet 分布</code> 的参数，从中可以推导出描述类概率的类别分布。</p>
<ul>
<li>
<p><strong>先验神经网络方法</strong></p>
<ul>
<li><code>先验神经网络</code> <sup class="refplus-num"><a href="#ref-32">[32]</a></sup> 的思想已经在上面进行了描述，并在 <code>图 6</code> 中进行了可视化。先验神经网络以多任务方式进行训练，目标是最小化： “分布内数据的预测分布和尖锐<code>Dirichlet 分布</code>之间的<code>预期 KL-散度</code>” 以及 “分布外数据的预测分布和平坦 <code>Dirichlet 分布</code>之间的<code>预期 KL-散度</code>” <sup class="refplus-num"><a href="#ref-32">[32]</a></sup>。其目的除了更好地分离分布内样本和分布外样本之外，还希望能够分离<strong>正确预测</strong>和<strong>错误预测</strong>的置信度，如 <sup class="refplus-num"><a href="#ref-98">[98]</a></sup> 所示。</li>
<li>作为后续，<sup class="refplus-num"><a href="#ref-94">[94]</a></sup> 讨论了数据不确定性很高的情况，其中有关 <code>KL-散度</code> 的扩展定义，可能会导致不希望的多峰目标分布。为了避免这种情况，他们使用 <code>逆 KL-散度</code> 重新计算损失。实验表明，在不确定性估计和对抗鲁棒性方面的结果有所改善。</li>
<li><code>Zhao 等</code> <sup class="refplus-num"><a href="#ref-99">[99]</a></sup> 通过一种新的损失函数扩展了 <code>Dirichlet</code> 神经网络方法，该损失函数旨在最小化基于 $$L_{\infty}$$ 范数的预期误差上界，即优化预期的最坏情况上界。</li>
<li><code>Wu 等</code> <sup class="refplus-num"><a href="#ref-34">[34]</a></sup> 认为，使用 <code>Dirichlet 分布</code> 的混合分布，会在后验分布的近似估计方面提供更大灵活性。因此，提出了一种用于预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 个 <code>Dirichlet 分布</code> 构成的混合分布参数的神经网络。为此，神经网络的 <code>logits</code> 输出用于表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个 <code>Dirichlet 分布</code> 的参数，并多出了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个待优化的权重 $$\omega_i$$ ，其约束条件为 $$\sum^M_{i=1} {\omega_i} = 1$$ 。</li>
<li><code>Nandy 等</code> <sup class="refplus-num"><a href="#ref-64">[64]</a></sup> 的分析表明，对于具有高数据不确定性的域内样本，根据错误预测结果得出的 <code>Dirichlet</code> 预测分布，通常比根据正确预测结果得出预测分布更平坦。他们认为，这使得区分分布内和分布外预测变得更加困难，并建议使用正则化项来最大化分布内和分布外样本之间的差距。</li>
</ul>
</li>
<li>
<p><strong>证据神经网络方法</strong></p>
<ul>
<li><code>证据神经网络</code> <sup class="refplus-num"><a href="#ref-44">[44]</a></sup> 优化了 <code>Dirichlet</code> 神经网络的参数化方案。损失公式通过主观逻辑得出，并将 <code>logits</code> 解释为多项的建议或信念，如 <code>证据理论</code> 或 <code>Dempster-Shafer 理论</code> <sup class="refplus-num"><a href="#ref-100">[100]</a></sup> 中所述。<code>证据神经网络</code> 根据类别数量来设置证据总量，并由此得出不确定性值。损失函数被表述为由 <code>logits</code> 参数化的 <code>Dirichlet 分布</code> 对应的基本损失期望值（例如：类交叉熵）。此外，还添加了一个正则化项，用于鼓励神经网络不要考虑同时为多个类提供证据的那些特征，例如一个圆圈可以同时证明 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">6</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn></mrow><annotation encoding="application/x-tex">8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8</span></span></span></span>。因此，<code>证据神经网络</code> 不区分数据不确定性和模型不确定性，而是学习它们是否能够给出一个确定性的预测。</li>
<li>
<sup class="refplus-num"><a href="#ref-33">[33]</a></sup> 通过区分证据中的敏锐度和不协调性来扩展了这一想法，以便更好地分离分布内和分布外的样本，为此，需要重叠类和分布外样本的两个显式数据集来学习正则化项。
</li>
<li><code>Amini 等</code> <sup class="refplus-num"><a href="#ref-101">[101]</a></sup> 通过学习在正态分布上的 <code>证据正态逆伽马分布</code> 参数，将证据神经网络的思想从分类任务迁移到回归任务。</li>
<li><code>Charpentier 等</code> <sup class="refplus-num"><a href="#ref-102">[102]</a></sup> 通过使用标准化流来学习每个类在潜在空间上的分布，避免了训练过程中对样本外数据的要求。一个新的输入样本被投影到这个潜在空间上，并根据接收到的潜在点的类别密度对 <code>Dirichlet 分布</code>进行参数化。</li>
</ul>
</li>
<li>
<p><strong>其他内蕴不确定估计方法</strong></p>
<ul>
<li>
<sup class="refplus-num"><a href="#ref-68">[68]</a></sup> 提出了一种对训练输入数据实施扰动的方法，采用温度尺度校准来有效区分分布内和分布外的样本。
</li>
<li><code>Mozejko 等</code> <sup class="refplus-num"><a href="#ref-92">[92]</a></sup> 利用了 <code>inhibited softmax</code> 函数。它包含一个人工指定的恒定 <code>logit</code>，使单个 <code>logit</code> 的绝对幅度在 <code>softmax</code> 输出中更具判决性。</li>
<li><code>Van Amersfoort 等</code> <sup class="refplus-num"><a href="#ref-35">[35]</a></sup> 表明径向基函数 (RBF) 神经网络可用于在准确性和不确定性估计方面取得非常好的结果。径向基函数神经网络在 <code>logits</code> 上学习一个线性变换，并根据（变换后的）<code>logits</code> 与（学习得到的）<code>类质心</code>之间的距离对输入进行分类，<sup class="refplus-num"><a href="#ref-35">[35]</a></sup> 使用了一个缩放指数化的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 距离。 数据不确定性可以直接从不同类质心之间的距离得出。通过在损失函数中包含对<code>雅可比矩阵</code>的惩罚，神经网络被训练为对输入空间的变化更加敏感。结果，该方法在分布外检测方面取得了良好的性能。在几次测试中，将该方法与具有五个弱学习器的深度集成方法 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup> 进行了比较，结果表明，这种单一神经网络方法在检测分布外样本方面表现相当甚至更好，并提高了真阳性率。</li>
</ul>
</li>
</ul>
<p><strong>（2） 回归任务</strong></p>
<p>对于回归任务来说：</p>
<ul>
<li>
<p><code>Oala 等</code> <sup class="refplus-num"><a href="#ref-93">[93]</a></sup> 引入了<code>区间神经网络</code>，根据网络输出的下限和上限，设计了不确定性的打分规则。<code>区间神经网络</code>与底层的确定性神经网络具有相同结构，并使用确定性神经网络的权重进行初始化。与通过高斯标准差来表示不确定性的方法相比，此方法可以给出不确定性的非对称结果。此外，该方法在噪声情况下更加稳健。</p>
</li>
<li>
<p><code>Tagasovska 和 Lopez-Paz</code> <sup class="refplus-num"><a href="#ref-103">[103]</a></sup> 提出了一种估计数据不确定性和模型不确定性的方法。引入了联立分位数回归损失函数，以便为数据不确定性生成经过良好校准的预测区间。模型不确定性则是基于从训练数据到零的映射来估计的（基于其所谓的<code>正交证书</code>）。其目的是将导致模型不确定性的分布外样本，映射到可以被识别的非零值。</p>
</li>
<li>
<p><code>Kawashima 等</code> <sup class="refplus-num"><a href="#ref-104">[104]</a></sup> 引入了一种类似交叉验证的预训练步骤，来计算回归任务的训练样本中的虚拟残差。利用这些残差信息对原始训练数据进行扩展后，再训练实际的预测器，以给出预测和确定性值。实验表明，虚拟残差是一种很有前途的工具，可以避免过度自信的神经网络预测。</p>
</li>
</ul>
<h4 id="3-1-2-外接不确定性估计法">3.1.2 外接不确定性估计法</h4>
<p>外接不确定性估计方法不会影响模型的预测，因为不确定性的估计与潜在的预测任务是分开的。因此，可以同时在已经训练好的神经网络上应用多种外部方法，而且相互之间不会影响。<code>Raghu 等</code> <sup class="refplus-num"><a href="#ref-46">[46]</a></sup> 认为，当预测和不确定性估计这两个任务都通过单一方法完成时，不确定性估计会受到实际预测任务的偏差影响。因此，他们推荐一种 <code>直接不确定性预测</code> 方法，建议训练两个神经网络，一个用于实际预测任务，另一个用于预测上一个神经网络的预测不确定性。</p>
<p>同样，<code>Ramalho 和 Miranda</code> <sup class="refplus-num"><a href="#ref-36">[36]</a></sup> 引入了一个额外的神经网络来进行不确定性估计。但与 <sup class="refplus-num"><a href="#ref-46">[46]</a></sup> 相比，考虑了训练数据的表示空间，并估计了其中测试样本点周边的密度，然后将该密度用于附加的神经网络，以预测主神经网络的估计是否正确。</p>
<p><code>Hsu 等</code> <sup class="refplus-num"><a href="#ref-105">[105]</a></sup> 在测试时计算了每个类的<code>总概率</code>，并结合 <code>softmax</code> 输出的类别分布，用以检测分类任务中的分布外样本。每个类的<code>总概率</code>计算，来自于对神经网络输出中该类的 <code>logits</code> 应用 <code>sigmoid</code> 函数。基于这些总概率，分布外样本可以通过 “所有类别的类概率都较低” 来识别。</p>
<p><code>Oberdiek 等</code> <sup class="refplus-num"><a href="#ref-71">[71]</a></sup> 在分类任务中考虑了模型的敏感性（如梯度），并且使用梯度指标来估计不确定性。<code>Li 等</code> <sup class="refplus-num"><a href="#ref-72">[72]</a></sup> 应用了类似想法，但利用了反向传播梯度，他们在分布外输入和损坏输入的检测方面，展示出了最先进的结果。</p>
<blockquote>
<p><strong>表 2：内部和外部单一确定性网络方法的性质概览</strong>。有关单一确定性网络方法与贝叶斯神经网络方法、集成方法和测试时增强方法的比较，请参见<code>表 1</code></p>
</blockquote>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220324073943-4d47.webp" alt=""></p>
<h4 id="3-1-3-小结">3.1.3 小结</h4>
<p>与许多其他方法相比，单一确定性方法在训练和评估中具有比较好的计算效率。对于训练，只需要训练一个神经网络，而且这些方法通常可以应用于预训练的神经网络。根据实际方法，只需完成一次或最多两次前向传递即可得到预测不确定性的估计。底层神经网络可能会包含更复杂的损失函数，从而减慢训练过程 <sup class="refplus-num"><a href="#ref-44">[44]</a></sup> ；或者必须附加的训练和评估组件 <sup class="refplus-num"><a href="#ref-46">[46]</a></sup>。但总的来说，单一确定性方法仍然比基于贝叶斯方法（<code>第 3.2 节</code>）、集成方法（<code>第 3.3 节</code>）和测试时数据增强方法（<code>第 3.4 节</code>）更有效率。单一确定性神经网络方法的缺点是：它们仅依赖于来自单一网络的建议，而无法像集成方法那样得到多个模型的建议，因此会对底层神经网络架构、训练过程和训练数据等比较敏感。</p>
<h3 id="3-2-贝叶斯神经网络方法">3.2 贝叶斯神经网络方法</h3>
<p>贝叶斯神经网络 (BNN) <sup class="refplus-num"><a href="#ref-106">[106]</a></sup><sup class="refplus-num"><a href="#ref-107">[107]</a></sup><sup class="refplus-num"><a href="#ref-108">[108]</a></sup> 能够将神经网络的可扩展性、表达性、预测性能等优势与贝叶斯学习相结合，而不是仅仅通过最大似然原理学习模型参数的点估计。这种能力与传统贝叶斯方法类似，是通过推断神经网络参数（或权重） <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>w</mi><mi>K</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\theta = (w_1,...,w_K)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 上的概率分布来实现的。</p>
<p>更具体地说，给定一个训练输入/目标对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>，参数空间上的后验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 在假设参数上的先验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 基础上建模，并依据贝叶斯定理，根据数据信息更新后验分布：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mtext> </mtext><mo>∝</mo><mtext> </mtext><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(16)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(\theta \mid x,y) = \frac{p(y \mid x,\theta)p(\theta)}{p(y \mid x)} \, \propto \, p(y \mid x,\theta)p(\theta) \tag{16}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">16</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><code>式 16</code> 中分母的归一化常数项 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y \mid x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 被称为模型的证据，被定义为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∫</mo><msub><mi mathvariant="normal">Θ</mi><mrow><mi>p</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi></mrow></msub></msub><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>d</mi><mi>θ</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(17)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(y \mid x) = \int_{\Theta_{prior}}  p(y \mid x,\theta)p(\theta)d\theta \tag{17}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4693em;vertical-align:-1.1093em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.4336em;"><span style="top:-1.7881em;margin-left:-0.4445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">Θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">or</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1093em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span class="tag"><span class="strut" style="height:2.4693em;vertical-align:-1.1093em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">17</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>一旦得到了模型参数的后验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> ，就可以利用 <code>贝叶斯模型平均</code> 或 <code>全贝叶斯分析</code>，通过对似然 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y \mid x,\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 实施后验分布的边缘化，来获得新输入数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">x^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> 对应的预测结果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">y^\ast</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8831em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span> ：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∫</mo><msub><mi mathvariant="normal">Θ</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi></mrow></msub></msub><mi>p</mi><mo stretchy="false">(</mo><msup><mi>y</mi><mo>∗</mo></msup><mo>∣</mo><msup><mi>x</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mi>d</mi><mi>θ</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(18)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(y^\ast \mid x^\ast,x,y) = \int_{\Theta_{posterior}} p(y^\ast \mid x^\ast, \theta)p(\theta \mid x,y) d\theta \tag{18}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4693em;vertical-align:-1.1093em;"></span><span class="mop"><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em;">∫</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:-0.4336em;"><span style="top:-1.7881em;margin-left:-0.4445em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mtight">Θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">er</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">or</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1093em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span class="tag"><span class="strut" style="height:2.4693em;vertical-align:-1.1093em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">18</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>这种贝叶斯预测方式是总概率法则的直接应用，并从原理上赋予了计算 <code>预测不确定性</code> 的能力。 <code>式 (18)</code> 中的积分对于一般的先验（用于先验预测检查）或后验（用于预测分布）通常是难以处理的，因此会使用近似技术。其中应用最广泛的近似方法为 <code>蒙特卡洛近似</code>，该方法遵循大数定律，从后验分布中抽取 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个模型参数（即权重）的样本 $$\theta_1,\theta_2 ,…,\theta_N$$ ，然后计算其对应的确定性神经网络输出样本 $$f_{\theta_1},…,f_{\theta_N}$$ ，最后用这些输出样本的均值，来近似期望的预测输出值，即：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msup><mi>y</mi><mo>∗</mo></msup><mo>≈</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msubsup><mi>y</mi><mi>i</mi><mo>∗</mo></msubsup><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><msub><mi>f</mi><msub><mi>θ</mi><mi>i</mi></msub></msub><mo stretchy="false">(</mo><msup><mi>x</mi><mo>∗</mo></msup><mo stretchy="false">)</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(19)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">y^\ast \approx \frac{1}{N}\sum_{i=1}^N {y^\ast_i} = \frac{1}{N}\sum_{i=1}^N
{f_{\theta_i} (x^\ast)} \tag{19}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9331em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2501em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7387em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span><span class="tag"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">19</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><code>Wilson 和 Izmailov</code> <sup class="refplus-num"><a href="#ref-16">[16]</a></sup> 认为 BNN 的一个关键优势就在于这种边缘化步骤，这尤其可以同时提高现代深度神经网络的<code>准确性（accuracy）</code>和<code>校准（calibration）</code>。我们注意到，BNN 的应用不仅限于不确定性估计，还开辟了在深度学习中连接强大贝叶斯工具箱的可能性。其中值得关注的例子包括：<code>贝叶斯模型选择</code> <sup class="refplus-num"><a href="#ref-109">[109]</a></sup><sup class="refplus-num"><a href="#ref-110">[110]</a></sup><sup class="refplus-num"><a href="#ref-111">[111]</a></sup><sup class="refplus-num"><a href="#ref-112">[112]</a></sup>、<code>模型压缩</code> <sup class="refplus-num"><a href="#ref-76">[76]</a></sup><sup class="refplus-num"><a href="#ref-113">[113]</a></sup><sup class="refplus-num"><a href="#ref-114">[114]</a></sup>、<code>主动学习</code> <sup class="refplus-num"><a href="#ref-115">[115]</a></sup><sup class="refplus-num"><a href="#ref-23">[23]</a></sup><sup class="refplus-num"><a href="#ref-116">[116]</a></sup>、<code>持续学习</code> <sup class="refplus-num"><a href="#ref-117">[117]</a></sup><sup class="refplus-num"><a href="#ref-118">[118]</a></sup><sup class="refplus-num"><a href="#ref-119">[119]</a></sup><sup class="refplus-num"><a href="#ref-120">[120]</a></sup>、<code>贝叶斯学习</code> <sup class="refplus-num"><a href="#ref-121">[121]</a></sup> 及其他方面的理论进展。</p>
<div class="note info flat"><p><code>准确性（accuracy）</code> 的定义参见机器学习书籍。<code>校准（calibration）</code>的定义参见 <code>第 5 节 对预测置信度进行校准</code>。</p>
</div>
<p>该公式虽然相当简单，但在实现上存在一些挑战性。例如，后验推断通常不存在封闭形式解，因为对于神经网络之类的复杂模型，基本上不存在共轭先验 <sup class="refplus-num"><a href="#ref-62">[62]</a></sup>，只能采用近似贝叶斯推断技术来得到后验分布的近似解。然而，直接在深度神经网络场景中使用近似贝叶斯推断技术已被证明是困难的，因为样本量和参数数量太大了。换句话说，随着样本量和参数数量的增加，上述公式中的积分项在计算上是 <code>untractable</code> 的。此外，为深度神经网络指定一个有意义的先验，也是一个巨大挑战。</p>
<p>在本次调研中，我们按照后验分布的推断方法，将 BNN 分为三种类型：</p>
<ul>
<li>
<p><strong>变分推断</strong> <sup class="refplus-num"><a href="#ref-73">[73]</a></sup><sup class="refplus-num"><a href="#ref-74">[74]</a></sup> 。变分推断方法通过对一个易处理分布的分布族进行优化，来估计复杂的后验分布（ 通常是 <code>untractable</code> 的 ）。</p>
</li>
<li>
<p><strong>采样方法</strong> <sup class="refplus-num"><a href="#ref-78">[78]</a></sup> 。采样方法提供了目标随机变量（ 即模型参数或权重 ）的一种离散化表示，从中可以进一步得到预测输出的样本。此类方法大多基于<code>马尔柯夫链蒙特卡洛（ MCMC ）</code> 及其扩展。</p>
</li>
<li>
<p><strong>拉普拉斯近似</strong> <sup class="refplus-num"><a href="#ref-122">[122]</a></sup><sup class="refplus-num"><a href="#ref-123">[123]</a></sup> 。该方法通过近似 <code>对数后验分布</code> 来简化目标分布的表示，在此近似基础上，得出神经网络权重的正态分布。</p>
</li>
</ul>
<p>虽然本文将范围限制在了上述三个类别，但我们也承认 BNN 领域的一些最新进展。其中包括：</p>
<ul>
<li>
<p>最新的推断技术，例如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 散度 <sup class="refplus-num"><a href="#ref-124">[124]</a></sup><sup class="refplus-num"><a href="#ref-125">[125]</a></sup><sup class="refplus-num"><a href="#ref-126">[126]</a></sup>、期望传播 <sup class="refplus-num"><a href="#ref-127">[127]</a></sup><sup class="refplus-num"><a href="#ref-128">[128]</a></sup>、假设密度滤波 <sup class="refplus-num"><a href="#ref-129">[129]</a></sup> 等</p>
</li>
<li>
<p>利用现代图形处理单元 (GPU) 的概率编程 <sup class="refplus-num"><a href="#ref-130">[130]</a></sup><sup class="refplus-num"><a href="#ref-131">[131]</a></sup><sup class="refplus-num"><a href="#ref-132">[132]</a></sup><sup class="refplus-num"><a href="#ref-133">[133]</a></sup></p>
</li>
<li>
<p>不同类型的先验尝试 <sup class="refplus-num"><a href="#ref-134">[134]</a></sup><sup class="refplus-num"><a href="#ref-135">[135]</a></sup></p>
</li>
<li>
<p>BNN 理论的进步 <sup class="refplus-num"><a href="#ref-136">[136]</a></sup><sup class="refplus-num"><a href="#ref-121">[121]</a></sup><sup class="refplus-num"><a href="#ref-137">[137]</a></sup></p>
</li>
<li>
<p>不确定性的传播技术，以加快边缘化计算过程 <sup class="refplus-num"><a href="#ref-138">[138]</a></sup></p>
</li>
<li>
<p>偶然不确定性的计算 <sup class="refplus-num"><a href="#ref-139">[139]</a></sup><sup class="refplus-num"><a href="#ref-140">[140]</a></sup><sup class="refplus-num"><a href="#ref-141">[141]</a></sup></p>
</li>
</ul>
<h4 id="3-2-1-变分推断">3.2.1 变分推断</h4>
<p><strong>（1） 变分推断概述</strong></p>
<p>变分推断的目标是：使用预先指定的可处理分布族 $$q_\phi(\theta)$$ 来近似并推断后验概率 $$p(\theta \mid x,y)$$。这些所谓的可处理分布族 $$q_\phi(\theta)$$ 被称为变分分布，由 $$\phi$$ 参数化，并通过优化方法得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span> 的最优解，进而得到参数后验分布的近似解。</p>
<p>以多元正态分布作为变分分布（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mi>μ</mi><mo separator="true">,</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q_\phi(\theta) = \mathcal{N}(\mu,\Sigma)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Σ</span><span class="mclose">)</span></span></span></span> ）为例，参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span> 由均值（ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span> ）和协方差矩阵 ( <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Σ</span></span></span></span> ）构成。在此设置下，变分推断的主要思想就是找到使  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mi>μ</mi><mo separator="true">,</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(\mu,\Sigma)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Σ</span><span class="mclose">)</span></span></span></span>  最接近后验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 时的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo separator="true">,</mo><mi mathvariant="normal">Σ</mi></mrow><annotation encoding="application/x-tex">\mu,\Sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Σ</span></span></span></span> 值。变分推断将原本复杂的后验估计问题转换成了对变分分布参数的最优化问题，大大地推动了近似推断技术的发展。</p>
<p>信息论中的 <code>Kullback-Leibler (KL) 散度</code> 给出了概率分布之间的接近程度的测度，理论上可以用做上述优化过程的目标函数：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mrow><mi mathvariant="normal">K</mi><mi mathvariant="normal">L</mi></mrow><mo stretchy="false">(</mo><mi>q</mi><mi mathvariant="normal">∥</mi><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mi>q</mi></msub><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">]</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(20)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathrm{KL}(q \| p)=\mathbb{E}_{q}\left[\log \frac{q(\theta)}{p(\theta \mid x, y)}\right] \tag{20}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathrm">KL</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mord">∥</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span><span class="tag"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">20</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>但 <code>KL 散度</code> 的公式中仍然要处理后验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>，因此实际上无法直接用作目标函数。于是有人提出了一个可以作为目标函数，且等效于 <code>KL 散度</code> 的测度 ： <code>证据下界 (ELBO)</code> 。对于模型参数上的给定先验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> ，<code>ELBO</code> 由下式给出：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>L</mi><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mi>q</mi></msub><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>q</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">]</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(21)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">L=\mathbb{E}_{q}\left[\log \frac{p(y \mid x, \theta)}{q(\theta)}\right] \tag{21}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span><span class="tag"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">21</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>对于 <code>KL 散度</code>，下式成立：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><mi>q</mi><mo>∣</mo><mo>∣</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>L</mi><mo>+</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(22)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">KL(q \mid \mid p) = -L + log p(y \mid x) \tag{22}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">22</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><code>Hinton 和 Van Camp</code> <sup class="refplus-num"><a href="#ref-73">[73]</a></sup> 开创了 BNN 的变分方法，其中作者推导出了神经网络后验分布的一种对角高斯的近似（ 在信息论中表述为 <code>最小描述长度</code> ）。 <code>Barber 和 Bishop</code> <sup class="refplus-num"><a href="#ref-74">[74]</a></sup> 在 1990 年代提出了另一个值得注意的扩展，他们选择全协方差矩阵作为变分族，进而改进了 <code>Hinton 等</code> 方法中模型参数必须相互独立的假设（ 因为现代神经网络中，权重之间大多具有一定相关性 ），作者演示了如何针对神经网络优化 <code>ELBO</code>。几种现代方法可以被视为这些早期成果的扩展，主要聚焦在如何将变分推断扩展到现代神经网络。</p>
<p><strong>（2） 随机变分推断（ SVI ）</strong></p>
<p>当前方法的一个明显方向是使用随机变分推断（ 或蒙特卡罗变分推断 ），可以使用小批量数据执行 <code>ELBO 优化</code>。 <code>Graves 等</code> <sup class="refplus-num"><a href="#ref-75">[75]</a></sup> 首先提出了采用高斯先验的随机变分推断方法。 2015 年，<code>Blundell 等</code> <sup class="refplus-num"><a href="#ref-30">[30]</a></sup> 引入了 <code>反向传播贝叶斯（ Bayes By Backprop ）</code>，将随机变分推断扩展到了<code>非高斯先验</code>，并展示了如何通过 <code>打分函数估计</code> 使随机梯度无偏。</p>
<p><code>Kingma 等</code> <sup class="refplus-num"><a href="#ref-142">[142]</a></sup> 引入了局部重参数化技巧以减少随机梯度的方差，其关键作用是能够将神经网络的损失函数重新表述为 <code>ELBO</code>，使得难以处理的后验分布被间接优化，并且变分推断与神经网络的反向传播过程兼容。</p>
<div class="note info flat"><p>在随机变分推断方法中，小批量随机梯度估计存在方差较大的问题，为提升梯度下降速度，需要开发出减少方差的方法，其中比较典型的有：<code>打分函数估计器</code> 和 <code>重参数化技巧</code>。参见 <a href="42400.html#4-2-%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD%E6%96%B9%E6%B3%95%E4%B8%8E%E6%A2%AF%E5%BA%A6%E4%BC%B0%E8%AE%A1">《贝叶斯神经网络技术浅析》的第 4.2 节</a></p>
</div>
<p>上述这些扩展广泛关注随机变分推断的脆弱性，这些脆弱性主要由于对初始化、先验定义和梯度方差的敏感性而引起。<code>Wu 等</code>最近使用分层先验解决了这些限制 <sup class="refplus-num"><a href="#ref-143">[143]</a></sup>，并且变分分布的矩是确定性近似得出的。</p>
<p>上述工作通常将平均场近似假设为变分族，忽略了参数之间的相关性。为了使深度神经网络能够具备更有表现力的变分分布，一些工作建议使用<code>矩阵正态分布</code> <sup class="refplus-num"><a href="#ref-144">[144]</a></sup><sup class="refplus-num"><a href="#ref-145">[145]</a></sup><sup class="refplus-num"><a href="#ref-146">[146]</a></sup> 或更具表现力的变体 <sup class="refplus-num"><a href="#ref-147">[147]</a></sup><sup class="refplus-num"><a href="#ref-148">[148]</a></sup> ，其中<code>协方差矩阵</code>被分解为低秩形式加上正对角矩阵，或者较小矩阵的 <code>Kronecker 积</code>。</p>
<p>对表达后验分布的一个显著进展是使用归一化流 <sup class="refplus-num"><a href="#ref-77">[77]</a></sup><sup class="refplus-num"><a href="#ref-149">[149]</a></sup> - 一种分层的概率分布，其中应用了一系列可逆变换，以将简单的初始密度函数转换为更复杂的分布。</p>
<p><code>Farquhar 等</code> <sup class="refplus-num"><a href="#ref-137">[137]</a></sup> 认为平均场近似不是一个限制性假设，并且逐层权重相关性可能不如捕获深度相关性重要。 <code>Farquhar 等</code>主张可能仍然是一个悬而未决的问题，平均场近似在较小的计算复杂度上具有优势。例如，<code>Osawa 等</code> <sup class="refplus-num"><a href="#ref-150">[150]</a></sup> 证明了变分推断可以使用多个 GPU 扩展到 ImageNet 大小的数据集和架构，并提出了诸如数据增强、动量初始化和学习率调度等实用技巧。</p>
<p>变分方法的后来者将深度学习的随机元素（ 如 Dropout ）转换为了变分推断 。其中广为人知的例子是 <code>蒙特卡洛 Dropout (MC Dropout)</code>，其中 Dropout 层被表述为服从伯努利分布的随机变量，训练具有 Dropout 层的神经网络可以近似为执行了变分推断 <sup class="refplus-num"><a href="#ref-61">[61]</a></sup><sup class="refplus-num"><a href="#ref-20">[20]</a></sup><sup class="refplus-num"><a href="#ref-151">[151]</a></sup>。 <code>MC Dropout</code> 的最大好处是<code>预测不确定性</code>可以通过激活 Dropout 来计算，不仅在训练期间，而且在测试阶段。通过这种方式，只要神经网络经过 Dropout 层的训练，实现工作就可以保持在最低工作量，并且不需要使用者具备专家级的知识来推断不确定性 <sup class="refplus-num"><a href="#ref-20">[20]</a></sup>。此方法的实用价值在其几个成果 <sup class="refplus-num"><a href="#ref-152">[152]</a></sup><sup class="refplus-num"><a href="#ref-10">[10]</a></sup><sup class="refplus-num"><a href="#ref-21">[21]</a></sup> 中得到了证明，并导致了不同扩展（ 评估不同 Dropout 掩码的使用，例如卷积层 <sup class="refplus-num"><a href="#ref-153">[153]</a></sup> 或通过将预测不确定性的表示分解为模型不确定性和数据不确定性 <sup class="refplus-num"><a href="#ref-60">[60]</a></sup>）。</p>
<p>在文献 <sup class="refplus-num"><a href="#ref-37">[37]</a></sup> 中也提出了类似想法，但随机丢弃的是传入节点的激活，而不是所有后续节点的激活，并将其称为<code>丢弃连接（ Drop Connect ）</code>。该工作发现这在不确定性表示上更加稳健，尽管有结果表明两者组合可以产生更高的预测准确性和稳健性 <sup class="refplus-num"><a href="#ref-154">[154]</a></sup>。</p>
<p>最后，部分文献进一步建立了变分推断与 <code>Adam</code> <sup class="refplus-num"><a href="#ref-155">[155]</a></sup>、<code>RMS Prop</code> <sup class="refplus-num"><a href="#ref-156">[156]</a></sup> 和<code>批量归一化</code> <sup class="refplus-num"><a href="#ref-157">[157]</a></sup> 的联系。</p>
<h4 id="3-2-2-采样方法">3.2.2 采样方法</h4>
<p>采样方法（也称蒙特卡洛方法）是另一类贝叶斯推断算法，它不需要像变分推断中那样的参数化变分分布来表示不确定性。具体来说，采样方法使用从分布中抽取的一组样本来做推断，其优势是不受分布类型的限制（例如可以是多峰值高斯或非高斯分布），而且不需要参数化假设，也就是说，概率分布通过非参数方法获得的。该领域内的流行算法是<code>粒子滤波</code>、<code>拒绝采样</code>、<code>重要性采样</code>和<code>马尔可夫链蒙特卡罗采样 (MCMC)</code> <sup class="refplus-num"><a href="#ref-62">[62]</a></sup>。</p>
<p>在神经网络的场景中，通常使用 MCMC ，因为已有的拒绝采样、重要性采样等方法对于高维问题存在效率低下的缺陷。 MCMC 的主要思想是：<code>通过在状态空间中的转移，从任意分布中采样</code>。这种转移由<code>当前状态记录</code>和（ 旨在估计目标分布的 ）<code>提议分布</code>控制。为了解释这一点，让我们定义马尔可夫链：</p>
<p>马尔可夫链是随机变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo separator="true">⋅</mo><mo separator="true">⋅</mo><mo separator="true">⋅</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">x_1,··· ,x_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,⋅⋅⋅,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 上的一个联合分布，它遵循如下状态转移规则：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>T</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>2</mn></mrow><mi>T</mi></munderover><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>∣</mo><msub><mi>x</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(23)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(x_1,\ldots ,x_T) = p(x_1)\prod_{t=2}^{T}p(x_t \mid x_{t-1})\tag{23}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">23</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>即下一个状态仅取决于当前状态，而不取决于任何其他的先前状态。为了从真实后验中抽取样本，MCMC 采样方法首先以马尔可夫链方式迭代地生成样本；在每次迭代中，由算法按照某种规则的接受概率来决定接受还是拒绝该样本；这样迭代下去，随着产生越来越多的样本，它们的值逐步逼近目标分布。</p>
<p><code>Hamiltonian Monte Carlo</code> 或 <code>Hybrid Monte Carlo (HMC)</code> <sup class="refplus-num"><a href="#ref-158">[158]</a></sup> 是 MCMC 采样方法最重要的变体（由 <code>Neals</code> 为神经网络引入 <sup class="refplus-num"><a href="#ref-78">[78]</a></sup><sup class="refplus-num"><a href="#ref-79">[79]</a></sup><sup class="refplus-num"><a href="#ref-80">[80]</a></sup><sup class="refplus-num"><a href="#ref-159">[159]</a></sup> ），通常被称为黄金贝叶斯推断标准<sup class="refplus-num"><a href="#ref-159">[159]</a></sup><sup class="refplus-num"><a href="#ref-160">[160]</a></sup><sup class="refplus-num"><a href="#ref-125">[125]</a></sup>。</p>
<p>该算法的工作原理如下：</p>
<p>（1）首先随机或以用户指定的方式初始化一组参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 。</p>
<p>对于给定的总迭代次数：</p>
<p>（2）对动量向量（ 一个辅助变量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi></mrow><annotation encoding="application/x-tex">\rho</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ρ</span></span></span></span> ） 进行采样，并通过汉密尔顿动力学更新参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 的当前值：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>ρ</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>ρ</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>ρ</mi><mo>∣</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(\rho, \theta)=-\log p(\rho, \theta)=-\log p(\rho \mid \theta)-\log p(\theta)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord mathnormal">ρ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">ρ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">ρ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span></p>
<p>定义势能 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>V</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(V (\theta)) = -\log p(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 和动能 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>ρ</mi><mo>∣</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>ρ</mi><mo>∣</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(\rho \mid \theta) = - \log p(\rho \mid \theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathnormal">ρ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">ρ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>，通过 <code>Hamilton</code> 方程的更新步骤由下式控制：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>d</mi><mi>θ</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>ρ</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>T</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>ρ</mi></mrow></mfrac><mtext>&nbsp;and&nbsp;</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>d</mi><mi>ρ</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo>−</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>H</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>θ</mi></mrow></mfrac><mo>=</mo><mo>−</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>T</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>θ</mi></mrow></mfrac><mo>−</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>V</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>θ</mi></mrow></mfrac><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\frac{d \theta}{d t} &amp;=\frac{\partial H}{\partial \rho}=\frac{\partial T}{\partial \rho} \text { and } \\
\frac{d \rho}{d t} &amp;=-\frac{\partial H}{\partial \theta}=-\frac{\partial T}{\partial \theta}-\frac{\partial V}{\partial \theta} .
\end{aligned}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.9093em;vertical-align:-2.2047em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.7047em;"><span style="top:-4.7047em;"><span class="pstrut" style="height:3.3714em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.1528em;"><span class="pstrut" style="height:3.3714em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal">ρ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.2047em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.7047em;"><span style="top:-4.7047em;"><span class="pstrut" style="height:3.3714em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">ρ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal">ρ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord text"><span class="mord">&nbsp;and&nbsp;</span></span></span></span><span style="top:-2.1528em;"><span class="pstrut" style="height:3.3714em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">.</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.2047em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>采用 <code>Leapfrog</code> 积分器作为求解器<sup class="refplus-num"><a href="#ref-161">[161]</a></sup>。</p>
<p>(3) 对于每一步，应用 <code>Metropolis</code> 接受准则来拒绝或接受样品（ 类似于 MCMC ）。</p>
<p>不幸的是，HMC 需要每次迭代处理整个数据集，当数据集规模增长到数百万甚至数十亿时，这在计算上过于昂贵了。因此，许多现代算法专注于如何以小批量方式随机执行计算。</p>
<p>在此背景下，<code>Welling 和 Teh</code> <sup class="refplus-num"><a href="#ref-81">[81]</a></sup> 首次提出将<code>随机梯度下降 (SGD) </code>与 <code>Langevin 动力学</code>（ MCMC <sup class="refplus-num"><a href="#ref-162">[162]</a></sup><sup class="refplus-num"><a href="#ref-163">[163]</a></sup><sup class="refplus-num"><a href="#ref-159">[159]</a></sup> 的一种形式 ）相结合，以获得基于小批量 SGD <sup class="refplus-num"><a href="#ref-164">[164]</a></sup><sup class="refplus-num"><a href="#ref-165">[165]</a></sup> 的可扩展 MCMC 算法。该工作表明，在深度神经网络上执行贝叶斯推断可以像运行 SGD 一样简单。该方法不包含 HMC 的动量项，而是采用一阶朗之万动力学，并且就此开辟了<code>随机梯度马尔可夫链蒙特卡罗（SG-MCMC）</code>的新研究领域。</p>
<p>因此出现有几个可用的扩展，包括（a）使用二阶信息，例如使用 <code>Fisher 信息矩阵 (FIM)</code> <sup class="refplus-num"><a href="#ref-166">[166]</a></sup><sup class="refplus-num"><a href="#ref-167">[167]</a></sup><sup class="refplus-num"><a href="#ref-168">[168]</a></sup>、<code>Hessian</code> <sup class="refplus-num"><a href="#ref-169">[169]</a></sup><sup class="refplus-num"><a href="#ref-170">[170]</a></sup><sup class="refplus-num"><a href="#ref-171">[171]</a></sup> 进行预处理和优化；（b）自适应<code>预处理对角线矩阵</code> <sup class="refplus-num"><a href="#ref-172">[172]</a></sup>；（c）使用 <code>Fisher 评分</code> <sup class="refplus-num"><a href="#ref-173">[173]</a></sup> 从非各向同性目标密度中生成样本；（d）在黎曼流形 <sup class="refplus-num"><a href="#ref-174">[174]</a></sup> 中使用一阶朗之万动力学和 Levy 散射噪声和动量的采样器 <sup class="refplus-num"><a href="#ref-175">[175]</a></sup>。这些方法使用了<code>参数依赖扩散矩阵</code>，以抵消梯度的随机扰动。为此，提出了一种 “恒温器” 概念 <sup class="refplus-num"><a href="#ref-176">[176]</a></sup><sup class="refplus-num"><a href="#ref-177">[177]</a></sup><sup class="refplus-num"><a href="#ref-178">[178]</a></sup>，以便与参数相关的噪声能够保持指定的恒定温度分布。</p>
<p><code>Ahn 等</code> <sup class="refplus-num"><a href="#ref-179">[179]</a></sup> 为 SG-MCMC 设计了一个分布式计算系统，以利用现代计算程序。 <code>Wang 等</code> <sup class="refplus-num"><a href="#ref-180">[180]</a></sup> 表明生成对抗模型 (GAN) 可以为了提高内存效率而用于提炼样本，而不是为了增强计算预测不确定性的运行时能力而进行提炼 <sup class="refplus-num"><a href="#ref-181">[181]</a></sup>。最后，其他最近的趋势是减少随机梯度引起的方差 <sup class="refplus-num"><a href="#ref-160">[160]</a></sup><sup class="refplus-num"><a href="#ref-182">[182]</a></sup> 和偏差 <sup class="refplus-num"><a href="#ref-183">[183]</a></sup><sup class="refplus-num"><a href="#ref-184">[184]</a></sup>。</p>
<p>同时，<code>SG-MCMC 方法</code>的理论及其在实践中的应用取得了扎实的进展。 <code>Sato 和 Nakagawa</code> <sup class="refplus-num"><a href="#ref-185">[185]</a></sup> 首次表明，具有恒定步长的 <code>SGLD 算法</code>收敛较弱；Chen 等 <sup class="refplus-num"><a href="#ref-186">[186]</a></sup> 表明，对于具有更高阶积分器而不是一阶欧拉积分器的 <code>SG-MCMC</code>，可以观察到更快的收敛速度和更准确的不变测度，而 <code>Teh 等</code> <sup class="refplus-num"><a href="#ref-187">[187]</a></sup> 研究了 <code>SGLD</code> 的一致性和波动性。作为结果，发现了服从中心极限定理的可验证条件（ 其算法是一致的 ），并探讨了渐进的<code>偏差-方差</code>分解如何取决于步长序列的问题。在 <code>Nemeth 和 Fearnhead</code> <sup class="refplus-num"><a href="#ref-82">[82]</a></sup> 中可以找到对 <code>SG-MCMC</code> 的更详细的回顾，特别是理论结果。实际上，<code>SG-MCMC</code> 技术已应用于形状分类和不确定性估计 <sup class="refplus-num"><a href="#ref-188">[188]</a></sup>、调温后验（或称为冷后验）的经验主义研究和验证 <sup class="refplus-num"><a href="#ref-189">[189]</a></sup> 、训练深度神经网络以进行泛化和避免过拟合 <sup class="refplus-num"><a href="#ref-190">[190]</a></sup><sup class="refplus-num"><a href="#ref-191">[191]</a></sup></p>
<h4 id="3-2-3-拉普拉斯近似">3.2.3 拉普拉斯近似</h4>
<p>拉普拉斯近似的目标是估计具有 <code>以局部峰值中心的多元正态分布几何形态</code> 的后验分布。在给定一些数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 的情况下，后验的拉普拉斯近似可以在以模型参数的 MAP 估计值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> 为中心的局部区域内，通过对<code>对数后验</code>做<code>二阶泰勒级数展开</code>获得。如果我们假设高斯先验的精度参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\tau &gt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> ，则对应于常用的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 正则化，并且泰勒级数展开生成：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>≈</mo><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>+</mo><mtext> </mtext><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><mi>θ</mi><mo>−</mo><mover accent="true"><mi>θ</mi><mo>^</mo></mover><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo stretchy="false">(</mo><mi>H</mi><mo>+</mo><mi>τ</mi><mi>I</mi><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>θ</mi><mo>−</mo><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log p(\theta\mid x,y)\approx\log p(\hat{\theta}\mid x,y)+\,\frac{1}{2}(\theta-\hat{\theta})^{T}(H+\tau I)(\theta-\hat{\theta})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2079em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.0074em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2079em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2079em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>由于对数后验的梯度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mi>θ</mi><mo>=</mo><mi mathvariant="normal">∇</mi><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\delta\theta=\nabla \log p(\theta\mid x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∇</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 在最大值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat \theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> 处为零，所以上式没有一阶项。对公式两边求指数，并通过<code>逆向工程密度</code>逼近积分，可得模型参数的后验近似为高斯分布，其均值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat \theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> 、协方差矩阵为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>H</mi><mo>+</mo><mi>τ</mi><mi>I</mi><msup><mo stretchy="false">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">(H + \tau I)^{−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>，这里 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span> 表示对数后验 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\log p(\theta \mid x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 的 <code>Hessian 矩阵</code>。</p>
<p>这意味着，模型不确定性可以由对数后验的 <code>Hessian 矩阵</code> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span> 表示，其形式为多元正态分布：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="script">N</mi><mrow><mo fence="true">(</mo><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo separator="true">,</mo><mo stretchy="false">(</mo><mi>H</mi><mo>+</mo><mi>τ</mi><mi>I</mi><msup><mo stretchy="false">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo fence="true">)</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(27)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">p(\theta\mid x,y)\sim{\mathcal{N}}\left({\hat{\theta}},(H+\tau I)^{-1}\right) \tag{27}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span><span class="tag"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">27</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>与前两种贝叶斯方法相比，拉普拉斯近似的优势是：<strong>可以应用于已经训练好的网络，并且适用于使用标准损失函数</strong>，例如 MSE 、交叉熵、分段线性激活（例如 RELU）等。 <code>Mackay</code> <sup class="refplus-num"><a href="#ref-123">[123]</a></sup> 和 <code>Denker 等</code> <sup class="refplus-num"><a href="#ref-122">[122]</a></sup> 在 1990 年代开创了神经网络的拉普拉斯近似，并且几种现代方法提供了其在深度神经网络中的扩展 <sup class="refplus-num"><a href="#ref-192">[192]</a></sup><sup class="refplus-num"><a href="#ref-193">[193]</a></sup><sup class="refplus-num"><a href="#ref-63">[63]</a></sup><sup class="refplus-num"><a href="#ref-84">[84]</a></sup>。</p>
<p>拉普拉斯近似的核心是 <code>Hessian 矩阵</code> 的估计。不幸的是，与 <code>Mackay</code> 和 <code>Denker 等</code> 讨论的小型网络相比，现代神经网络中存在大量参数，<code>Hessian 矩阵</code> 无法以可行方式进行计算 <sup class="refplus-num"><a href="#ref-122">[122]</a></sup>。因此，部分文献提出了一些新的估计 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span></span></span></span> 的方法。简要回顾如下：</p>
<p><strong>（1）非对角线近似</strong></p>
<p>一些研究人员专注于采用非对角线近似（例如 <sup class="refplus-num"><a href="#ref-195">[195]</a></sup><sup class="refplus-num"><a href="#ref-196">[196]</a></sup> 和 <sup class="refplus-num"><a href="#ref-197">[197]</a></sup>），代替对角线近似（ 例如 <sup class="refplus-num"><a href="#ref-194">[194]</a></sup><sup class="refplus-num"><a href="#ref-83">[83]</a></sup>）。其中，<sup class="refplus-num"><a href="#ref-198">[198]</a></sup><sup class="refplus-num"><a href="#ref-193">[193]</a></sup><sup class="refplus-num"><a href="#ref-192">[192]</a></sup> 和 <sup class="refplus-num"><a href="#ref-199">[199]</a></sup> 的逐层 <code>Kronecker 因子近似</code> 已被证明具有显著的可扩展性 <sup class="refplus-num"><a href="#ref-200">[200]</a></sup>。最近的扩展可以在 <sup class="refplus-num"><a href="#ref-201">[201]</a></sup> 中找到，其作者建议重新缩放 <code>Kronecker 因子矩阵</code> 的特征值，以便其特征基中的对角线方差更准确。该工作提出了一个有趣的想法，因为可以证明，就 <code>Frobenius 范数</code> 而言，其得到的近似值比 <sup class="refplus-num"><a href="#ref-193">[193]</a></sup> 更准确。然而，这种近似容易受到特征向量的不准确估计影响，<code>Lee 等</code> <sup class="refplus-num"><a href="#ref-84">[84]</a></sup> 建议进一步修正参数空间中的对角线元素。</p>
<p><strong>（2）对角线近似及其扩展</strong></p>
<p>现有获得拉普拉斯近似的方法，大多是在 “保真性-复杂性权衡” 的技术路线下，采用各种方法计算 <code>Hessian 矩阵</code>。其中几项工作，使用了 <code>Fisher 信息矩阵</code> 或 <code>高斯牛顿矩阵</code> 的对角线的近似值（ 即模型参数之间相互独立），已被用于修剪权重 <sup class="refplus-num"><a href="#ref-202">[202]</a></sup> ，或持续学习 <sup class="refplus-num"><a href="#ref-203">[203]</a></sup>。在 <code>Ritter 等</code> <sup class="refplus-num"><a href="#ref-63">[63]</a></sup> 的工作中，<code>近似块对角 Hessian 矩阵</code> 的 <code>Kronecker 分解</code> 已被用于获得神经网络的可扩展拉普拉斯近似 <sup class="refplus-num"><a href="#ref-193">[193]</a></sup><sup class="refplus-num"><a href="#ref-192">[192]</a></sup> 。不过该工作仍然假设不同层之间的权重独立分布，仅同一层内的权重存在相关性。近年，考虑到神经网络损失的几何形态中 <code>Hessian 矩阵</code> 的许多特征值为零，<code>Lee 等</code> <sup class="refplus-num"><a href="#ref-84">[84]</a></sup> 开发了一种 <code>低秩近似</code>，可以实现层间协方差矩阵的稀疏表示。此外，他们还证明了拉普拉斯近似可以扩展到 ImageNet 大小的数据集和架构，并进一步表明，使用所提出的稀疏化技术，可以使<code>相关性建模的内存复杂度</code>与<code>对角线近似方法</code>相当。最近，<code>Kristiadi 等</code> <sup class="refplus-num"><a href="#ref-204">[204]</a></sup> 提出了一个简单程序来计算最后一层的高斯近似（ 即忽略所有其他神经网络层中的模型不确定性 ），并表明这既是一个极简解决方案，也可以有效减轻 <code>ReLU 网络</code> 的过度自信预测。</p>
<p><strong>（3）其他</strong></p>
<p>最近的努力已将<code>拉普拉斯近似</code>扩展到 <code>Hessian 近似</code>之外。为了解决广为人知的假设（ 即拉普拉斯近似适用于钟形真实后验并因此导致欠拟合行为） <sup class="refplus-num"><a href="#ref-63">[63]</a></sup>，<code>Humt 等</code> <sup class="refplus-num"><a href="#ref-205">[205]</a></sup> 提出使用贝叶斯优化，并表明拉普拉斯近似的超参数可以通过提高校准性能得到有效优化。该领域的另一项工作是 <code>Kristiadi 等</code> <sup class="refplus-num"><a href="#ref-206">[206]</a></sup> 提出了不确定性单元 — 一种新型隐藏单元，它可以改变损失的几何形状，进而有可能更准确的推断。</p>
<p><code>Shinde 等</code> <sup class="refplus-num"><a href="#ref-207">[207]</a></sup> 证明了拉普拉斯近似对自动驾驶应用的实际有效性，<code>Feng 等</code> <sup class="refplus-num"><a href="#ref-208">[208]</a></sup> 则在图像分类任务中展示了：（a）合并上下文信息；（ii）以半监督方式实现域适应。其思想是在<code>条件随机场</code>中设计了<code>一元势</code>。</p>
<p>一些实时性方法不需要多次前向传递来计算预测不确定性。 <sup class="refplus-num"><a href="#ref-209">[209]</a></sup><sup class="refplus-num"><a href="#ref-210">[210]</a></sup> 中提出了<code>线性拉普拉斯近似</code>，他们使用了 <code>Mackay</code> <sup class="refplus-num"><a href="#ref-115">[115]</a></sup> 的思想，并用<code>拉普拉斯桥</code> 扩展了分类方法 <sup class="refplus-num"><a href="#ref-211">[211]</a></sup>。在这个框架内，<code>Daxberger 等</code> <sup class="refplus-num"><a href="#ref-212">[212]</a></sup> 建议推出子网络以增加协方差传播的表达能力，同时保持计算上的可处理性。</p>
<h4 id="3-2-4-小结">3.2.4 小结</h4>
<p>通过将深度神经网络和贝叶斯原理结合，用于深度学习的贝叶斯方法已成为当前的一个强大研究领域。对当前贝叶斯神经网络的回顾，主要集中在如何推断后验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>。通过观察，最近的许多突破都是通过小批量方式（随机）执行近似贝叶斯推断，或研究相对简单但可扩展的技术（如 <code>MC-Dropout</code> 或 <code>拉普拉斯近似</code>）来实现的。几项工作成果表明，现在可以在大规模场景中进行后验推断 <sup class="refplus-num"><a href="#ref-213">[213]</a></sup><sup class="refplus-num"><a href="#ref-150">[150]</a></sup><sup class="refplus-num"><a href="#ref-84">[84]</a></sup>，并且该领域已经有了几种实用的近似工具来计算更具表现力和准确率的后验 <sup class="refplus-num"><a href="#ref-73">[73]</a></sup><sup class="refplus-num"><a href="#ref-74">[74]</a></sup><sup class="refplus-num"><a href="#ref-78">[78]</a></sup><sup class="refplus-num"><a href="#ref-122">[122]</a></sup><sup class="refplus-num"><a href="#ref-123">[123]</a></sup>。</p>
<p>除了精确推断技术之外，新的前沿领域也出现了一些新挑战。一些例子是：</p>
<ul>
<li>如何指定有意义的先验？ <sup class="refplus-num"><a href="#ref-134">[134]</a></sup><sup class="refplus-num"><a href="#ref-135">[135]</a></sup></li>
<li>如何有效地边缘化参数以快速计算预测不确定性？ <sup class="refplus-num"><a href="#ref-181">[181]</a></sup><sup class="refplus-num"><a href="#ref-138">[138]</a></sup><sup class="refplus-num"><a href="#ref-211">[211]</a></sup></li>
<li>新基准、评估协议和软件工具等基础设施 <sup class="refplus-num"><a href="#ref-214">[214]</a></sup><sup class="refplus-num"><a href="#ref-131">[131]</a></sup><sup class="refplus-num"><a href="#ref-132">[132]</a></sup><sup class="refplus-num"><a href="#ref-215">[215]</a></sup></li>
<li>对当前方法及其潜在应用的深入理解和应用<sup class="refplus-num"><a href="#ref-137">[137]</a></sup><sup class="refplus-num"><a href="#ref-189">[189]</a></sup><sup class="refplus-num"><a href="#ref-216">[216]</a></sup><sup class="refplus-num"><a href="#ref-208">[208]</a></sup>。</li>
</ul>
<h3 id="3-3-深度集成网络">3.3 深度集成网络</h3>
<h4 id="3-3-1-基本原理">3.3.1 基本原理</h4>
<p>集成方法基于多个集成成员的预测得出最终预测。该方法利用不同模型之间的协同效应来实现更好的泛化，并认为一组决策往往比单个决策效果更好 <sup class="refplus-num"><a href="#ref-217">[217]</a></sup><sup class="refplus-num"><a href="#ref-218">[218]</a></sup>。对于集合 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">f : X → Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> 和成员 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub><mo>:</mo><mi>X</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">f_i : X → Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> 其中 $ i =1,2,…,M$，最终预测可以通过简单地对成员预测进行平均获得：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>:</mo><mo>=</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><msub><mi>f</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x) := \frac{1}{M}\sum_{i=1}^{M} f_i(x)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p>
<p>基于这种直观想法，一些文献将集成方法应用于不同类型的实际任务和方法中，例如生物信息学 <sup class="refplus-num"><a href="#ref-219">[219]</a></sup><sup class="refplus-num"><a href="#ref-220">[220]</a></sup><sup class="refplus-num"><a href="#ref-221">[221]</a></sup>、遥感 <sup class="refplus-num"><a href="#ref-222">[222]</a></sup><sup class="refplus-num"><a href="#ref-223">[223]</a></sup><sup class="refplus-num"><a href="#ref-224">[224]</a></sup>、强化学习 <sup class="refplus-num"><a href="#ref-225">[225]</a></sup><sup class="refplus-num"><a href="#ref-226">[226]</a></sup>。 除了能够提高准确性之外，集成方法还可以通过评估成员预测之间的多样性，来提供了一种能够直观表达最终预测中模型不确定性的方法。</p>
<p>与<code>贝叶斯方法</code>和<code>单一确定性神经网络方法</code>相比，集成方法有两个主要区别：</p>
<ul>
<li>集成方法背后的总体思路比较清晰，不同类型集成方法及其在不同领域的应用没有太多突破性的差异。因此，本节重点介绍训练集成方法的不同策略，以及旨在提高集成方法效率的一些变体。</li>
<li>最初引入集成方法时，其目的并非处理和估计神经网络不确定性。尽管从集成预测中推导不确定性显而易见，但该方法的初衷还是旨在降低模型不确定性 <sup class="refplus-num"><a href="#ref-218">[218]</a></sup>，因此，许多关于集成方法的工作没有明确考虑到不确定性。不过，已有研究表明：集成方法非常适合神经网络中的不确定性估计<sup class="refplus-num"><a href="#ref-31">[31]</a></sup>。</li>
</ul>
<h4 id="3-3-2-单峰和多峰分布">3.3.2 单峰和多峰分布</h4>
<p>集成方法与其他方法的一个重要区别在于：<strong>集成方法考虑的局部最优值数量可能更多，可以区分单峰值和多峰值的估计</strong>。</p>
<p>为了产生协同效应并通过边缘化消除单个成员可能的错误预测，在不确定输出结果的情况下，集成成员必须能够采取不同的行为，即保证成员多样性。由神经网络定义的映射是高度非线性的，通常只能收敛到局部最优解，因此，当损失函数中包含多个局部最优解时，不同训练算法就有可能会收敛到不同局部最优解。</p>
<p>确定性神经网络在参数空间中收敛到一个局部最优的点估计值 <sup class="refplus-num"><a href="#ref-227">[227]</a></sup>。其他方法（如 BNN ）也会收敛到一个最优的点估计值，但额外考虑了该局部最优解周边相邻点的不确定性 <sup class="refplus-num"><a href="#ref-227">[227]</a></sup>。这意味着，最优解周边某个区域内的相邻点也会影响损失函数，也会影响预测输出。由于这些方法侧重于单个区域，因此被称为单峰值估计。与此相反，集成方法由多个神经网络组成，它们可能会收敛到不同的局部最优值，进而产生多峰值的估计 <sup class="refplus-num"><a href="#ref-227">[227]</a></sup>。</p>
<p>在 <code>图 7</code> 中，可视化了单峰确定性方法、单峰贝叶斯方法、多峰集成方法对应的参数估计。多峰估计的目标是：不同的局部最优可以导致模型在预测中具有不同的优势和劣势，这样多个此类模型的组合就会产生协同效应，从而提高整体性能。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/bayes_20220323_151458_4ea6.webp" alt=""></p>
<blockquote>
<p>图 7：确定性神经网络方法、贝叶斯神经网络方法、确定性神经网络集成方法的不同估计结果。 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 轴表示神经网络参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 轴表示损失值。确定性神经网络基于点估计来学习参数，贝叶斯神经网络则同时考虑了点周边区域的分布，而集成方法虽然也是点估计，但可以学习到多套不同的参数。</p>
</blockquote>
<h4 id="3-3-3-成员的多样性问题">3.3.3 成员的多样性问题</h4>
<p>应用集成方法时最关键的一点是<strong>最大化单一神经网络行为的多样性</strong> <sup class="refplus-num"><a href="#ref-228">[228]</a></sup><sup class="refplus-num"><a href="#ref-31">[31]</a></sup> 。为了增加这种多样性，可以应用几种不同的方法：</p>
<ul>
<li><strong>随机初始化和数据混排（ Shuffle ）</strong>。由于存在严重的非线性损失，神经网络的不同初始化通常会导致不同的训练结果。由于训练是在小批量上实现的，训练数据点的顺序也会影响最终结果。因此，通过随机初始化和数据的混排，有可能增加集成成员的多样性。</li>
<li><strong>装袋和提升</strong>。Bagging 和 Boosting 是两种策略，它们通过从原始集合中的二次采样获得新训练样本集，以改变训练数据集的分布。 Bagging 方法从训练数据中均匀采样和替换<sup class="refplus-num"><a href="#ref-62">[62]</a></sup>。替换过程的引入，使新训练集中多次出现同一样本，而丢失一些其他训练样本。对于 Boosting 方法，成员一个接一个地接受训练，并且下一个训练集中的样本采样概率由已训练集成的性能决定 <sup class="refplus-num"><a href="#ref-62">[62]</a></sup>。</li>
<li><strong>数据增强</strong>。为每个集成成员随机增加输入数据，会导致在不同数据点上训练的模型，因此也会在不同成员之间产生更大的多样性。</li>
<li><strong>不同神经网络架构的集合</strong>。不同神经网络架构的组合导致不同的损失，因此也可以增加预测输出的多样性 <sup class="refplus-num"><a href="#ref-229">[229]</a></sup>。</li>
</ul>
<p>有几项研究工作已经表明 <sup class="refplus-num"><a href="#ref-230">[230]</a></sup><sup class="refplus-num"><a href="#ref-31">[31]</a></sup>，随机初始化产生的多样性足够有效，而 Bagging 有可能导致性能下降；<code>Livieris 等</code> <sup class="refplus-num"><a href="#ref-231">[231]</a></sup> 比较和评估了权重约束的神经网络集成方法中的不同 Bagging 和 Boosting 策略，<u>发现 Bagging 在集成成员较少时表现更好，而 Boosting 在集成成员较多时表现更好</u>。</p>
<p><code>Nanni 等</code> <sup class="refplus-num"><a href="#ref-232">[232]</a></sup> 以生物图像分类任务为背景，比较和评估了不同类型的图像增强对集成方法的影响； <code>Guo 和 Gould</code> <sup class="refplus-num"><a href="#ref-233">[233]</a></sup> 在用于目标检测的集成方法中使用了增强方法。两篇文献都指出，<u>使用增强的集成方法提高了结果准确性</u>。然而与此相对，<sup class="refplus-num"><a href="#ref-234">[234]</a></sup><sup class="refplus-num"><a href="#ref-235">[235]</a></sup> 在不确定性估计中结果表明，图像增强<u>会损害集成的校准，在使用集成方法时必须稍微调整后处理校准方法</u>。</p>
<p>还有其他一些为特定任务引入多样性的方法。例如，在 <sup class="refplus-num"><a href="#ref-236">[236]</a></sup> 中，集成成员<u>使用不同的注意力掩码进行训练</u>，以便专注于输入数据的不同部分。其他方法侧重于训练过程，并<u>引入了学习率调度程序</u>，旨在在一个训练过程中发现多个局部最优值 <sup class="refplus-num"><a href="#ref-86">[86]</a></sup><sup class="refplus-num"><a href="#ref-237">[237]</a></sup>，接下来，可以基于在一次训练运行中找到的局部最优值来构建集成。</p>
<p>重要重申：如果没有明确说明，迄今为止提出的各种集成工作和方法都旨在提高预测的准确性，并没有明确考虑对不确定性的估计，但事实上不确定性及其校准确实会发生变化。</p>
<h4 id="3-3-4-集成与不确定性估计的关系">3.3.4 集成与不确定性估计的关系</h4>
<p>除了提高准确性外，集成广泛用于估计复杂模型预测的不确定性，如气候预测 <sup class="refplus-num"><a href="#ref-238">[238]</a></sup><sup class="refplus-num"><a href="#ref-239">[239]</a></sup>。因此，集成也被用于估计深度神经网络预测的不确定性，并且在过去几年中，它们在此类任务中变得越来越流行<sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-228">[228]</a></sup>。</p>
<p>其中， <code>Lakshminarayanan 等</code> <sup class="refplus-num"><a href="#ref-31">[31]</a></sup> 的工作经常被作为 “基于神经网络集成作不确定性估计” 的基础，并作为深度集成竞争力的参考基线。他们引入了一个集成训练管道来估计深度神经网络中的预测不确定性。为了处理区分数据不确定性和模型不确定性，集成成员设计有两个头，分别表示预测不确定性和其中的数据不确定性。该方法在分类和回归任务的准确性、校准和分布外样本检测方面都进行了评估，在所有测试中，该方法的性能至少与 <code>Monte Carlo Dropout</code> 和 <code>概率反向传播</code> 方法一样好。 <code>Lakshminarayanan 等</code> <sup class="refplus-num"><a href="#ref-31">[31]</a></sup> 还表明，<u>训练数据的混排和训练过程的随机初始化，会使模型具备足够的多样性，并有利于预测给定架构和数据集的不确定性</u>。此外，他们发现 <code>Bagging</code> 会恶化预测的不确定性估计，证明了 <code>Lee 等</code> 的发现 <sup class="refplus-num"><a href="#ref-230">[230]</a></sup>。基于其框架，他们比较了 <code>集成方法</code> 和 <code>MC Dropout</code>，发现<u> <code>集成方法</code> 更加可靠，更适用于现实生活中的应用 </u>。这些发现支持了 <code>Beluch 等</code> 报告的结果 <sup class="refplus-num"><a href="#ref-240">[240]</a></sup>， 他们发现 <code>集成方法</code> 比 <code>MC Dropout</code> 给主动学习任务提供了更准确和更好的预测校准。</p>
<p>基于受分布变化影响的测试集，<code>Ovadia 等</code> <sup class="refplus-num"><a href="#ref-13">[13]</a></sup> 评估了多种不确定性估计方法。该评估包含多种模型类型和数据峰值形态。作为收获，<u>作者表示，对于相对较小的成员数（ 由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn></mrow><annotation encoding="application/x-tex">5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span></span></span></span> 个成员构成的集成 ），深度集成似乎表现最好，并且比其他方法更稳健</u>。</p>
<p><code>Vyas 等</code> <sup class="refplus-num"><a href="#ref-241">[241]</a></sup> 提出了一种用于改进分布外样本检测的集成方法。对于每个集成成员，训练数据的一个子集被认为是分布外的。在训练过程中，他们引入了新的损失函数，该损失函数在域内子集和分布外子集的平均熵之间寻求大于零的最小边距，使分布外样本的检测得到显著改进。</p>
<h4 id="3-3-5-剪枝与蒸馏">3.3.5 剪枝与蒸馏</h4>
<p>与单一模型方法相比，集成方法伴随着显著增加的计算量和内存消耗 <sup class="refplus-num"><a href="#ref-217">[217]</a></sup><sup class="refplus-num"><a href="#ref-45">[45]</a></sup>。在为现实应用部署集成方法时，可用内存和计算能力通常是有限的。这种限制很容易成为瓶颈 <sup class="refplus-num"><a href="#ref-242">[242]</a></sup>，并且对于反应时间有限的应用来说可能至关重要。减少模型的数量可以导致更少的内存和计算能力消耗。</p>
<p><code>剪枝</code> 通过减去成员以减少成员冗余来降低集成的复杂度。为此，开发了多种基于多样性测度的方法来删除单个成员，而不会强烈影响性能 <sup class="refplus-num"><a href="#ref-88">[88]</a></sup><sup class="refplus-num"><a href="#ref-87">[87]</a></sup><sup class="refplus-num"><a href="#ref-243">[243]</a></sup>。</p>
<p><code>蒸馏</code>是另一种减少神经网络数量的方法，它训练一个单一神经网络来表示一组神经网络的知识 <sup class="refplus-num"><a href="#ref-244">[244]</a></sup> 。第一个关于神经网络蒸馏的工作，正是在部署大规模分类模型时受到了限制的启发 <sup class="refplus-num"><a href="#ref-244">[244]</a></sup> 。原始的分类问题被分成几个子问题，分别关注难以区分的某个类块。几个较小的<code>训练器（Trainer）</code>神经网络分别在子问题上进行训练，然后教一个<code>学生（Student）</code>神经网络同时分离所有类。与此不同，<code>集成蒸馏方法</code>通过单一神经网络捕获集成的行为。最早的 <code>集成蒸馏</code> 工作使用每个集成成员 <code>softmax</code> 层输出的均值，向<code>学生神经网络</code>教授派生的预测不确定性 <sup class="refplus-num"><a href="#ref-245">[245]</a></sup>。 <code>Englesson 和 Azizpour</code> <sup class="refplus-num"><a href="#ref-246">[246]</a></sup> 证明了这种方法得到的预测分布是合理的，并且还涵盖了分布外样本的处理。当对成员输出进行平均时，模型不确定性会丢失。为了克服这个缺点，研究人员产生了学习高阶分布的想法，即学习分布的分布，而不是直接预测输出 <sup class="refplus-num"><a href="#ref-90">[90]</a></sup><sup class="refplus-num"><a href="#ref-45">[45]</a></sup>。该方法根据与均值分布之间的散度对成员进行蒸馏。这个想法与 <code>先验神经网络</code> <sup class="refplus-num"><a href="#ref-32">[32]</a></sup> 和 <code>证据神经网络</code> <sup class="refplus-num"><a href="#ref-44">[44]</a></sup> 密切相关，这些神经网络在 <code>第 3.1 节</code> 中进行过描述。</p>
<p>论文 <sup class="refplus-num"><a href="#ref-45">[45]</a></sup> 将<code>集成成员</code>和<code>蒸馏神经网络</code>建模为<code>预测 Dirichlet 分布参数</code>的先验神经网络。然后，蒸馏寻求最小化 <code>集成成员的平均 Dirichlet 分布</code> 与 <code>蒸馏神经网络输出</code> 之间的 <code>KL-散度</code>。 <code>Lindqvist 等</code> <sup class="refplus-num"><a href="#ref-90">[90]</a></sup> 将这个想法推广到任意其他可参数化的分布。此方法也适用于回归问题，例如通过预测均值和标准差来描述正态分布。在几个测试中，这些方法生成的蒸馏模型能够区分数据不确定性和模型不确定性。尽管蒸馏方法不能完全捕获底层集成的行为，但已经表明确实能够提供良好结果，某些实验甚至能够得到有竞争力的结果 <sup class="refplus-num"><a href="#ref-90">[90]</a></sup><sup class="refplus-num"><a href="#ref-45">[45]</a></sup><sup class="refplus-num"><a href="#ref-247">[247]</a></sup>。</p>
<p>其他方法，如<code>子集成</code> <sup class="refplus-num"><a href="#ref-39">[39]</a></sup> 和<code>批处理集成</code> <sup class="refplus-num"><a href="#ref-40">[40]</a></sup>，试图通过在集成成员之间共享部件来减少计算工作量和内存消耗。重要的是要注意，当共享部分集成时，也会部分失去为集成成员使用不同模型架构的可能性。此外，模型的训练无法以完全独立的方式运行，因此训练所需的实际时间不一定会减少。</p>
<p><code>子集成方法</code> <sup class="refplus-num"><a href="#ref-39">[39]</a></sup> 将神经网络架构分为两个子神经网络：从输入数据中提取一般信息的<strong>主干神经网络</strong>，以及使用这些信息完成实际任务的<strong>任务神经网络</strong>。为了训练子集成，首先，固定每个成员的主干网络权重（基于某个单一模型训练过程得到的结果参数）；接下来，每个集成成员的任务神经网络参数都独立于其他成员进行训练；其结果是，集成成员建立了一个公共主干和一个单独的任务子网络。由于主干神经网络的训练和评估只需进行一次，因此训练和测试所需的计算量按照比例 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>M</mi><mo>⋅</mo><msub><mi>N</mi><mtext>task</mtext></msub><mo>+</mo><msub><mi>N</mi><mtext>trunk</mtext></msub></mrow><mrow><mi>M</mi><mo>⋅</mo><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{M \cdot N_{\text {task}}+N_{\text {trunk}}}{M \cdot N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2392em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8942em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mbin mtight">⋅</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4159em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">task</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">trunk</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 减少， 其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mtext>task</mtext></msub><mtext>、</mtext><msub><mi>N</mi><mtext>trunk</mtext></msub></mrow><annotation encoding="application/x-tex">N_{\text{task}}、 N_{\text{trunk}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">task</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord cjk_fallback">、</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">trunk</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>、 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 分别表示任务神经网络、主干神经网络和完整神经网络中的变量数量。 <code>Valdenegro-Toro</code> <sup class="refplus-num"><a href="#ref-39">[39]</a></sup> 进一步强调了共享主干神经网络的使用，他认为主干神经网络通常比任务神经网络的计算成本更高。</p>
<p><code>批量集成方法</code> <sup class="refplus-num"><a href="#ref-40">[40]</a></sup> 在每一层都将成员神经网络相互连接起来。集成成员的权重被描述为一个共享权重矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W \in \mathbb{R}^{n \times m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个个体排名第一的矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">F_{i} \in \mathbb{R}^{n \times m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span> 的 Hadamard 乘积，每个矩阵都与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个集成成员之一相关联。排名第一的矩阵可以写成两个向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">s \in \mathbb{R}^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>m</mi></msup></mrow><annotation encoding="application/x-tex">r \in \mathbb{R}^{m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6889em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span></span></span></span></span></span></span></span> 的乘积 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub><mo>=</mo><msub><mi>r</mi><mi>i</mi></msub><msubsup><mi>s</mi><mi>i</mi><mi mathvariant="normal">T</mi></msubsup></mrow><annotation encoding="application/x-tex">F_{i}=r_{i} s_{i}^{\mathrm{T}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1em;vertical-align:-0.2587em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span></span></span></span>，因此矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">F_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 可以用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n+m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span> 个参数来描述。使用这种方法，每个额外的集成成员仅将参数数量按照因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>n</mi><mo>+</mo><mi>m</mi></mrow><mrow><mi>M</mi><mo>⋅</mo><mo stretchy="false">(</mo><mi>n</mi><mo>+</mo><mi>m</mi><mo stretchy="false">)</mo><mo>+</mo><mi>n</mi><mo>⋅</mo><mi>m</mi></mrow></mfrac><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{n+m}{M \cdot(n+m)+n \cdot m}+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3223em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8023em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mbin mtight">⋅</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">m</span><span class="mclose mtight">)</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">⋅</span><span class="mord mathnormal mtight">m</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 增加， 而不是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>M</mi><mo>+</mo><mn>1</mn></mrow><mi>M</mi></mfrac><mo>=</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn><mi>M</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{M+1}{M}=1+\frac{1}{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2173em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。通过这种方法，成员不再是独立的，因此所有成员都必须并行训练。作者还表明，可以实现类似于小批量和单一单元优化的并行化。</p>
<h4 id="3-3-6-小结">3.3.6 小结</h4>
<p>集成方法非常容易应用，因为不涉及对标准确定性模型的复杂实现或重大修改。此外，集成成员彼此独立训练，使得训练易于并行化。此外，经过训练的集成可以轻松扩展，但所需内存和计算量会随着成员数量线性增加。</p>
<p><strong>使用集成方法时的主要挑战是需要在集成成员中引入多样性</strong>。对于准确性、不确定性估计和分布外样本检测问题，随机初始化、数据混排和增强已被发现足以满足许多应用和任务 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-232">[232]</a></sup>。由于这些方法无论如何都可以使用，因此不需要太多额外努力。单个集成成员的独立性导致每个成员所需的内存和计算能力线性增加，并且训练和测试阶段都是如此，这限制了集成方法在许多实际应用中的部署，因为可能计算能力或内存有限，而对时间要求很高 <sup class="refplus-num"><a href="#ref-45">[45]</a></sup>。</p>
<p>集成方法的许多方面仅针对预测准确性指标进行了研究，但并未考虑预测不确定性，类似现象在针对广泛问题和数据集中比较的不同训练策略上也存在。特别是，由于单个成员的过度自信能够转移到整个集成，因此应该进一步研究能够鼓励成员提供不同错误预测（而不是所有成员都提供相同的错误预测）的策略。为了更好地理解集成行为，更进一步评估损失的几何形态可以提供更有趣的见解，正如 <code>Fort 等</code> 所做的那样 <sup class="refplus-num"><a href="#ref-227">[227]</a></sup> 。</p>
<h3 id="3-4-测试时增强方法">3.4 测试时增强方法</h3>
<p>受集成方法和对抗性样本 <sup class="refplus-num"><a href="#ref-14">[14]</a></sup> 的启发，<code>测试时数据增强</code>是一种更简单的<code>预测不确定性</code>估计技术。其基本方法是应用数据增强技术从每个测试样本创建多个测试样本，然后测试所有样本并计算预测分布，以测量预测输出的不确定性。此方法背后的想法是：<strong>增强后的测试样本允许探索不同的视图，因此能够捕获不确定性</strong>。</p>
<p>测试时数据增强技术已用于医学图像处理领域 <sup class="refplus-num"><a href="#ref-248">[248]</a></sup><sup class="refplus-num"><a href="#ref-249">[249]</a></sup><sup class="refplus-num"><a href="#ref-14">[14]</a></sup><sup class="refplus-num"><a href="#ref-250">[250]</a></sup> 。造成这种情况的原因之一是医学图像处理领域在使用深度学习同时，已经大量使用了数据增强 <sup class="refplus-num"><a href="#ref-251">[251]</a></sup>，因此，在测试期间应用类似的增强来计算不确定性就变得非常容易。另一个原因是收集医学图像的成本很高，因此迫使从业者依赖数据增强技术。</p>
<p><code>Moshkov 等</code> <sup class="refplus-num"><a href="#ref-250">[250]</a></sup> 将测试时增强技术用于细胞分割任务。为此，他们创建了测试数据的多种变体，然后将其提供给经过训练的 UNet 或 Mask R-CNN 架构。接下来，使用多数投票来创建最终的输出分割掩码，并讨论应用不同增强技术的策略以及它们对深度神经网络最终预测结果的影响。</p>
<p>总体而言，测试时增强是一种估计不确定性的简单方法，因为它保持基础模型不变，不需要额外数据，并且易于使用现成的库付诸实践。尽管如此，需要记住的是，在应用这种技术时，应该只对数据使用有效的增强，这意味着增强不应该从目标分布之外生成数据。</p>
<p>为了限制许多因素（ 例如手头问题的性质、训练数据的大小、深度神经网络架构和增强类型等）的影响，<code>Shanmugam 等</code> <sup class="refplus-num"><a href="#ref-252">[252]</a></sup> 提出了一种基于学习的测试时增强方法，该方法将上述因素考虑在内。特别是，所提出的方法学习了一个函数，该函数聚合了来自测试样本的每次增强的预测。</p>
<p>与 <sup class="refplus-num"><a href="#ref-252">[252]</a></sup> 类似，<code>Molchanov 等</code> <sup class="refplus-num"><a href="#ref-91">[91]</a></sup> 提出了一种名为 “贪婪策略搜索” 的方法，用于通过选择要包含在固定长度策略中的增强，来构建测试时增强的策略。同样，<code>Kim 等</code> <sup class="refplus-num"><a href="#ref-253">[253]</a></sup> 提出了一种从训练数据中学习损失预测器的方法，对于给定的样本，预测器选择具有最低预测损失的测试时增强。</p>
<p>尽管可学习的<code>测试时增强技术</code> <sup class="refplus-num"><a href="#ref-252">[252]</a></sup><sup class="refplus-num"><a href="#ref-91">[91]</a></sup><sup class="refplus-num"><a href="#ref-253">[253]</a></sup> 有助于选择有效的增强，但主要的<strong>悬而未决的问题之一是：不同类型增强对不确定性的影响到底如何？</strong>。例如，像镜像这样的简单增强无法捕捉到大部分不确定性，而在某些领域，专门的拉伸和剪切能够捕获到更多不确定性。</p>
<p><strong>找出需要多少增强才能正确估计给定任务中的不确定性也很重要</strong>。这在地球观测等应用中尤为重要，在这些应用中，可能需要在资源有限的全球范围内进行推断。</p>
<h3 id="3-5-方法对比与应用场景">3.5 方法对比与应用场景</h3>
<p>为了在现实生活中使用上述不确定性估计方法，必须考虑内存和算力等因素，而且许多现实世界的许多任务可能是时间敏感的 <sup class="refplus-num"><a href="#ref-242">[242]</a></sup>。表 1 中给出了上面四种获取不确定性方法的主要特性概述。表中表现出各种方法都有优缺点，具体取决于用户感兴趣的性质。</p>
<ul>
<li>
<p><strong>应用难度方面</strong>：虽然<code>集成方法</code>和<code>测试时增强方法</code>相对更容易使用，但<code>贝叶斯方法</code>可以清楚地描述模型参数的不确定性，也提供了更深层次的理论基础。</p>
</li>
<li>
<p><strong>计算效率方面</strong>：计算量和内存消耗是现实生活应用的常见限制条件，而<code>单一确定性神经网络</code>方法在此表现最好，但也可以考虑采用<code>集成蒸馏方法</code>或<code>高效贝叶斯方法</code>。在不同类型的贝叶斯方法中，性能、计算工作量和实现工作量存在很大差异。拉普拉斯方法相对容易应用，并且与采样方法相比，需要的计算量少得多。</p>
</li>
<li>
<p><strong>成果继承方面</strong>：对于存在预训练神经网络的情况，<code>拉普拉斯估计</code>和<code>外部确定性单一神经网络</code>方法可以应用于已经训练好的神经网络，较其他方法更有优势。</p>
</li>
<li>
<p><strong>分布外样本检测方面</strong>：在实际应用中进行不确定性估计时，必须考虑的另一个重要方面是不确定性的来源和类型。对于现实生活中的应用，分布外样本检测可能是最重要的挑战，可以避免神经网络的意外决策，并感知对抗性攻击。特别是，由于风险最小化给出了不确定性估计的许多动机，因此提供规避风险预测的方法是一个重要的评估领域。许多成果已经证明了在多个任务中检测分布外样本的能力，并为现实生活应用 <sup class="refplus-num"><a href="#ref-254">[254]</a></sup><sup class="refplus-num"><a href="#ref-241">[241]</a></sup><sup class="refplus-num"><a href="#ref-255">[255]</a></sup><sup class="refplus-num"><a href="#ref-56">[56]</a></sup> 的部署构建了强大的基础工具集。但现实生活中的任务比在数据集中找到分布外样本要困难得多，主要挑战在于：在互斥的几个现实世界数据集上比较这些方法。 <code>Gustafsson 等</code>的工作 <sup class="refplus-num"><a href="#ref-56">[56]</a></sup> 迈出了评估更适合现实生活应用需求的重要一步。有趣的是，他们在测试中发现<code>集成方法</code>优于<code>贝叶斯方法</code>。这表明，集成给出的多峰值评估是现实应用中的一个突出优势。尽管如此，贝叶斯方法也取得了很好的结果，而且具有强大的理论基础 <sup class="refplus-num"><a href="#ref-84">[84]</a></sup><sup class="refplus-num"><a href="#ref-211">[211]</a></sup><sup class="refplus-num"><a href="#ref-6">[6]</a></sup><sup class="refplus-num"><a href="#ref-23">[23]</a></sup>。作为一种可行方法，将<code>集成策略</code>和<code>贝叶斯方法</code>结合，可以在保留模型参数的变化性同时，考虑多个预测峰值。此外，单一确定性方法，如 <code>先验神经网络</code> <sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-64">[64]</a></sup><sup class="refplus-num"><a href="#ref-44">[44]</a></sup><sup class="refplus-num"><a href="#ref-33">[33]</a></sup>，也提供了有竞争力的结果，并且消耗的算力显著减少。但这种效率需要为训练过程提供人为分开的<code>分布内样本集</code>和<code>分布外样本集</code> <sup class="refplus-num"><a href="#ref-33">[33]</a></sup><sup class="refplus-num"><a href="#ref-64">[64]</a></sup>。</p>
</li>
</ul>
<p>一般来说，新问题和新损失函数的开发（ 如 <sup class="refplus-num"><a href="#ref-64">[64]</a></sup> 中给出的 ）可以更好地理解和描述潜在问题，并形成一个重要的研究领域。</p>
<h2 id="4-不确定性的测度">4 不确定性的测度</h2>
<div class="note info flat"><p>几个容易让人混淆的术语：</p>
<p><code>不确定性估计（Estimation of Uncertainty）</code>：指不确定性估计的过程或方法，如：贝叶斯方法（MCMC、变分推断等）、集成方法等。</p>
<p><code>不确定性估计结果（the Uncertainty Estimates）</code>：指不确定估计过程或方法给出的结果，可以用后验预测图的形式表达（见下图）。</p>
<p><code>不确定性测度（Uncertainty Measures）</code>：指用于定量刻画不确定性构成和大小的测度指标，测度值的大小反映了不确定性的大小。如：互信息、熵、预测方差等，主要目的是方便用户对单点预测结果中的不确定性进行量化分析。</p>
<p><code>不确定性估计的质量（Quality of the Uncertainty Estimates）</code>：指通过对不确定性估计结果的分析，来辨识不同不确定性估计方法的优劣。理论上需要和不确定性的真实值做对比（即比较<code>不确定性估计结果</code> 与 <code>不确定真实值</code>，见下图），但实践中无法得到不确定性的真实值（这也是实践中的困难之一），因此，通常使用达到收敛状态的蒙特卡洛估计结果作为真实值的近似。</p>
<p>下图说明了设计 <code>不确定性测度</code> 新指标的重要性：</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220329092412-4b16.webp" alt=""></p>
<blockquote>
<p>不同估计方法的后验预测图，蓝色区域为两倍标准差的不确定性区间。（1）收敛并混合良好的 HMC 后验预测作为基线（即作为真实值的替代），注意中间缺乏样本的区间不确定性明显增加，符合真实预期；（2）PBP、MVG 和 BBH 等其他方法产生的后验预测分布，明显在缺乏样本的区间都错误地表现出了较低的方差，表明在此处出现了过度自信（ 或者说不确定性估计结果不准确 ）；（3）后三种方法的对数似然都与 HMC 方法相当，说明依赖样本点的传统测度指标（ 分类中的对数似然、回归中的 RMSE 等 ），无法有效地评价不确定性估计的质量，需要设计新的测度指标。</p>
</blockquote>
</div>
<p>在<code>第 3 节</code> 中，我们介绍了用于建模和预测神经网络中不确定性的多种方法。为了评估这些方法，需要对其导出的不确定性进行度量。在下文中，我们提出了多种量化不同类型<code>预测不确定性</code>的测度指标。通常来说，这些不确定性的 <code>正确性</code> 和 <code>置信度</code> 并不是自动给出的。事实上，评估不确定性估计结果的质量是一项具有挑战性的任务，这主要有以下几个原因：</p>
<p><strong>首先，不确定性估计的质量取决于不确定性估计方法。</strong></p>
<p>这在 <code>Yao 等</code> 所做的工作中得到了例证 <sup class="refplus-num"><a href="#ref-256">[256]</a></sup>，该工作表明表明贝叶斯推断的不同近似值（例如高斯和拉普拉斯近似值）导致不确定性估计结果的不同质量。</p>
<p><strong>其次，缺乏不确定性估计的真实值 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup>，而且如何定义该真实值具有挑战性。</strong></p>
<p>例如，如果我们将不确定性的真实值定义为人类受试者中的不确定性，那么仍然必须回答 “需要多少受试者？” 或 “如何选择受试者？” 的问题。</p>
<p><strong>第三，不同任务可能存在各自的评价指标</strong><sup class="refplus-num"><a href="#ref-257">[257]</a></sup>。</p>
<p>这主要来源于：<strong>不确定性在分类、分割和回归等机器学习任务中存在不同的定义</strong>。例如，回归任务中的不确定性常常采用 <code>预测区间</code> 或<code>标准差</code>，而分类任务和分割任务中则常常采用 <code>熵</code>。</p>
<p>本节剩余部分，将按照分类、回归和分割三类任务，分别讨论其不确定性的测度指标。</p>
<div class="mermaid-wrap"><pre class="mermaid-src" hidden>
  graph LR
不确定性测度--&gt;分类任务
不确定性测度--&gt;回归任务
不确定性测度--&gt;分割任务
分类任务--&gt;数据不确定性 A
分类任务--&gt;模型不确定性 A
分类任务--&gt;分布不确定性 A
分类任务--&gt;多样本不确定性 A
回归任务--&gt;数据不确定性 B
回归任务--&gt;模型不确定性 B
回归任务--&gt;分布不确定性 B
回归任务--&gt;多样本不确定性 B
数据不确定性 A--&gt;最大概率
数据不确定性 A--&gt;熵
模型不确定性 A--&gt;互信息
模型不确定性 A--&gt;预期 KL 散度
模型不确定性 A--&gt;预测方差
  </pre></div>
<h3 id="4-1-评估分类任务中的不确定性">4.1 评估分类任务中的不确定性</h3>
<p>分类任务稍微特殊一些，因为用于分类的神经网络的最后一层通常是 <code>softmax</code> 层，其输出已经代表了一种对信念的度量。但原始的 <code>softmax</code> 输出并不可靠 <sup class="refplus-num"><a href="#ref-67">[67]</a></sup>，也无法区分不确定性的来源 <sup class="refplus-num"><a href="#ref-19">[19]</a></sup>，因此业界发展出了一些新的测度指标。</p>
<h4 id="4-1-1-数据不确定性的测度指标">4.1.1 数据不确定性的测度指标</h4>
<p>考虑一个具有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> 个不同类别的分类任务，某个分类神经网络的输出概率向量为 $$p(x), x \in { 1,\ldots,K }$$ 。在下文中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 作简化表示，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">p_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 代表 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo>=</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x=k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span>，为第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 个条目的对应概率值。通常来说，给定的预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 代表了一个类别分布，它为每个类别分配了一个概率，以便作出正确的预测。</p>
<p>由于预测是以概率分布形式（ 而非明确的类别 ）给出的，所以不确定性估计可以直接从该预测中得出，而这种逐数据点的预测可以被视为获得了 <strong>数据不确定性</strong> <sup class="refplus-num"><a href="#ref-60">[60]</a></sup>。但正如 <code>第 2 节</code> 所讨论的，模型对 <strong>数据不确定性</strong> 的估计会受到 <strong>模型不确定性</strong> 的影响（ 我们通常希望能够单独考虑模型不确定性，以辨识模型的优劣 ）。为了评估 <strong>数据不确定性</strong> 的量值，可以采用 <code>最大类概率</code> 或 <code>熵</code> 这两个测度：</p>
<p><code>最大类概率</code> 直接使用预测中的最大类概率来量化不确定性：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mtext>Maximal&nbsp;probability:</mtext><mspace width="1em"></mspace><msub><mi>p</mi><mi>max</mi><mo>⁡</mo></msub><mo>=</mo><mi>max</mi><mo>⁡</mo><msubsup><mrow><mo fence="true">{</mo><msub><mi>p</mi><mi>k</mi></msub><mo fence="true">}</mo></mrow><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></msubsup></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(28)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\text{Maximal probability:} \quad p_{\max }=\max \left\{p_{k}\right\}_{k=1}^{K} \tag{28}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">Maximal&nbsp;probability:</span></span><span class="mspace" style="margin-right:1em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">m</span><span class="mtight">a</span><span class="mtight">x</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="mop">max</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">}</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">28</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><code>熵</code> 则描述了神经网络输出的概率向量（或类别分布）中，不确定性（信息量）的平均水平：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mtext>Entropy:</mtext><mspace width="1em"></mspace><mi mathvariant="normal">H</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>p</mi><mi>k</mi></msub><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mrow><mo fence="true">(</mo><msub><mi>p</mi><mi>k</mi></msub><mo fence="true">)</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(29)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\text{Entropy:} \quad \mathrm{H}(p)=-\sum_{k=1}^{K} p_{k} \log _{2}\left(p_{k}\right) \tag{29}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Entropy:</span></span><span class="mspace" style="margin-right:1em;"></span><span class="mord mathrm">H</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span><span class="tag"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">29</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>需要注意的是，虽然 <code>softmax</code> 层的输出能够代表数据不确定性，但我们无法从单个数据点的预测中区分出其中到底包含了多少 <strong>模型不确定性</strong> 。</p>
<div class="note info flat"><p>此处数据不确定性面向单数据点，实际上是基于 <code>softmax</code> 函数输出的类别分布计算了测度指标，可以用一个标量来表达该数据点上的预测不确定性水平。</p>
</div>
<h4 id="4-1-2-模型不确定性的测度指标">4.1.2 模型不确定性的测度指标</h4>
<p>正如在<code>第 3 节</code>中已经讨论的，单一的 <code>softmax</code> 预测对于不确定性量化来说，并不可靠，因为它通常会被错误地校准，并且在其特定的输出中，并没有提供与模型不确定性相关的信息 <sup class="refplus-num"><a href="#ref-19">[19]</a></sup> 。</p>
<p>根据贝叶斯统计，学习模型参数上的（近似）后验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span> 有助于获得更好的模型不确定性估计。如果模型参数是随机变量，则神经网络的预测输出（ 即 <code>softmax 层的输出</code> ）也就变成了随机变量，自然就可以评估它的变化性（ 即不确定性 ）。信息论为我们提供了测量这种变化性的工具，其大致思路都是假设随机变量的期望值（均值）能够代表真实值，然后对随机变量的样本与该期望值之间的某种差异做统计分析，所得到的统计量可以用来近似量化该随机变量的不确定性。</p>
<p>为了简单起见，我们也将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>θ</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y \mid \theta,x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 表示为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span>，通过上下文，读者应该可以清楚地看出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 到底代表了模型参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> ，还是模型输出。</p>
<p>分类任务的模型不确定性测度主要有： <code>互信息 (MI)</code>、<code>预期 KL 散度 (EKL)</code> 和 <code>预测方差（ σ ）</code>。根据上面的分析，所有这些测度基本上都是在对 <code>softmax 层的输出</code>（即随机变量的样本） 与其均值之间的某种差异做统计分析。其中 <code>softmax 层的输出</code> 指对于某个数据点而言，神经网络 <code>softmax 层</code> 实际输出的类概率向量（点估计）； 而其均值则表示为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> ，可以通过对模型参数后验分布的边缘化得到（也是点估计），定义为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>θ</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(30)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\hat{p}=\mathbb{E}_{\theta \sim p(\theta \mid D)}[p(y \mid x, \theta)] \tag{30}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)]</span></span><span class="tag"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">30</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><strong>（1）互信息（MI）</strong></p>
<p><code>互信息</code> 是一个用熵值来衡量两个随机变量之间相互依赖关系的测度指标，代表一个随机变量由于已知另一个随机变量而减少的不确定性：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="normal">MI</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>θ</mi><mo separator="true">,</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">H</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">]</mo><mo>−</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>θ</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></msub><mi mathvariant="normal">H</mi><mo stretchy="false">[</mo><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>∣</mo><mi>x</mi><mo separator="true">,</mo><mi>θ</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(31)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\operatorname{MI}(\theta, y \mid x, D)=\mathrm{H}[p]-\mathbb{E}_{\theta \sim p(\theta \mid D)} \mathrm{H}[p(y \mid x, \theta)] \tag{31}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">MI</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathrm">H</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mord mathrm">H</span><span class="mopen">[</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)]</span></span><span class="tag"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">31</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>式中， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">MI</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\operatorname{MI}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mop"><span class="mord mathrm">MI</span></span></span></span></span> 为互信息，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">H</mi></mrow><annotation encoding="application/x-tex">\mathrm{H}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathrm">H</span></span></span></span> 代表某给概率分布的熵。</p>
<p><code>Smith 和 Gal</code> <sup class="refplus-num"><a href="#ref-19">[19]</a></sup> 指出，当关于模型参数的知识不会再增加最终预测中的不确定性时，互信息达到最小。也就是说互信息越小，不确定性越低，互信息越大，不确定性月高。因此，互信息可以解释为 <strong>模型不确定性</strong> 的度量。</p>
<p><strong>（2）平均 KL 散度（EKL）</strong></p>
<p><code>KL-散度</code> 衡量两个概率分布之间的差异性且不支持交换律，顾名思义， <code>平均 KL 散度（EKL）</code> 是求所有可能的 <code>softmax 层</code> 输出带来的平均差异。这种平均差异越大，则表明不确定性越大：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msub><mi mathvariant="double-struck">E</mi><mrow><mi>θ</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi mathvariant="normal">∥</mi><mi>p</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>θ</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mo fence="true">[</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><msub><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi>i</mi></msub><msub><mi>p</mi><mi>i</mi></msub></mfrac><mo fence="true">)</mo></mrow><mo fence="true">]</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(32)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathbb{E}_{\theta \sim p(\theta \mid D)}[K L(\hat{p} \| p)]=\mathbb{E}_{\theta \sim p(\theta \mid D)}\left[\sum_{i=1}^{K} \hat{p}_{i} \log \left(\frac{\hat{p}_{i}}{p_{i}}\right)\right] \tag{32}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1052em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mord">∥</span><span class="mord mathnormal">p</span><span class="mclose">)]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">[</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">]</span></span></span></span><span class="tag"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">32</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><strong>（3）预测方差（σ）</strong></p>
<p>方差是用来表示随机变量变化性的最直接指标，此处的<code>预测方差（σ）</code> 指 <code>softmax 层</code> 输出（随机变量）的均方差，即：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mi>θ</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></msub><mrow><mo fence="true">[</mo><mo stretchy="false">(</mo><mi>p</mi><mo>−</mo><mover accent="true"><mi>p</mi><mo>^</mo></mover><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(33)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\sigma(p)=\mathbb{E}_{\theta \sim p(\theta \mid D)}\left[(p-\hat{p})^{2}\right]  \tag{33}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2193em;vertical-align:-0.3552em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mrel mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span><span class="tag"><span class="strut" style="height:1.2193em;vertical-align:-0.3552em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">33</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><strong>（4）计算考虑</strong></p>
<p>上述三个测度指标，都是基于贝叶斯方法的，需要得到后验支撑。但正如 <code>第 3 节</code> 所述，具有封闭形式描述的后验分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>θ</mi><mo>∣</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\theta \mid D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span> 仅仅是贝叶斯方法中一个很小的子集；而且即便存在封闭形式的解，将参数的不确定性传播到预测分布中在计算上也很难处理，通常必须使用例如蒙特卡罗方法来进行近似。类似地，集成方法从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个神经网络收集预测结果，而测试时数据增强方法从应用于原始输入样本的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个不同增强中收集 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个预测。</p>
<p>对于所有这些情况，我们都可以收到数据点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 处的一组 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个样本 $${p^{i}}_{i=1}^{M}$$，其中每个样本点均对应一个 <code>softmax 层</code> 输出的类别分布，可以依据该样本来估计难以处理的底层分布。<code>式（31）</code>、<code>式（32）</code> 和 <code>式（33）</code> 中定义的测度指标可以直接应用这些近似，只需用<code>平均求和</code>公式代替<code>期望</code>即可。例如，<code>式（30）</code> 中的 <code>softmax</code> 层输出的期望（即预测分布）就可以近似为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo>≈</mo><mfrac><mn>1</mn><mi>M</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><msup><mi>p</mi><mi>i</mi></msup></mrow><annotation encoding="application/x-tex">\hat{p} \approx \frac{1}{M} \sum_{i=1}^{M} p^{i}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8747em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><code>式（31）</code>、<code>式（32）</code> 和 <code>式（33）</code> 中的其他期望，也可以采用类似方法推导和计算。</p>
<h4 id="4-1-3-分布不确定性的度量">4.1.3 分布不确定性的度量</h4>
<p>尽管上述不确定性测度被广泛用于捕获从贝叶斯神经网络 <sup class="refplus-num"><a href="#ref-60">[60]</a></sup>、集成方法 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup> 或测试时数据增强方法 <sup class="refplus-num"><a href="#ref-14">[14]</a></sup> 得出的多个预测之间的变化性，但它们无法捕获输入数据中的分布偏移或分布外的样本，这可能导致有偏见的推断过程和错误的置信度。如果所有预测器都将高的概率质量归因于同一个（错误的）类标签，则会导致估计值之间的低变异性。因此，神经网络似乎对其预测是确定的，而预测本身的不确定性（由 <code>softmax</code> 概率给出）也被低估了。</p>
<p>为了解决这个问题，<code>第 3 节</code>中描述的几种方法使用了 <code>logits</code> 的值，因为更大的 <code>logits</code> 表明相应类别的证据更大 <sup class="refplus-num"><a href="#ref-44">[44]</a></sup>。这些方法要么将 <code>logits</code>（的指数）的总和解释为 <code>Dirichlet 分布</code> 的精度参数（参见<code>第 3.1 节</code>中 <code>Dirichlet 先验</code> 的描述）<sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-94">[94]</a></sup><sup class="refplus-num"><a href="#ref-64">[64]</a></sup>，要么解释为与预定义常数 <sup class="refplus-num"><a href="#ref-44">[44]</a></sup><sup class="refplus-num"><a href="#ref-92">[92]</a></sup> 进行比较的证据集合。</p>
<p>人们还可以通过将 <code>sigmoid 函数</code> 应用于每个 <code>logits</code> <sup class="refplus-num"><a href="#ref-105">[105]</a></sup> 来单独导出每个类的总概率。基于类别的总概率，<code>分布外样本</code>可能更容易被检测到，因为所有类别可能同时具有低概率。其他方法可以明确衡量新数据样本与训练数据分布的匹配程度。基于此，他们还给出了用于估计<code>样本将被正确预测</code>的测度指标<sup class="refplus-num"><a href="#ref-36">[36]</a></sup>。</p>
<h4 id="4-1-4-不确定估计方法的总体质量评估">4.1.4 不确定估计方法的总体质量评估</h4>
<p>上述措施衡量了单数据点预测的性能，但无法评估不确定估计的整体质量，因此通常需要在一组样本上进行统计评估。在此情况下，不确定性测度通常被分为 <code>正确分类的样本</code> 和 <code>错误分类的样本</code>，或 <code>域内样本</code> 和 <code>分布外样本</code> <sup class="refplus-num"><a href="#ref-67">[67]</a></sup>。也就是说，样本通常会被分成两组，例如 <code>域内样本</code> 和 <code>分布外样本</code>，或者 <code>正确分类样本</code> 和 <code>错误分类样本</code> ，然后基于两组样本的情况进行分析。</p>
<p><strong>（1） <code>ROC 曲线</code> 和 <code>PR 曲线</code></strong></p>
<p>两种最常见的总体质量评估方法是 <code>受试者工作特征曲线 (ROC) 曲线</code> 和 <code>精确召回 (PR) 曲线</code>。两者都是在底层测度值的不同阈值基础上生成的曲线。</p>
<ul>
<li><code>ROC 曲线</code>：对于每个考虑的阈值，绘制 <code>真阳性率</code> 相对于 <code>假阳性率</code> 的曲线</li>
<li><code>PR 曲线</code> ：对于每个考虑的阈值，绘制 <code>精度</code> 相对于 <code>召回率</code> 的曲线。</li>
<li>对于多分类任务，会将每一个类视为一个二分类任务，分别绘制一条<code>ROC 曲线</code> 或　<code>PR 曲线</code></li>
</ul>
<div class="note info flat"><p>可以先熟悉机器学习中的常见质量评价指标，如：准确率（Accuracy）、错误率（Error rate）、精确率（Precision）、召回率（recall）、综合评价指标（F-Measure）等，以及常见图形：ROC 曲线、PR 曲线等。</p>
<p><strong>准确率(Accuracy)</strong> 为 <code>被正确预测的总样本数（TP+TN）</code> 除以 <code>所有样本数量（TP+FP+TN+FN）</code>，该指标在样本不平衡时可能不准确。</p>
<p><strong>真阳性率(True Positive Rate, TPR)</strong> 为 <code>被正确预测为阳性的样本数（TP）</code> 除以 <code>真实阳性样本的总数（TP+FN）</code>，通常表明对阳性样本的敏感性，即如果病人是阳性的，那么检出率大概为多少；</p>
<p><strong>假阳性率(False Positive Rate, FPR)</strong> 为 <code>被错误预测为阳性的样本数(FP)</code> 除以 <code>真实阴性样本的总数（TN+FP）</code>，通常表明阴性样本的特异性，即如果病人是阴性的，那么被错检的概率大概为多少；</p>
<p><strong>精度(Precision)</strong> 为 <code>被正确预测为阳性的样本数（TP）</code> 除以 <code>被预测为阳性的样本总数（TP+FP）</code>，又称查准率，衡量的是预测的信噪比；</p>
<p><strong>召回率(Recall)</strong> 为 <code>被正确预测为阳性的样本数（TP）</code> 除以 <code>真实阳性样本的总数（TP+FN）</code>，又称查全率，衡量的是预测的覆盖率；</p>
<p><strong>F-Score</strong> 为综合指标，定义为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>（</mtext><mn>1</mn><mo>+</mo><msup><mi>β</mi><mn>2</mn></msup><mtext>）</mtext><mfrac><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>⋅</mo><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>+</mo><msup><mi>β</mi><mn>2</mn></msup><mo>⋅</mo><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">（1+ \beta^2）\frac{Recall \cdot Precision}{Recall+ \beta^2 \cdot Precision}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord cjk_fallback">（</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.3612em;vertical-align:-0.4811em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord cjk_fallback">）</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight">ec</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">ll</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7463em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">⋅</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">rec</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="mord mathnormal mtight">ec</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">ll</span><span class="mbin mtight">⋅</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mord mathnormal mtight">rec</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4811em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>， 当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\beta=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 时， 被称为 <code>F1-Score</code>，此时精度和召回率都很重要，权重相当。如果认为精度更重要一些，可以设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\beta &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> ，如果认为召回率更重要一些，可以设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\beta &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>。</p>
<p>上述指标的真实含义均与正例的定义有关，例如：定义垃圾邮件为正，则正常邮件为负，此时查准率可能意味着是否需要到<code>垃圾邮件箱</code>中再人工筛查一遍，以免遗漏正常邮件，而查全率则可能意味着<code>收件箱</code>中垃圾邮件的多少。</p>
<p>不同的应用，关心的指标也不一样。例如：</p>
<ul>
<li>在肿瘤判断和地震预测场景中，要求高的召回率，即有肿瘤或有地震尽量都与测出来；</li>
<li>在垃圾邮件检测场景中，要求高的精度，即放进　<code>垃圾邮件箱</code> 中的，尽量不要有正常邮件。</li>
</ul>
<p>指标计算案例：</p>
<p>癌症检查数据样本有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10000</mn></mrow><annotation encoding="application/x-tex">10000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10000</span></span></span></span> 个，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span> 个祥本真有癌症，其它无癌症。假设分类模型在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9990</mn></mrow><annotation encoding="application/x-tex">9990</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">9990</span></span></span></span> 个无癌症数据中预测正确了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9980</mn></mrow><annotation encoding="application/x-tex">9980</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">9980</span></span></span></span> 个，在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span> 个癌症数据中预测正确了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">9</span></span></span></span> 个，此时真阳 = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">9</span></span></span></span> ，真阴 = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9980</mn></mrow><annotation encoding="application/x-tex">9980</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">9980</span></span></span></span> ，假阳 = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">10</span></span></span></span> ，假阴 = <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>。</p>
<p>那么：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>c</mi><mi>c</mi><mi>u</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>y</mi><mo>=</mo><mo stretchy="false">(</mo><mn>9</mn><mo>+</mo><mn>9980</mn><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mn>10000</mn><mo>=</mo><mn>99.89</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">Accuracy = (9+9980) /10000=99.89\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">cc</span><span class="mord mathnormal">u</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.03588em;">cy</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">9980</span><span class="mclose">)</span><span class="mord">/10000</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">99.89%</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mn>9</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>9</mn><mo>+</mo><mn>10</mn><mo stretchy="false">)</mo><mo>=</mo><mn>47.36</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">Precision=9 / (9+10)= 47.36\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal">rec</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">9/</span><span class="mopen">(</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">10</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">47.36%</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mn>9</mn><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>9</mn><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mn>90</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">Recall = 9/(9+1) = 90\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal">ec</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">ll</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">9/</span><span class="mopen">(</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">90%</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mn>1</mn><mo>−</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mn>2</mn><mo>×</mo><mo stretchy="false">(</mo><mn>47.36</mn><mi mathvariant="normal">%</mi><mo>×</mo><mn>90</mn><mi mathvariant="normal">%</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>1</mn><mo>×</mo><mn>47.36</mn><mi mathvariant="normal">%</mi><mo>+</mo><mn>90</mn><mi mathvariant="normal">%</mi><mo stretchy="false">)</mo><mo>=</mo><mn>62.07</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">F1-score=2×(47.36\% × 90\%)/(1 × 47.36\% + 90\%)=62.07\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">score</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">47.36%</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">90%</span><span class="mclose">)</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.0833em;"></span><span class="mord">47.36%</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">90%</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">62.07%</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mn>2</mn><mo>−</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><mn>5</mn><mo>×</mo><mo stretchy="false">(</mo><mn>47.36</mn><mi mathvariant="normal">%</mi><mo>×</mo><mn>90</mn><mi mathvariant="normal">%</mi><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>4</mn><mo>×</mo><mn>47.36</mn><mi mathvariant="normal">%</mi><mo>+</mo><mn>90</mn><mi mathvariant="normal">%</mi><mo stretchy="false">)</mo><mo>=</mo><mn>76.27</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">F2-score=5× (47.36\% × 90\%)/(4×47.36\%+90\%)=76. 27\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">score</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">47.36%</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">90%</span><span class="mclose">)</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.0833em;"></span><span class="mord">47.36%</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">90%</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">76.27%</span></span></span></span></li>
</ul>
<p>参见 <sup class="refplus-num"><a href="#ref-258">[258]</a></sup>，或<a target="_blank" rel="noopener" href="https://blog.csdn.net/liweibin1994/article/details/79462554">博客</a></p>
</div>
<p><strong>（2） AUC 测度指标</strong></p>
<p>虽然 <code>ROC 曲线</code> 和 <code>PR 曲线</code> 可以直观可视化地了解底层测度是否适合分离两个测试用例，但它们并没有给出定量的评价指标。为此，可以评估 <code>曲线下面积 (AUC)</code>。粗略地说，<code>AUC</code> 给出了 <code>随机选择的正样本</code> 比 <code>随机选择的负样本</code> 导致更高测度值的概率。 例如，<code>最大 softmax 值</code> 可以用于衡量 <code>正确分类样本</code> 的等级高于 <code>错误分类样本</code>。</p>
<p><code>Hendrycks 和 Gimpel</code> <sup class="refplus-num"><a href="#ref-67">[67]</a></sup> 在几个应用领域表明，与错误预测相比，正确预测通常在 <code>softmax 值</code> 中具有更高的预测确定性。特别是对于域内和分布外样本的评估，通常使用 <code>ROC 曲线下面积（AUROC）</code> 和 <code>精确召回曲线下面积（AUPRC）</code> <sup class="refplus-num"><a href="#ref-64">[64]</a></sup><sup class="refplus-num"><a href="#ref-32">[32]</a></sup><sup class="refplus-num"><a href="#ref-94">[94]</a></sup>。</p>
<p>这些评估方法的明显弱点是：<strong><code>性能评估</code>和<code>最佳阈值</code> 计算都必须基于给定的测试数据集</strong>。如果待预测的新数据点与测试集之间存在分布偏移，则可能会破坏整体性能并使派生的阈值不切实际。</p>
<h3 id="4-2-评估回归任务中的不确定性">4.2 评估回归任务中的不确定性</h3>
<h4 id="4-2-1-数据不确定性的测度指标">4.2.1 数据不确定性的测度指标</h4>
<p><strong>（1）预测密度函数的参数</strong></p>
<p>与分类任务不同，回归任务仅输出了预测的点估计，没有任何有关数据不确定性的信息。如 <code>第 3 节</code> 所述，克服这一问题的<strong>常用方法是让神经网络预测概率分布的参数</strong>（即密度估计），例如，假设呈正态分布的不确定性的均值向量和标准差参数 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-60">[60]</a></sup>。这样做可以直接给出数据不确定性的测度。其中<code>标准差</code> 的预测结果可以描述（未知）真实值在某个特定区间内的情况。</p>
<p>以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 的概率覆盖真实值的区间由下式给出（假设预测分布正确）：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mo fence="true">[</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mi mathvariant="normal">Φ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>σ</mi><mo separator="true">;</mo><mspace width="1em"></mspace><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>+</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mi mathvariant="normal">Φ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>σ</mi><mo fence="true">]</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(34)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\left[\hat{y}-\frac{1}{2} \Phi^{-1}(\alpha) \cdot \sigma ; \quad \hat{y}+\frac{1}{2} \Phi^{-1}(\alpha) \cdot \sigma\right] \tag{34}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mpunct">;</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span><span class="tag"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">34</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="normal">Φ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\Phi^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 是分位数函数，是累积概率函数的倒数。对于给定的概率值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span>，分位数函数给出一个边界，使得标准正态分布的概率质量的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn><mo>⋅</mo><mi>α</mi><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">100 \cdot \alpha \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord">%</span></span></span></span> 位于小于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="normal">Φ</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Phi^{-1}(\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">Φ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span></span></span></span> 的值中。分位数假设一些概率分布，并将给定的预测解释为分布的期望值。</p>
<p><strong>（2）直接预测不确定性区间</strong></p>
<p>另外有其他方法 <sup class="refplus-num"><a href="#ref-259">[259]</a></sup><sup class="refplus-num"><a href="#ref-260">[260]</a></sup> 直接预测所谓的预测区间（ 假设预测结果在其中 ）：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi>P</mi><mi>I</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">[</mo><msub><mi>B</mi><mi>l</mi></msub><mo separator="true">,</mo><msub><mi>B</mi><mi>u</mi></msub><mo fence="true">]</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(35)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">P I(x)=\left[B_{l}, B_{u}\right] \tag{35}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">]</span></span></span><span class="tag"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">35</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>顾名思义，这种方法的确定性可以直接通过预测区间的大小来衡量。<code>平均预测区间宽度 (MPIW)</code> 可用于评估模型的平均确定性 <sup class="refplus-num"><a href="#ref-259">[259]</a></sup><sup class="refplus-num"><a href="#ref-260">[260]</a></sup> 。为了评估预测区间的正确性，可以应用<code>预测区间覆盖概率 (PICP)</code> <sup class="refplus-num"><a href="#ref-259">[259]</a></sup><sup class="refplus-num"><a href="#ref-260">[260]</a></sup>。 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>C</mi><mi>I</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">PCIP</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">PC</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 表示落入预测区间的测试结果所占百分比，定义为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mtext>&nbsp;PICP&nbsp;</mtext><mo>=</mo><mfrac><mi>c</mi><mi>n</mi></mfrac></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(36)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\text { PICP }=\frac{c}{n} \tag{36}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">&nbsp;PICP&nbsp;</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.7936em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height:1.7936em;vertical-align:-0.686em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">36</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 是预测的总数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span> 是预测区间实际捕获的真实值数量。</p>
<h4 id="4-2-2-模型不确定性的测度指标">4.2.2 模型不确定性的测度指标</h4>
<p>在 <code>第 2 节</code> 中，描述了模型的不确定性主要是由模型的架构、训练过程和训练数据中代表性不足的区域引起的。因此，回归任务和分类任务之间 <strong>模型不确定性</strong> 的原因和影响没有真正的区别，回归任务中的 <strong>模型不确定性</strong> 可以像已经描述的分类任务一样等价地度量，即在大多数情况下，可以通过计算平均预测和单个预测之间的<code>KL 散度均值</code>来度量 <sup class="refplus-num"><a href="#ref-60">[60]</a></sup> 。</p>
<h3 id="4-3-评估分割任务中的不确定性">4.3 评估分割任务中的不确定性</h3>
<p>分割任务中不确定性的评估与分类问题非常相似，分割任务中主要使用贝叶斯推断 <sup class="refplus-num"><a href="#ref-1">[1]</a></sup><sup class="refplus-num"><a href="#ref-2">[2]</a></sup><sup class="refplus-num"><a href="#ref-4">[4]</a></sup><sup class="refplus-num"><a href="#ref-152">[152]</a></sup><sup class="refplus-num"><a href="#ref-261">[261]</a></sup><sup class="refplus-num"><a href="#ref-262">[262]</a></sup><sup class="refplus-num"><a href="#ref-263">[263]</a></sup><sup class="refplus-num"><a href="#ref-264">[264]</a></sup> 或测试时数据增强方法来估计不确定性技术 <sup class="refplus-num"><a href="#ref-249">[249]</a></sup> 。</p>
<p>在分割任务场景中，像素级分割的不确定性（ 像素不确定性 ）使用 <code>置信区间</code> <sup class="refplus-num"><a href="#ref-4">[4]</a></sup><sup class="refplus-num"><a href="#ref-152">[152]</a></sup> 、<code>预测方差</code> <sup class="refplus-num"><a href="#ref-262">[262]</a></sup><sup class="refplus-num"><a href="#ref-264">[264]</a></sup> 、<code>预测熵</code> <sup class="refplus-num"><a href="#ref-2">[2]</a></sup><sup class="refplus-num"><a href="#ref-249">[249]</a></sup><sup class="refplus-num"><a href="#ref-261">[261]</a></sup><sup class="refplus-num"><a href="#ref-263">[263]</a></sup> 或 <code>互信息</code> <sup class="refplus-num"><a href="#ref-1">[1]</a></sup> 来度量的。</p>
<p>体（结构）不确定性估计则是通过 “对所有像素不确定性的估计求均值” 获得的 <sup class="refplus-num"><a href="#ref-264">[264]</a></sup><sup class="refplus-num"><a href="#ref-261">[261]</a></sup> 。体不确定性的质量则主要通过 <code>变异系数</code>、<code>平均分数</code> 或 <code>IOU</code> 来评估 <sup class="refplus-num"><a href="#ref-2">[2]</a></sup><sup class="refplus-num"><a href="#ref-249">[249]</a></sup> 。这些指标以成对方式衡量多个估计之间区域重叠的一致性。理想情况下，错误分割会导致像素不确定性和体不确定性的增加。为了评估是否是这种情况，<code>Nair 等</code> <sup class="refplus-num"><a href="#ref-1">[1]</a></sup> 在不同不确定性阈值下保留的像素上，评估了 <code>真阳性率</code>、<code>错误检测率</code> 以及 <code>ROC 曲线</code>。与 <sup class="refplus-num"><a href="#ref-1">[1]</a></sup> 类似，<code>McClure 等</code>  <sup class="refplus-num"><a href="#ref-261">[261]</a></sup> 还分析了 <code>ROC 曲线下的面积</code>。</p>
<h2 id="5-对预测置信度进行校准">5 对预测置信度进行校准</h2>
<h3 id="5-1-校准的定义">5.1 校准的定义</h3>
<p>如果一个预测器得出的预测不确定性（或置信度）与事件发生的真实概率相匹配，那么，该预测器就可以被称为经过良好校准的预测器 <sup class="refplus-num"><a href="#ref-15">[15]</a></sup> 。或者反过来说，经过良好校准的预测器，其预测不确定性（或置信度）可以被认为是近似准确的。</p>
<p>为了让一种不确定性量化方法有意义，必须确保其经过了良好校准，因此，一个理想预测器的不确定性测度（置信度）本身必须是可信的（或没有偏差的），但实践结果表明，大多数情况下的不确定性估计都存在未校准的问题。</p>
<div class="note info flat"><p>上一节介绍的各种测度指标，大多是将预测结果的期望值作为假想真实值而得到的统计量，但该统计量是否具备真实的意义，则需要校准来保证。例如：某个预测器以预测方差作为不确定性的测度，但其给出的方差值却与真实的不确定性之间不匹配，那么该测度就是没有校准的；没有校准的不确定性测度从某种程度上来说等于没有得到<code>预测不确定性</code>，有时甚至还会对后续任务产生误导。</p>
</div>
<p>形式上，对于分类任务，校准可以被定义为：预测正确率与其置信度之间应当匹配。对于一个神经网络 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> ，如果其满足以下条件，则称其为经过校准过的 <sup class="refplus-num"><a href="#ref-265">[265]</a></sup></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="normal">∀</mi><mi>p</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo><mo>:</mo><mspace width="1em"></mspace><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mfrac><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><mo>⋅</mo><mi mathvariant="double-struck">I</mi><mrow><mo fence="true">{</mo><msub><mi>f</mi><mi>θ</mi></msub><msub><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mi>k</mi></msub><mo>=</mo><mi>p</mi><mo fence="true">}</mo></mrow></mrow><mrow><mi mathvariant="double-struck">I</mi><mrow><mo fence="true">{</mo><msub><mi>f</mi><mi>θ</mi></msub><msub><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mi>k</mi></msub><mo>=</mo><mi>p</mi><mo fence="true">}</mo></mrow></mrow></mfrac><mo><mover><mo><mo>⟶</mo></mo><mrow><mi>N</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></mover></mo><mi>p</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(37)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\forall p \in[0,1]: \quad \sum_{i=1}^{N} \sum_{k=1}^{K} \frac{y_{i, k} \cdot \mathbb{I}\left\{f_{\theta}\left(x_{i}\right)_{k}=p\right\}}{\mathbb{I}\left\{f_{\theta}\left(x_{i}\right)_{k}=p\right\}} \stackrel{N \rightarrow \infty}{\longrightarrow} p \tag{37}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">∀</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4397em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathbb">I</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">p</span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6897em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathbb">I</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">p</span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9857em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2893em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">⟶</span></span></span><span style="top:-3.711em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mrel mtight">→</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.011em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span><span class="tag"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">37</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>这里， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 代表置信度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">p \in [0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub><msub><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">f_{\theta}\left(x_{i}\right)_{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1864em;"><span style="top:-2.4003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x=x_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 时，预测类概率向量中第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 个类的预测置信度； $$\mathbb{I} \left{ \cdot \right}$$ 为指示函数，条件为真时等于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> ;条件为假时等于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y_{i, k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 为第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个训练样本的标签真实值所对应的独热编码向量中的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 个元素的值。这个公式的含义是：在置信度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 的所有预测中，正确率也应当达到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span>，例如， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>70</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p = 70\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">70%</span></span></span></span> 的所有预测中，应当有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>70</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">70\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">70%</span></span></span></span> 的预测是正确的， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>30</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">30\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">30%</span></span></span></span> 的预测是错误的。</p>
<blockquote>
<p>独热编码： 用一个长度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 的向量来表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 分类结果，其中仅代表所属类别的那一个元素的值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>，其他元素的值均为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>。</p>
</blockquote>
<p>对于回归任务，校准可以被定义为：预测的置信区间应该与从训练数据集中经验计算得出的置信区间相匹配 <sup class="refplus-num"><a href="#ref-265">[265]</a></sup> 。即：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="normal">∀</mi><mi>p</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo><mo>:</mo><mspace width="1em"></mspace><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mfrac><mrow><mi mathvariant="double-struck">I</mi><mrow><mo fence="true">{</mo><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><msub><mrow><mi mathvariant="normal">conf</mi><mo>⁡</mo></mrow><mi>p</mi></msub><mrow><mo fence="true">(</mo><msub><mi>f</mi><mi>θ</mi></msub><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo fence="true">}</mo></mrow></mrow><mi>N</mi></mfrac><mo><mover><mo><mo>⟶</mo></mo><mrow><mi>N</mi><mo>→</mo><mi mathvariant="normal">∞</mi></mrow></mover></mo><mi>p</mi></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(38)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\forall p \in[0,1]: \quad \sum_{i=1}^{N} \frac{\mathbb{I}\left\{y_{i} \in \operatorname{conf}_{p}\left(f_{\theta}\left(x_{i}\right)\right)\right\}}{N} \stackrel{N \rightarrow \infty}{\longrightarrow} p \tag{38}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">∀</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:1em;"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathbb">I</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mop"><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2893em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">⟶</span></span></span><span style="top:-3.711em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mrel mtight">→</span><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.011em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span><span class="tag"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">38</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>conf</mtext><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">\text{conf}_{p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord text"><span class="mord">conf</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 代表置信度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 预测分布区间。上式表示：真实值落入置信区间 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>conf</mtext><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">\text{conf}_{p}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord text"><span class="mord">conf</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 中的样本比例应当和置信度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 保持一致。</p>
<p>如果 <code>式 (37)</code> 和 <code>式 (38)</code> 的箭头左侧大于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span>，则深度神经网络被称为信心不足。如果小于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span>，则表示过于自信。</p>
<p>深度神经网络的校准特性可以使用 <code>可靠性图</code> 来可视化，如 <code>图 8</code> 所示。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220329132215-931d.webp" alt=""></p>
<blockquote>
<p>图 8：（a）过度自信分类器的可靠性图：每个柱条的准确率小于相应的置信度。 ( b ) 信心不足分类器的可靠性图：每个柱条的准确率大于相应的置信度。 ( c ) 良好校准分类器的可靠性图：置信度与每个柱条的实际准确率相符。</p>
</blockquote>
<p>校准误差通常是由 <strong>模型不确定性</strong> 引起的 <sup class="refplus-num"><a href="#ref-15">[15]</a></sup> ，因为 <strong>数据不确定性</strong> 代表了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 在表示真实世界中信息时的内生不确定性，其对于所有模型而言都是难以消除的。当然，如果能够正确地预测出 <strong>数据不确定性</strong> ，将会得到一个完美校准的神经网络。实践工作表明，越深的神经网络往往比浅层神经网络更容易过度自信 <sup class="refplus-num"><a href="#ref-15">[15]</a></sup><sup class="refplus-num"><a href="#ref-266">[266]</a></sup><sup class="refplus-num"><a href="#ref-267">[267]</a></sup> 。</p>
<p>由于校准误差主要来自于模型不确定性，因此本文 <code>第 3 节</code> 中有几种不确定性估计方法虽然没有显式地提到校准，但其实已经或多或少内含了对神经网络的校准 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-20">[20]</a></sup> ，因为这些方法本身就建立在分别估计<code>模型不确定性</code>和<code>数据不确定性</code>的思路之上，其主要目的就是为了减少<code>模型不确定性</code>。除了上述通过降低<code>模型不确定性</code>来改进校准的方法之外，还有大量文献研究了显式校准误差的方法。</p>
<p>本节将重点介绍上述第二类显式的方法，并且讨论校准误差的度量和评价手段。</p>
<p>值得注意的是，下文介绍的这些方法并没有减少<code>模型不确定性</code>，而只是将<code>模型不确定性</code>传播到了<code>数据不确定性</code>的表达上。例如，如果一个二分类的分类器出现过拟合，并以概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.0</span></span></span></span> 将测试集的所有样本预测为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 类，而实际上其中有一半测试样本的真实值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 类，则校准方法可能会将神经网络的输出重新映射（矫正、校准）到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span>，以便获得更可靠的信念。这个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.5</span></span></span></span> 的概率并不等同于<code>数据不确定性</code> ，而是代表了传播到（最终预测的）数据不确定性上的<code>模型不确定性</code>。</p>
<div class="note info flat"><p>（1）校准误差主要来自模型不确定性；</p>
<p>（2）大多数估计不确定性的方法，都会为模型不确定性建模，因而或多或少内含校准能力；</p>
<p>（3）实践表明，内含校准能力的估计方法不足以消除校准误差，尤其是深层神经网络，因此存在显式校准误差的必要性；</p>
<p>（4）校准并没有减少模型不确定性，只是对模型不确定性延伸至预测不确定性中的部分进行了标校。</p>
</div>
<h3 id="5-2-校准方法">5.2 校准方法</h3>
<p>校准方法可以根据所在的步骤分为三个主要类型：</p>
<ul>
<li>
<p>在<strong>训练阶段</strong>应用的正则化方法 <sup class="refplus-num"><a href="#ref-268">[268]</a></sup><sup class="refplus-num"><a href="#ref-269">[269]</a></sup><sup class="refplus-num"><a href="#ref-11">[11]</a></sup><sup class="refplus-num"><a href="#ref-270">[270]</a></sup><sup class="refplus-num"><a href="#ref-271">[271]</a></sup>。此类方法修改了目标函数、优化和/或正则化过程，以构建内含校准的深度神经网络。</p>
</li>
<li>
<p>在深度神经网络<sup class="refplus-num"><a href="#ref-15">[15]</a></sup><sup class="refplus-num"><a href="#ref-47">[47]</a></sup> 的<strong>训练过程之后</strong>应用后处理方法。此类方法需要一个预留的校准数据集来调整预测分值，以进行重校准。这种方法仅在<code>预留验证集</code>与 <code>训练数据集</code> 同分布的预期假设下才成立，而且验证数据集的大小也会影响校准结果。</p>
</li>
<li>
<p>神经网络不确定性估计方法。如 <code>第 3 节</code> 所述，那些依据<code>神经网络的预测置信度</code>来减少<code>模型不确定性</code>的估计方法，也能得到校准很好的预测器。这是因为剩下的 <strong>数据不确定性</strong> 更好地代表了预测的真实不确定性。此类方法大多基于 <code>贝叶斯方法</code> <sup class="refplus-num"><a href="#ref-272">[272]</a></sup><sup class="refplus-num"><a href="#ref-209">[209]</a></sup><sup class="refplus-num"><a href="#ref-273">[273]</a></sup><sup class="refplus-num"><a href="#ref-274">[274]</a></sup><sup class="refplus-num"><a href="#ref-16">[16]</a></sup> 或<code>深度集成方法</code> <sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-275">[275]</a></sup> 。</p>
</li>
</ul>
<p>下面，我们将更详细地介绍三种校准方法。</p>
<h4 id="5-2-1-正则化方法">5.2.1 正则化方法</h4>
<p>正则化方法的目标和思想与 <code>第 3.1 节</code> 中单一确定性方法非常相似，即主要是在单一前向传递网络中进行估计。不过，<code>第 3.1 节</code> 中的方法分别估计了<code>模型不确定性</code>和<code>数据不确定性</code>，而此处的正则化校准方法主要目的是将<code>模型不确定性</code>最小化。在预测阶段，此方法只能得到混合在一起的<code>预测不确定性</code>，无法再单独区分出<code>模型不确定性</code>。这也是我们将此方法与 <code>第 3.1 节</code> 中的方法分开介绍的主要动机。</p>
<div class="note info flat"><p>（1）正则化方法本质上属于单一确定性神经网络方法的一种；</p>
<p>（2）其基本思想是在训练阶段，通过正则化将模型不确定性降到最低；</p>
<p>（3）此类方法在预测阶段无法单独计算模型不确定性，因为其假设是模型不确定性已经通过正则化被消除了。</p>
</div>
<p><strong>（1）标签平滑</strong></p>
<p>在分类任务中，一种流行的基于正则化的校准方法是 <code>标签平滑（label smoothing）</code> <sup class="refplus-num"><a href="#ref-268">[268]</a></sup> 。该方法修改训练样本中的标签值，从真类的概率质量中分出较小的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">α</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 部分，并将其均匀地分配到假类中（ 即将真实值的独热向量转换为元素值在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> 之间的概率向量 ）。对于非平滑的硬标签，实际上无法达到最优，因为神经网络输出相对于 logits 向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 的梯度（见下式），只可能随着真类和假类 <code>logits 值</code> 之间的距离增加而收敛到零，导致正确类的 <code>logits</code> 比不正确类的 <code>logits</code> 大得多，并且不正确类的 <code>logits</code> 彼此非常不同。</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi mathvariant="normal">∇</mi><mi>z</mi></msub><mi mathvariant="normal">CE</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="normal">softmax</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>−</mo><mi>y</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow></mfrac><mo>−</mo><mi>y</mi></mrow></mstyle></mtd></mtr></mtable></mtd><mtd width="50%"></mtd><mtd><mtext>(39)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\nabla_{z} \operatorname{CE}(y, \hat{y}(z)) &amp;=\operatorname{softmax}(z)-y \\
&amp;=\frac{\exp (z)}{\sum_{i=1}^{K} \exp \left(z_{i}\right)}-y
\end{aligned} \tag{39}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.3979em;vertical-align:-1.949em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.449em;"><span style="top:-5.036em;"><span class="pstrut" style="height:3.427em;"></span><span class="mord"><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mord mathrm">CE</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">))</span></span></span><span style="top:-2.949em;"><span class="pstrut" style="height:3.427em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.949em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.449em;"><span style="top:-5.036em;"><span class="pstrut" style="height:3.427em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mop"><span class="mord mathrm">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span><span style="top:-2.949em;"><span class="pstrut" style="height:3.427em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.1288em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1709em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.949em;"><span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:4.3979em;vertical-align:-1.949em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">39</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><code>标签平滑</code> 避免了上述硬标签存在的问题，尽管它通常会导致更高的训练损失，但校准误差会有所降低，并且准确率通常也会提高 <sup class="refplus-num"><a href="#ref-270">[270]</a></sup> 。</p>
<p><strong>（2）修改目标函数</strong></p>
<p><code>Seo 等</code> <sup class="refplus-num"><a href="#ref-266">[266]</a></sup> 扩展了标签平滑的想法，目标直指减少模型不确定性。为此，他们在训练阶段，对随机神经网络的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 个前向传递进行了采样。对于某个训练样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\left(x_{i}, y_{i}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 个前向传递，会求得一个归一化的模型方差 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，其值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 个个体预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y}_{1}, \ldots, \hat{y}_{T}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和平均预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mo>=</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\bar{y}=\frac{1}{T} \sum_{t=1}^{T} \hat{y}_{t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7622em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 之间的 <code>平均 Bhattacharyya 系数</code> <sup class="refplus-num"><a href="#ref-281">[281]</a></sup> 。</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>α</mi><mi>i</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>B</mi><mi>C</mi><mrow><mo fence="true">(</mo><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mi>i</mi></msub><mo separator="true">,</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msqrt><mrow><msub><mover accent="true"><mi>y</mi><mo>ˉ</mo></mover><mrow><mi>i</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><mo>⋅</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mrow><mi>i</mi><mo separator="true">,</mo><mi>t</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub></mrow></msqrt></mrow></mstyle></mtd></mtr></mtable></mtd><mtd width="50%"></mtd><mtd><mtext>(40)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\alpha_{i} &amp;=\frac{1}{T} \sum_{t=1}^{T} B C\left(\bar{y}_{i}, \hat{y}_{t}\right) \\
&amp;=\frac{1}{T} \sum_{t=1}^{T} \sum_{k=1}^{K} \sqrt{\bar{y}_{i, k} \cdot \hat{y}_{i, t, k}}
\end{aligned} \tag{40}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:6.8259em;vertical-align:-3.1629em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.6629em;"><span style="top:-5.6629em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.2675em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.1629em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.6629em;"><span style="top:-5.6629em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">BC</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span><span style="top:-2.2675em;"><span class="pstrut" style="height:3.8283em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.898em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z" /></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.302em;"><span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.1629em;"><span></span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:6.8259em;vertical-align:-3.1629em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">40</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>基于该 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 值，<code>Seo 等</code> <sup class="refplus-num"><a href="#ref-266">[266]</a></sup> 引入了方差加权且集成置信度的损失函数（ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mrow><mi>V</mi><mi>W</mi><mi>C</mi><mi>I</mi></mrow></msup></mrow><annotation encoding="application/x-tex">L^{VWCI}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">VW</span><span class="mord mathnormal mtight" style="margin-right:0.07153em;">C</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span></span></span></span></span></span></span></span></span></span></span></span> ），它是两个相互矛盾的损失函数的凸组合：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msup><mi>L</mi><mrow><mi mathvariant="normal">V</mi><mi mathvariant="normal">W</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">I</mi></mrow></msup><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><msub><mi>α</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><msubsup><mi>L</mi><mrow><mi mathvariant="normal">G</mi><mi mathvariant="normal">T</mi></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>+</mo><msub><mi>α</mi><mi>i</mi></msub><msubsup><mi>L</mi><mi mathvariant="normal">U</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(41)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">L^{\mathrm{VWCI}}(\theta)=-\sum_{i=1}^{N}\left(1-\alpha_{i}\right) L_{\mathrm{GT}}^{(i)}(\theta)+\alpha_{i} L_{\mathrm{U}}^{(i)}(\theta) \tag{41}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">VWCI</span></span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord">−</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4065em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">GT</span></span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2935em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.3383em;vertical-align:-0.2935em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4065em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">U</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2935em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span><span class="tag"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">41</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>L</mi><mrow><mi>G</mi><mi>T</mi></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">L^{(i)}_{GT}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3383em;vertical-align:-0.2935em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.4065em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">GT</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2935em;"><span></span></span></span></span></span></span></span></span></span> 是为给定真值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 计算的平均交叉熵。 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>U</mi></msub></mrow><annotation encoding="application/x-tex">L_U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 表示均匀概率向量（人为设定的目标分布）和预测结果（类别概率向量）之间的<code>平均 KL 散度</code>。自适应平滑参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 将具有 <strong>高模型不确定性</strong> 的训练样本的预测推向均匀分布，同时增加具有 <strong>低模型不确定性</strong> 样本的预测分数。这样的话，单个样本的预测方差变小了，预测也可以通过单一的前向传递网络实现。</p>
<p><code>Pereyra 等</code> <sup class="refplus-num"><a href="#ref-269">[269]</a></sup> 通过将负熵添加到标准损失函数中来解决过度自信问题，因此惩罚会随着神经网络的预测置信度而增加。这导致基于熵的目标函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mi>H</mi></msup></mrow><annotation encoding="application/x-tex">L^H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span></span></span></span></span></span></span>，其定义为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msup><mi>L</mi><mi>H</mi></msup><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>y</mi><mi>i</mi></msub><mi>log</mi><mo>⁡</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo>−</mo><msub><mi>α</mi><mi>i</mi></msub><mi>H</mi><mrow><mo fence="true">(</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo fence="true">)</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(42)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">L^{H}(\theta)=-\frac{1}{N} \sum_{i=1}^{N} y_{i} \log \hat{y}_{i}-\alpha_{i} H\left(\hat{y}_{i}\right) \tag{42}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span><span class="tag"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">42</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo stretchy="false">(</mo><mover accent="true"><msub><mi>y</mi><mi>i</mi></msub><mo>^</mo></mover><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">H(\hat{y_i})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是输出的熵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是控制置信度惩罚力度的参数，其计算与 <code>VWCI 损失</code>等价。</p>
<p><strong>（3）mixup 数据增强</strong></p>
<p><code>Thulasidasan 等</code> 没有通过修改目标函数来正则化训练过程<sup class="refplus-num"><a href="#ref-278">[278]</a></sup> ，而是通过使用名为 <code>mixup</code> <sup class="refplus-num"><a href="#ref-282">[282]</a></sup> 的数据增强技术对其进行正则化。在 <code>mixup</code> 训练中，神经网络不仅在训练数据上进行训练，而且在由两个随机训练对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\left(x_{i}, y_{i}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>j</mi></msub><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\left(x_{j}, y_{j}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span> 的凸组合生成的虚拟训练样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo>~</mo></mover><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\tilde{x},\tilde{y})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 上进行训练， 也就是：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo>=</mo><mi>λ</mi><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><msub><mi>x</mi><mi>j</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(43)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\tilde{x} =\lambda x_i + (1 − \lambda ) x_j  \tag{43}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">43</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mover accent="true"><mi>y</mi><mo>~</mo></mover><mo>=</mo><mi>λ</mi><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy="false">)</mo><msub><mi>y</mi><mi>j</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(44)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\tilde{y} =\lambda y_i + (1 − \lambda ) y_j  \tag{44}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8623em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">~</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">λ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal">λ</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">44</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>根据 <sup class="refplus-num"><a href="#ref-278">[278]</a></sup> ，<code>mixup</code> 训练产生的标签平滑可以被视为一种基于熵的正则化，使得经过 <code>mixup</code> 训练的神经网络具备内在的校准能力。</p>
<p><code>Marõnas 等</code> <sup class="refplus-num"><a href="#ref-279">[279]</a></sup> 在流行的数据增强正则化技术中注意到了 <code>mixup</code> 训练，因为它能够提高校准和准确性。不过，他们也指出，在 <code>mixup</code> 训练中，混合后数据中的 <strong>数据不确定性</strong> 会影响校准，从而导致 <code>mixup</code> 并不一定必然会改善校准。同样，<code>Rahaman 和 Thiery</code> <sup class="refplus-num"><a href="#ref-234">[234]</a></sup> 实验表明，由 <code>mixup</code> 等数据增强技术引起的分布偏移，也会对校准产生负面影响。基于这一观察，<code>Marõnas 等</code> <sup class="refplus-num"><a href="#ref-279">[279]</a></sup> 提出了一个新的目标函数，它明确考虑了未混合样本的校准性能。受校准误差的期望（ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span>，参见 <code>第 5.3 节</code>）的启发，<code>Naeini 等</code> <sup class="refplus-num"><a href="#ref-283">[283]</a></sup> 通过批次准确率和批次样本的平均置信度之间的可微平方差来度量每个批次 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> 的未混合样本的校准性能。将混合和未混合样本的原始损失的加权组合作为总损失函数，并且仅在未混合样本上评估校准：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><msup><mi>L</mi><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow></msup><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>B</mi></mfrac><munder><mo>∑</mo><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow></munder><msup><mi>L</mi><mi>b</mi></msup><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>+</mo><mi>β</mi><mi>E</mi><mi>C</mi><msub><mi>E</mi><mi>b</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(45)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">L^{E C E}(\theta)=\frac{1}{B} \sum_{b \in B} L^{b}(\theta)+\beta E C E_{b} \tag{45}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1413em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">ECE</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.6509em;vertical-align:-1.3295em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3295em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">βEC</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:2.6509em;vertical-align:-1.3295em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">45</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>L</mi><mi>b</mi></msup><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L^{b}(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0991em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 是使用包含在批次 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">b</span></span></span></span> 中的训练和混合样本的原始非正则化损失，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 是一个超参数，用于控制给予批量校准误差的期望 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><msub><mi>E</mi><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">ECE_{b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">EC</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的相对重要性。通过将每个批次 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mo>∈</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">b \in B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 的批量校准误差添加到标准损失函数中，由 <code>mixup</code> 引起的错误校准被正则化。</p>
<p>在数据增强背景下，<code>Patel 等</code> <sup class="refplus-num"><a href="#ref-280">[280]</a></sup> 通过使用流形数据增强技术改进了不确定性估计的校准。<code>mixup</code> 通过训练样本生成虚拟样本，而流形对抗训练则使用对抗攻击生成域外样本。他们通过实验表明，在改进校准方面，流形对抗训练优于 <code>mixup</code> 训练。与 <sup class="refplus-num"><a href="#ref-280">[280]</a></sup> 类似，<code>Hendrycks 等</code> <sup class="refplus-num"><a href="#ref-277">[277]</a></sup> 表明，在训练中将分类器暴露于分布外的样本有助于改进校准。</p>
<h4 id="5-2-2-后处理方法">5.2.2 后处理方法</h4>
<p>在训练过程之后应用后处理（或事后）方法，旨在学习一个重校准函数。为此，训练数据的一个子集在训练过程中被保留下来用作校准集。重校准函数应用于神经网络的输出（ 例如 <code>logits</code> 向量 ），并且生成一个在保留校准集上学习后改进的校准。<code>Zhang 等</code> <sup class="refplus-num"><a href="#ref-48">[48]</a></sup> 讨论了事后校准方法应满足的三个要求：</p>
<ul>
<li>1）  保证准确率，即不应该影响预测器的性能。</li>
<li>2）  保证数据效率，即只需要一小部分样本作为预留校准数据集。</li>
<li>3）  只要有足够的数据可用于校准，就能够获得正确的重新校准图。</li>
</ul>
<p>此外，他们指出，没有任何一种现存方法可以同时满足三个要求。</p>
<p><strong>（1）分类任务：温度缩放（ Temp Scaling ）</strong></p>
<p>对于分类任务，事后校准最基本且有效的方法是<code>温度缩放</code> <sup class="refplus-num"><a href="#ref-15">[15]</a></sup> 。</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="normal">softmax</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><msup><mrow><mi>exp</mi><mo>⁡</mo></mrow><mrow><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi></mrow></msup><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msup><mrow><mi>exp</mi><mo>⁡</mo></mrow><mrow><msub><mi>z</mi><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi></mrow></msup></mrow></mfrac></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(46)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\operatorname{softmax}\left(z_{i}\right)=\frac{\exp ^{z_{i} / T}}{\sum_{j=1}^{K} \exp ^{z_{j} / T}} \tag{46}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">softmax</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.872em;vertical-align:-1.307em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.565em;"><span style="top:-2.1288em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">exp</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8301em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop">exp</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.307em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height:2.872em;vertical-align:-1.307em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">46</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>对于温度缩放而言，<code>softmax</code> 函数的温度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">T &gt; 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> 时是比较好的：<br>
对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T = 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>，该函数就是常规的 <code>softmax</code> 函数。<br>
对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>，输出的预测置信度降低，熵增加。<br>
对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T \in (0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>，输出的预测置信度增加，熵减小。</p>
<p>如上所述，完美校准的神经网络输出 <code>MAP 估计值</code>。由于学习的温度变换只能影响不确定性，因此原先基于对数似然的损失函数（如交叉熵）不必做特殊调整。虽然能够保持准确性和数据效率，但温度缩放的表现力是有限的 <sup class="refplus-num"><a href="#ref-48">[48]</a></sup> 。为了克服这一点，<code>Zhang 等</code> <sup class="refplus-num"><a href="#ref-48">[48]</a></sup> 进一步研究了多个温度缩放模型的集成方法，实现了更好的校准，同时保持了分类准确率并提高了数据效率和表达能力。</p>
<p><code>Kull 等</code> <sup class="refplus-num"><a href="#ref-284">[284]</a></sup> 受到非神经网络校准方法的启发，其中校准是按类别执行的一对多的二分类校准。他们表明，这种方法可以解释为学习预测对数似然的线性变换，然后是 <code>softmax</code> 函数。这又相当于在对数概率上训练一个密集层，因此该方法也很容易实现和应用。但显然，其无法保留原始预测。</p>
<p><strong>（2）回归任务：标准差缩放</strong></p>
<p>类似于分类神经网络的温度缩放，<code>Levi 等</code> <sup class="refplus-num"><a href="#ref-285">[285]</a></sup> 为回归神经网络引入了 <code>标准差缩放（std-scaling）</code>。顾名思义，该方法经过训练以重新调整给定神经网络的预测标准差。等效于使用交叉熵损失优化温度缩放，可以使用高斯对数似然函数作为损失来训练标准差缩放，这通常也用于回归神经网络的训练，这也给出了预测数据的不确定性。</p>
<p><code>Wenger 等</code> <sup class="refplus-num"><a href="#ref-47">[47]</a></sup> 提出了一种基于高斯过程 (GP) 的方法，该方法可用于校准具有任意置预测信度值的多类分类器，并通过校准神经网络提出了它们的方法。他们工作背后的主要思想是通过一个高斯过程来学习校准图，该过程在神经网络置信度预测和保留校准集中的相应真值上进行训练。对于这种方法，也不能保证原始预测的保存。</p>
<h4 id="5-2-3-使用不确定性估计方法进行校准">5.2.3 使用不确定性估计方法进行校准</h4>
<p>如上所述，尽量消除 <strong>模型不确定性</strong> 并给出 <strong>数据不确定性</strong> 的准确估计，会形成良好校准的预测器。</p>
<p>在基于深度集成 <sup class="refplus-num"><a href="#ref-31">[31]</a></sup><sup class="refplus-num"><a href="#ref-275">[275]</a></sup> 和贝叶斯神经网络的几项工作之后， <sup class="refplus-num"><a href="#ref-272">[272]</a></sup><sup class="refplus-num"><a href="#ref-209">[209]</a></sup><sup class="refplus-num"><a href="#ref-204">[204]</a></sup> 基于校准结果将它们的性能与其他基准方法进行了比较。<code>Lakshminarayanan 等</code> <sup class="refplus-num"><a href="#ref-31">[31]</a></sup> 和 <code>Mehrtash 等</code> <sup class="refplus-num"><a href="#ref-275">[275]</a></sup> 表明，与单一的神经网络相比，深度集成能够改进校准。</p>
<p>然而，<code>Rahaman 和 Thiery</code> <sup class="refplus-num"><a href="#ref-234">[234]</a></sup> 表明，对于使用了 <code>mixup</code> 正则化的特定设置，深度集成会增加校准误差。另一方面，他们表明，对平均后的预测应用温度缩放可以显著改善校准。</p>
<p>对于贝叶斯方法， <sup class="refplus-num"><a href="#ref-204">[204]</a></sup> 表明，将贝叶斯近似限制为深度神经网络的最后一个全连接层的权重已经足以显著改善校准。<code>Zhang 等</code> <sup class="refplus-num"><a href="#ref-273">[273]</a></sup> 和 <code>Laves 等</code> <sup class="refplus-num"><a href="#ref-274">[274]</a></sup> 表明使用 <code>MC Dropout</code> 计算的置信度估计很难进行校准。为了克服这一点，<code>Zhang 等</code> <sup class="refplus-num"><a href="#ref-273">[273]</a></sup> 提出了 <code>Structured Dropout</code>，它由 <code>Dropout</code> 通道、块或层组成，以促进模型多样性并减少校准误差。</p>
<h3 id="5-3-校准效果的评估">5.3 校准效果的评估</h3>
<p>评估校准包括度量预测分布和观测结果之间的统计一致性 <sup class="refplus-num"><a href="#ref-286">[286]</a></sup> 。对于分类任务，一些校准措施基于 <code>分区（ binning ）</code> 。为此，预测结果按照预测置信度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\hat p_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 排序，并分组到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个分区 $$\left {b_1,…,b_M \right }$$ 中。然后，用每个分区的平均置信度来评估其校准。</p>
<p>每个分区的平均置信度为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="normal">conf</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mo fence="true">∣</mo><msub><mi>b</mi><mi>m</mi></msub><mo fence="true">∣</mo></mrow></mfrac><munder><mo>∑</mo><mrow><mi>s</mi><mo>∈</mo><msub><mi>b</mi><mi>m</mi></msub></mrow></munder><msub><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi>s</mi></msub></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(47)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\operatorname{conf}\left(b_{m}\right)=\frac{1}{ \left | b_{m} \right | } \sum_{s \in b_{m}} \hat{p}_{s} \tag{47}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7237em;vertical-align:-1.4022em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4022em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">p</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height:2.7237em;vertical-align:-1.4022em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">47</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>每个分区的平均准确率为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="normal">acc</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mo fence="true">∣</mo><msub><mi>b</mi><mi>m</mi></msub><mo fence="true">∣</mo></mrow></mfrac><munder><mo>∑</mo><mrow><mi>s</mi><mo>∈</mo><msub><mi>b</mi><mi>m</mi></msub></mrow></munder><mi mathvariant="double-struck">I</mi><mrow><mo fence="true">(</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>s</mi></msub><mo>=</mo><msub><mi>y</mi><mi>s</mi></msub><mo fence="true">)</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(48)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\operatorname{acc}\left(b_{m}\right)=\frac{1}{\left|b_{m}\right|} \sum_{s \in b_{m}} \mathbb{I}\left(\hat{y}_{s}=y_{s}\right) \tag{48}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">acc</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.7237em;vertical-align:-1.4022em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4022em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbb">I</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span></span><span class="tag"><span class="strut" style="height:2.7237em;vertical-align:-1.4022em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">48</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><msub><mi>y</mi><mi>s</mi></msub><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{y_s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>、</mtext></mrow><annotation encoding="application/x-tex">、</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord cjk_fallback">、</span></span></span></span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>s</mi></msub></mrow><annotation encoding="application/x-tex">y_s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><msub><mi>p</mi><mi>s</mi></msub><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{p_s}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span> 分别指样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span> 的预测类标签、真实类标签和预测置信度。如 <sup class="refplus-num"><a href="#ref-15">[15]</a></sup> 中所述，当每个分区的准确率与置信度相匹配时，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">acc</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">conf</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{acc}(b_m) = \operatorname{conf}(b_m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">acc</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 时，置信度得到了良好的校准。</p>
<p><strong>（1）可靠性图及其变体</strong></p>
<p>对于模型校准的可视化评估， <sup class="refplus-num"><a href="#ref-287">[287]</a></sup> 引入的 <code>可靠性图</code> 被广泛使用。对于可靠性图，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">conf</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{conf}(b_m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是针对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">acc</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{acc}(b_m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">acc</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 绘制的。对于一个校准良好的模型，该图应该接近对角线，如 <code>图 8</code> 所示。基础的可靠性图并不区分不同类别，为了按照类别分析并提高校准的可解释性，<code>Vaienavicius 等</code> <sup class="refplus-num"><a href="#ref-286">[286]</a></sup> 使用了一种 <code>多维可靠性图</code> 的改进方案。</p>
<p><strong>（2）平均校准误差</strong></p>
<p>对于模型校准的定量评估，可以考虑不同的校准测度。</p>
<p><strong>校准误差的期望 ( <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> )</strong> 是一种广泛使用的基于分区的校准测度指标 <sup class="refplus-num"><a href="#ref-283">[283]</a></sup><sup class="refplus-num"><a href="#ref-15">[15]</a></sup><sup class="refplus-num"><a href="#ref-274">[274]</a></sup><sup class="refplus-num"><a href="#ref-275">[275]</a></sup><sup class="refplus-num"><a href="#ref-278">[278]</a></sup><sup class="refplus-num"><a href="#ref-47">[47]</a></sup> 。对于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span>，考虑了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个等间距的分区， $$\left{ b_1,…,b_ M\right}$$，其中 $$b_m$$ 表示置信度落入区间 $$I_{m}=\left[ \frac{m-1}{M}, \frac{m}{M}\right]$$ 的样本索引集。然后将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> 计算为逐分区的校准误差的加权平均，即：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mrow><mi mathvariant="normal">E</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">E</mi></mrow><mo>=</mo><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mfrac><mrow><mo fence="true">∣</mo><msub><mi>b</mi><mi>m</mi></msub><mo fence="true">∣</mo></mrow><mi>N</mi></mfrac><mrow><mo fence="true">∣</mo><mi mathvariant="normal">acc</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo fence="true">)</mo></mrow><mo>−</mo><mi mathvariant="normal">conf</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><mi>m</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">∣</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(49)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathrm{ECE}=\sum_{m=1}^{M} \frac{\left|b_{m}\right|}{N}\left|\operatorname{acc}\left(b_{m}\right)-\operatorname{conf}\left(b_{m}\right)\right| \tag{49}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"><span class="mord mathrm">ECE</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mop"><span class="mord mathrm">acc</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span><span class="tag"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">49</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p><strong>（3）静态校准误差（SCE）</strong></p>
<p>上述 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> 仅考虑了不分类别的预测置信度得分（ Top Labels ）。与此相对的，静态校准误差 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SCE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">SCE</span></span></span></span>) <sup class="refplus-num"><a href="#ref-288">[288]</a></sup><sup class="refplus-num"><a href="#ref-289">[289]</a></sup> 考虑了所有类的预测置信度 ( All Labels )，对于每个类别，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SCE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">SCE</span></span></span></span> 计算各分区内的校准误差，并在所有分区上取平均值，最后在按照类别进行平均。即：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mrow><mi mathvariant="normal">S</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">E</mi></mrow><mo>=</mo><mfrac><mn>1</mn><mi>K</mi></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><munderover><mo>∑</mo><mrow><mi>m</mi><mo>=</mo><mn>1</mn></mrow><mi>M</mi></munderover><mfrac><mrow><mo fence="true">∣</mo><msub><mi>b</mi><msub><mi>m</mi><mi>k</mi></msub></msub><mo fence="true">∣</mo></mrow><mi>N</mi></mfrac><mrow><mo fence="true">∣</mo><mi mathvariant="normal">conf</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><msub><mi>m</mi><mi>k</mi></msub></msub><mo fence="true">)</mo></mrow><mo>−</mo><mi mathvariant="normal">acc</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><msub><mi>m</mi><mi>k</mi></msub></msub><mo fence="true">)</mo></mrow><mo fence="true">∣</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(50)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathrm{SCE}=\frac{1}{K} \sum_{k=1}^{K} \sum_{m=1}^{M} \frac{\left|b_{m_{k}}\right|}{N}\left|\operatorname{conf}\left(b_{m_{k}}\right)-\operatorname{acc}\left(b_{m_{k}}\right)\right| \tag{50}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"><span class="mord mathrm">SCE</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm">acc</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span><span class="tag"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">50</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>这里 $$\operatorname{con} f\left(b_{m_{k}}\right)$$ 和 $$\operatorname{acc}\left(b_{m_{k}}\right)$$ 分别是 $$b_{m}$$ 对类标签 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 的置信度和准确率。<code>Nixon 等</code> <sup class="refplus-num"><a href="#ref-288">[288]</a></sup> 经验表明，全标签（ All Labels ）校准测度（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SCE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">SCE</span></span></span></span> ）在评估校准误差方面比顶级标签（ Top Labels ）校准措施（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> ）更有效。</p>
<p><strong>（4）自适应平均校准误差和静态校准误差</strong></p>
<p>与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SCE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">SCE</span></span></span></span> 将预测分组到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个等间距的分区中不同（这通常会导致每个分区的评估样本数量不同），自适应校准误差 <sup class="refplus-num"><a href="#ref-288">[288]</a></sup><sup class="refplus-num"><a href="#ref-289">[289]</a></sup> 自适应地将预测分组到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> 个不同的宽度但预测数量相同的分区中 。使用此自适应分区大小，自适应平均校准误差 ( <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">aECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> ) 定义为：</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mrow><mi mathvariant="normal">a</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">C</mi><mi mathvariant="normal">E</mi></mrow><mo>=</mo><mfrac><mn>1</mn><mi>R</mi></mfrac><munderover><mo>∑</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>R</mi></munderover><mrow><mo fence="true">∣</mo><mi mathvariant="normal">conf</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><mi>r</mi></msub><mo fence="true">)</mo></mrow><mo>−</mo><mi mathvariant="normal">acc</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><mi>r</mi></msub><mo fence="true">)</mo></mrow><mo fence="true">∣</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(51)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\mathrm{aECE}=\frac{1}{R} \sum_{r=1}^{R}\left|\operatorname{conf}\left(b_{r}\right)-\operatorname{acc}\left(b_{r}\right)\right| \tag{51}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"><span class="mord mathrm">aECE</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm">acc</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span><span class="tag"><span class="strut" style="height:3.0954em;vertical-align:-1.2671em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">51</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>和自适应静态校准误差 ( <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>S</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">aSCE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">SCE</span></span></span></span> )</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable width="100%"><mtr><mtd width="50%"></mtd><mtd><mrow><mi mathvariant="normal">aSCE</mi><mo>⁡</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>K</mi><mi>R</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><munderover><mo>∑</mo><mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow><mi>R</mi></munderover><mrow><mo fence="true">∣</mo><mi mathvariant="normal">conf</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><msub><mi>r</mi><mi>k</mi></msub></msub><mo fence="true">)</mo></mrow><mo>−</mo><mi mathvariant="normal">acc</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>b</mi><msub><mi>r</mi><mi>k</mi></msub></msub><mo fence="true">)</mo></mrow><mo fence="true">∣</mo></mrow></mrow></mtd><mtd width="50%"></mtd><mtd><mtext>(52)</mtext></mtd></mtr></mtable><annotation encoding="application/x-tex">\operatorname{aSCE}=\frac{1}{K R} \sum_{k=1}^{K} \sum_{r=1}^{R}\left|\operatorname{conf}\left(b_{r_{k}}\right)-\operatorname{acc}\left(b_{r_{k}}\right)\right|\tag{52}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mop"><span class="mord mathrm">aSCE</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">∣</span><span class="mop"><span class="mord mathrm" style="margin-right:0.07778em;">conf</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop"><span class="mord mathrm">acc</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mclose delimcenter" style="top:0em;">∣</span></span></span><span class="tag"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">52</span></span><span class="mord">)</span></span></span></span></span></span></p>
<p>正如 <sup class="refplus-num"><a href="#ref-280">[280]</a></sup> 和 <sup class="refplus-num"><a href="#ref-288">[288]</a></sup> 中的经验所示，自适应分区校准措施 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">aECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>S</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">aSCE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.05764em;">SCE</span></span></span></span> 同等数量时的等宽分区校准措施 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">ECE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">ECE</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mi>C</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">SCE</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">SCE</span></span></span></span> 更稳健。</p>
<p>重要的是要明确，在分类任务中，校准措施可能会受到测试数据不均衡问题的影响。即便按类别计算校准，计算的误差也会按类别中的样本数加权。进而数量较大的类有可能掩盖数量小的类中存在的不良校准，其表现与多分类任务中的准确率概念相似 <sup class="refplus-num"><a href="#ref-290">[290]</a></sup> 。</p>
<h2 id="6-数据集与基线">6 数据集与基线</h2>
<p>在本节中，我们收集常用任务和数据集，用于评估现有工作中的不确定性估计。此外，还介绍了通常用于与研究人员提出的方法进行比较的各种基线方法。通过对这些实验的相关信息进行回顾，我们希望研究人员和实践者都能从中受益。虽然前者可以对最近的基准测试任务、数据集和基线有一个基本的了解，以便可以设计适当的实验来更有效地验证他们的想法，但后者可能会使用提供的信息选择更相关的方法来开始基于对已验证该方法的任务和数据集的简要概述。</p>
<p>在下文中，我们将根据本次调研中使用的分类法，介绍 <code>表 4</code> 中总结的数据集和基线。</p>
<blockquote>
<p>表 4：根据本文分类法组织的现有工作中经常比较的基准方法、任务及其数据集</p>
</blockquote>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220329154449-565a.webp" alt=""></p>
<p>表格的结构旨在简明扼要地组织本节的主要内容，希望能够对相关工作提供一个清晰的概述。</p>
<p>我们将每个类别的方法分为四个块，并分别为每列提取最常用的任务、数据集和提供的基线。相应的文献列在每个块的底部，以方便查找。请注意，我们在这里关注方法比较，而不是架构选择，因此可能会缺少性能比较。由于空间限制和视觉密度，我们只展示了（研究过的）文献中使用频率最高的要素（任务、数据集、基线）。</p>
<h3 id="6-1-主要任务">6.1 主要任务</h3>
<p>（1） 回归任务。</p>
<p>评估不确定性估计方法最常见的任务之一是回归任务，其中研究离训练分布近和远的样本。</p>
<p>（2）校准任务（分类问题）。</p>
<p>此外，在分类问题的情况下，不确定性估计的校准经常被研究。进一步值得注意的任务是分布式（OOD）检测和对抗对抗性攻击的鲁棒性。在医学领域，语义分割结果的校准是主要的用例。</p>
<p>（3）分布外样本检测任务。</p>
<p>（4）主动学习任务</p>
<p>（5）连续学习任务</p>
<p>（6）强化学习任务</p>
<p>（7）对抗样本检测任务</p>
<h3 id="6-2-主要数据集">6.2 主要数据集</h3>
<p>在所有调研的文献中，数据集的选择大多是一致的。</p>
<p>对于回归，使用玩具数据集来可视化不确定区间，而根据（负）对数似然比较研究 UCI 数据集。</p>
<p>最常见的校准和 OOD 检测数据集是 MNIST、CIFAR10 和 CIFAR100 以及 SVHN，而 ImageNet 及其变体也经常被研究。</p>
<p>当研究 OOD 检测时，出现了不同组合方式，例如，在 SVHN 上评估在 CIFAR 变体上训练的模型、 MNIST 与自身的变体（如 not MNIST 和 Fashion MNIST）组合。</p>
<p>分类数据集也经常被扭曲和损坏，以研究对校准的影响，模糊了 OOD 检测和对抗性攻击之间的界限。</p>
<h3 id="6-3-主要基线">6.3 主要基线</h3>
<p>到目前为止，最常用的基线是 <code>Monte Carlo (MC) Dropout</code> 和 <code>深度集成</code>，而 <code>确定性模型的 softmax 输出</code> 几乎总是被用作一种替代基线。有趣的是，在每种方法（贝叶斯神经网络、集成方法、单一确定性模型和输入增强方法）中，有些基线比其他基线更受欢迎。例如：</p>
<ul>
<li>贝叶斯神经网络最常与变分推断方法进行比较，如<code>反向传播 (BBB)</code> 或<code>概率反向传播 (PBP)</code> 贝叶斯方法</li>
<li>单一确定性模型，在 OOD 检测任务中，常与<code>基于距离的方法</code>进行比较</li>
<li>总体而言，贝叶斯神经网络方法显示了更多样化的任务</li>
<li>所有方法在 ImageNet 等大型数据集上的评估频率较低</li>
</ul>
<p>为了进一步方便从业者的访问，我们提供了作者在基线列中标识的所有常见基线的官方实现（用星号标记）及其网络链接。如果没有提供官方实现，我们会链接到本次调研时在 GitHub 上找到的排名最高的实现。该列表也可以在 <a target="_blank" rel="noopener" href="https://github.com/JakobCode/UncertaintyInNeuralNetworks_Resources">我们的 GitHub 存储库</a>中找到。</p>
<p>相关基线包括：Softmax（TensorFlow、PyTorch）、MCDropout（TensorFlow；PyTorch）、DeepEnsembles（TensorFlow；PyTorch）、BBB（PyTorch), Normalizing Flow (TensorFlow, PyTorch)、 PBP、 SWAG (1, 2)、 KFAC (PyTorch; TensorFlow)、 DVI (TensorFlow, PyTorch)、 HMC、 VOGN、 INF、 MFVI、SGLD、Temperature Scaling、GAN、Dirichlet 、Mahalanobis。</p>
<h2 id="7-不确定性估计的应用">7 不确定性估计的应用</h2>
<p>从实践的角度来看，估计深度神经网络中不确定性的主要动机是能够对接收到的预测进行分类并做出更自信的决策。本节对上述动机进行了简要概述和示例。在第一部分，我们讨论了如何在主动学习和强化学习中使用不确定性。随后，我们讨论了在医学图像分析、机器人技术和地球观测等领域工作的社区的兴趣。这些应用领域代表性地用于不确定性估计起重要作用的大量领域。挑战和概念可以（并且应该）转移到任何感兴趣的应用领域</p>
<h3 id="7-1-主动学习">7.1 主动学习</h3>
<p>为深度神经网络的监督学习收集有标签数据的过程非常费力、耗时、成本高昂。为了减少标记工作，<code>图 10</code> 所示的<code>主动学习框架</code>在随时间增加的不同标记数据集上，依次训练深度神经网络<sup class="refplus-num"><a href="#ref-292">[292]</a></sup>。特别是，在给定一个小的有标签数据集和一个大的无标签数据集时，主动学习框架会从小标记数据开始学习，并根据<code>采集函数</code>决定从候选池中选择哪些无标签样本最需要补充标记，将该选定的数据添加到训练数据集中，并在更新的训练数据集上训练新的 DNN。上述过程重复运行，训练集会随时间推移而增加。</p>
<p><code>不确定性采样</code>是<code>采集函数</code>中最常用的标准之一 <sup class="refplus-num"><a href="#ref-293">[293]</a></sup> ，其中<code>预测不确定性</code>决定了哪些训练样本具有最高不确定性，应该接下来被标记。在深度学习应用中基于不确定性的主动学习策略已成功用于多项工作  <sup class="refplus-num"><a href="#ref-23">[23]</a></sup><sup class="refplus-num"><a href="#ref-24">[24]</a></sup><sup class="refplus-num"><a href="#ref-294">[294]</a></sup><sup class="refplus-num"><a href="#ref-25">[25]</a></sup><sup class="refplus-num"><a href="#ref-26">[26]</a></sup> 。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220329155420-caa4.webp" alt=""></p>
<blockquote>
<p>图 10：主动学习框架：采集函数评估神经网络的预测不确定性，用于选择无标签数据。被选中的数据被外部资源打上标签后，添加到有标签数据集中，用于下一轮训练并提高预测器性能</p>
</blockquote>
<h3 id="7-2-强化学习">7.2 强化学习</h3>
<p>深度强化学习的一般框架如 <code>图 11</code> 所示。在强化学习的背景下，<strong>不确定性估计可用于解决探索-利用困境</strong>。也就是说，不确定性估计可用于有效地平衡 <code>对未知环境的探索</code> 与 <code>从已知环境中提取知识并利用</code>。例如，如果机器人与未知环境交互，机器人可以通过推断其不确定性来安全地避免灾难性故障。为了估计强化学习框架中的不确定性，<code>Huang 等</code>  <sup class="refplus-num"><a href="#ref-27">[27]</a></sup>  使用了一组自举模型（ 依据在原始数据集上采样得到的不同训练集，训练得到的不同模型 ）的集成方法，而 <code>Gal 和 Ghahramani</code>  <sup class="refplus-num"><a href="#ref-20">[20]</a></sup>  通过 Dropout 采样近似贝叶斯推断。受  <sup class="refplus-num"><a href="#ref-20">[20]</a></sup>  和  <sup class="refplus-num"><a href="#ref-27">[27]</a></sup>  的启发，<code>Kahn 等</code>  <sup class="refplus-num"><a href="#ref-28">[28]</a></sup>  和 <code>L̈otjens 等</code>  <sup class="refplus-num"><a href="#ref-29">[29]</a></sup>  使用了混合深度贝叶斯网络，对自举模型的集成执行 Dropout 采样。如需进一步阅读，<code>Ghavamzadeh 等</code>  <sup class="refplus-num"><a href="#ref-295">[295]</a></sup>  对贝叶斯强化学习进行了调查。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220329155521-b043.webp" alt=""></p>
<blockquote>
<p>图 11：强化学习框架：代理（Agent）通过执行会影响代理下一个状态的特定动作与环境交互。代理观测到与执行动作相关的成本奖励，并根据深度神经网络学习的策略抉择使用哪个响应动作。然而，与所预测的动作相关的<code>预测不确定性</code>，可以帮助智能体决定是否执行所预测的动作。</p>
</blockquote>
<h3 id="7-3-不确定性的实际应用">7.3 不确定性的实际应用</h3>
<p>随着在许多领域中越来越多地使用深度学习方法，估计和处理不确定性变得越来越重要。一方面，不确定性估计在风险最小化方面起着重要作用，这在许多应用领域都是必需的。另一方面，许多领域只提供具有挑战性的数据源，难以控制和验证。这使得<code>生成可信赖的基本事实</code>这一任务变得非常具有挑战性。下面将介绍三个不确定性发挥重要作用的重要领域，即自动驾驶、医学图像分析和地球观测。</p>
<h4 id="7-3-1-医学分析">7.3.1 医学分析</h4>
<p>由于许多疾病的大小、形状和位置因患者而异，因此估计预测不确定性对于病变分析检测  <sup class="refplus-num"><a href="#ref-1">[1]</a></sup><sup class="refplus-num"><a href="#ref-3">[3]</a></sup> 、肺节点分割 <sup class="refplus-num"><a href="#ref-296">[296]</a></sup> 、脑肿瘤分割  <sup class="refplus-num"><a href="#ref-152">[152]</a></sup><sup class="refplus-num"><a href="#ref-248">[248]</a></sup><sup class="refplus-num"><a href="#ref-249">[249]</a></sup><sup class="refplus-num"><a href="#ref-2">[2]</a></sup><sup class="refplus-num"><a href="#ref-261">[261]</a></sup> 、肝期疟疾图像中的寄生虫分割  <sup class="refplus-num"><a href="#ref-262">[262]</a></sup> 、胸片异常识别  <sup class="refplus-num"><a href="#ref-297">[297]</a></sup> ，以及年龄估计 <sup class="refplus-num"><a href="#ref-6">[6]</a></sup> 等医学图像应用至关重要。</p>
<p>在这里，不确定性估计特别提高了深度神经网络决策的可解释性  <sup class="refplus-num"><a href="#ref-298">[298]</a></sup> 。它们对于理解分割结果的可靠性、检测错误分割区域、指导人类专家完成细化任务等至关重要  <sup class="refplus-num"><a href="#ref-249">[249]</a></sup> 。校准良好且可靠的不确定性估计使临床专家能够正确判断是否可信 <sup class="refplus-num"><a href="#ref-298">[298]</a></sup> 。基于 <code>MC Dropout</code>  <sup class="refplus-num"><a href="#ref-152">[152]</a></sup><sup class="refplus-num"><a href="#ref-296">[296]</a></sup><sup class="refplus-num"><a href="#ref-1">[1]</a></sup><sup class="refplus-num"><a href="#ref-2">[2]</a></sup><sup class="refplus-num"><a href="#ref-3">[3]</a></sup><sup class="refplus-num"><a href="#ref-263">[263]</a></sup><sup class="refplus-num"><a href="#ref-4">[4]</a></sup><sup class="refplus-num"><a href="#ref-5">[5]</a></sup><sup class="refplus-num"><a href="#ref-6">[6]</a></sup> 、<code>spike-and-slab Dropout</code>  <sup class="refplus-num"><a href="#ref-261">[261]</a></sup>  和 <code>空间 Dropout</code>  <sup class="refplus-num"><a href="#ref-262">[262]</a></sup>，<code>Wang 等</code>  <sup class="refplus-num"><a href="#ref-248">[248]</a></sup><sup class="refplus-num"><a href="#ref-249">[249]</a></sup>  使用测试时数据增强的方法来估计医学图像分割中与数据相关的不确定性。</p>
<h4 id="7-3-2-机器人">7.3.2 机器人</h4>
<p>机器人是在现实世界中感知、决定、计划和行动的主动代理，所有这些行动都基于他们对世界的不完整知识。作为结果，机器人的错误不仅会导致自己的任务失败，还会危及人的生命，例如在手术机器人、自动驾驶汽车、太空机器人等的情况下。因此，与计算机视觉和其他离线场景大不相同，深度学习的机器人应用提出了比较独特的研究挑战 <sup class="refplus-num"><a href="#ref-299">[299]</a></sup> ，例如，<code>测试条件与训练数据来自相同分布的假设（即同分布假设）</code> 在许多机器人场景中通常是无效的，这导致深度神经网络在不受控和有害条件下的性能出现恶化。这就提出了 “如何估计深度神经网络的预测不确定性，以避免灾难性故障” 的新问题。回答这些问题在机器人技术中至关重要，因为期望数据驱动方法始终准确（ 在从控制到感知的许多方面 ）可能是一个崇高的目标。对不确定性的推理有助于机器人利用深度学习的最新成果。</p>
<p>在深度学习  <sup class="refplus-num"><a href="#ref-300">[300]</a></sup> 出现之前，使用不确定性的<code>推理</code>和<code>概率表示</code>，而非单纯依赖于最大似然估计，一直是机器人研究的核心之一。在机器人感知中，已经提出了几种不确定性感知方法，从<code>定位技术</code>  <sup class="refplus-num"><a href="#ref-301">[301]</a></sup><sup class="refplus-num"><a href="#ref-302">[302]</a></sup><sup class="refplus-num"><a href="#ref-303">[303]</a></sup>  到<code>同步定位与地图构建 (SLAM)</code> 框架  <sup class="refplus-num"><a href="#ref-304">[304]</a></sup><sup class="refplus-num"><a href="#ref-305">[305]</a></sup><sup class="refplus-num"><a href="#ref-306">[306]</a></sup><sup class="refplus-num"><a href="#ref-307">[307]</a></sup> 。因此，许多概率方法（ 例如因子图  <sup class="refplus-num"><a href="#ref-308">[308]</a></sup><sup class="refplus-num"><a href="#ref-309">[309]</a></sup> ）依然是先进消费产品（ 例如机器人真空吸尘器、无人机 ）的主力军。在规划和控制场景中，估计问题被广泛视为<code>贝叶斯顺序学习</code>问题，诸如 <code>POMDP</code>  <sup class="refplus-num"><a href="#ref-310">[310]</a></sup><sup class="refplus-num"><a href="#ref-311">[311]</a></sup>  之类的顺序决策框架，均将潜在的规划问题视为概率处理问题。通过概率表示，许多强化学习算法得到了现实世界中安全交互稳定性保证需求的支撑 <sup class="refplus-num"><a href="#ref-312">[312]</a></sup><sup class="refplus-num"><a href="#ref-313">[313]</a></sup><sup class="refplus-num"><a href="#ref-314">[314]</a></sup> 。另外还有一些其他进展，内容涵盖推理（ 语义到几何联合推理 <sup class="refplus-num"><a href="#ref-315">[315]</a></sup> ）、认知（ 例如主动感知 <sup class="refplus-num"><a href="#ref-316">[316]</a></sup> ）、学习（ 例如主动学习 <sup class="refplus-num"><a href="#ref-317">[317]</a></sup><sup class="refplus-num"><a href="#ref-318">[318]</a></sup><sup class="refplus-num"><a href="#ref-319">[319]</a></sup>）和未知对象识别 <sup class="refplus-num"><a href="#ref-320">[320]</a></sup><sup class="refplus-num"><a href="#ref-321">[321]</a></sup><sup class="refplus-num"><a href="#ref-322">[322]</a></sup> ）。</p>
<p>同样，随着深度学习的出现，许多研究人员提出了新方法来估计深度学习中的不确定性，以及如何进一步利用不确定性信息。与许多通用方法不同，我们将特定于任务的方法及其在实践中的应用总结如下。</p>
<ul>
<li>比较值得注意的是， <sup class="refplus-num"><a href="#ref-323">[323]</a></sup> 提出了使用自编码器执行新颖性检测，该方法中自编码器重建的输出用于计算人们可以信任网络预测的程度。</li>
<li><code>Peretroukhin 等</code> <sup class="refplus-num"><a href="#ref-324">[324]</a></sup>  为具有不确定性的<code>旋转学习问题 (Rotational learning problems )</code> 开发了 <code>SO(3) 表示</code>和不确定性估计框架。</li>
<li>
<sup class="refplus-num"><a href="#ref-325">[325]</a></sup><sup class="refplus-num"><a href="#ref-28">[28]</a></sup><sup class="refplus-num"><a href="#ref-326">[326]</a></sup><sup class="refplus-num"><a href="#ref-327">[327]</a></sup> 展示了不确定性感知，这是机器人强化学习算法在现实世界中的应用之一。
</li>
<li>
<sup class="refplus-num"><a href="#ref-328">[328]</a></sup><sup class="refplus-num"><a href="#ref-329">[329]</a></sup>  提出在 `MC-Dropout` 基础上使用空间信息。
</li>
<li>
<sup class="refplus-num"><a href="#ref-207">[207]</a></sup><sup class="refplus-num"><a href="#ref-330">[330]</a></sup><sup class="refplus-num"><a href="#ref-331">[331]</a></sup> 开发了基于深度学习的定位系统以及不确定性估计。
</li>
<li>其他方法还可以学习机器人过去的故障经验，或检测预测器的不一致性  <sup class="refplus-num"><a href="#ref-332">[332]</a></sup><sup class="refplus-num"><a href="#ref-333">[333]</a></sup> 。</li>
</ul>
<p>总之，机器人社区既是不确定性估计框架的用户，也是开发者。</p>
<p>然而，机器人技术对深度神经网络的不确定性估计方法提出了几个独特的挑战。例如：</p>
<ul>
<li>如何限制计算负担并构建可以在计算能力有限的机器人（例如空中机器人、太空机器人等）上执行的实时方法；</li>
<li>如何利用空间和时间信息，因为机器人是顺序感知的，而不是拥有一批用于不确定性估计的训练数据；</li>
<li>机器人是否可以选择最不确定的样本并在线更新学习器；</li>
<li>机器人能否在不确定时有目的地操纵场景。</li>
</ul>
<p>上述大多数挑战都是由机器人自身属性引起的，它们毕竟是物理系统。</p>
<h3 id="7-3-3-对地观测">7.3.3 对地观测</h3>
<p><strong>（1）现实世界的可变性</strong></p>
<p>对地观测系统越来越多地用于制定城市规划  <sup class="refplus-num"><a href="#ref-334">[334]</a></sup> 、资源管理  <sup class="refplus-num"><a href="#ref-335">[335]</a></sup> 、灾害响应  <sup class="refplus-num"><a href="#ref-336">[336]</a></sup>  等相关决策任务。目前，太空中有数百颗不同航天机构和私营公司拥有的对地观测卫星。<code>图 12</code> 显示了<code>欧洲航天局 (ESA)</code> 拥有的卫星。与许多其他领域一样，深度学习在过去几年中在对地观测领域也取得了初步成功 <sup class="refplus-num"><a href="#ref-337">[337]</a></sup> 。这些早期成功包括对计算机视觉深度学习最新成果的采用，并将其应用于经策划的小型地球观测数据集上 <sup class="refplus-num"><a href="#ref-337">[337]</a></sup> 。</p>
<p>但与此同时，底层数据带来了巨大挑战性。虽然对地观测数据的数据量很大，但自然界的数据可变性更是如此。这种可变性是由不同的传感器类型、空间变化（例如不同的区域和分辨率）、时间变化（例如变化的光照条件、天气条件、季节）等多种因素引起的。因此，除了海量数据对不确定性估计方法的高效性提出的挑战之外，对地观测领域还存在很多可以通过不确定性估计来解决的问题。总而言之，对地观测应用的敏感性、对地观测系统的性质、具有挑战性的对地观测数据等，使不确定性估计技术在该领域非常重要。在过去几年中，尽管有数百篇关于对地观测深度学习的出版物，但其中和上述系统的不确定性度量和应用有关的文献相对较少。</p>
<p><strong>（2）分布外数据</strong></p>
<p>由于数据的巨大变化，在测试时收到的数据样本通常不会被训练数据分布充分覆盖。例如，在为当地气候区分类准备训练数据时，人类专家可能只看到没有障碍物且结构清晰可见的图像。当在此数据集上训练的模型部署在现实世界中时，它可能会看到云遮挡结构或雪的图像，从而使其看起来完全不同。</p>
<p>此外，对地观测数据中的<code>类别分布</code>范围非常广泛。例如，世界上有数百万种房屋类型，没有任何训练数据可以包含所有类型的样本。那么，分布外样本检测器应该如何设定界限，并将符合条件的房屋定义为分布外样本呢？</p>
<p>因此，分布外样本检测在对地观测领域非常重要，而不确定性估计和度量将在其中发挥重要作用 <sup class="refplus-num"><a href="#ref-22">[22]</a></sup> 。</p>
<p><strong>（3）数据融合中的不确定性</strong></p>
<p>对地观测中的另一个常见任务是数据融合，其中不确定性也可以发挥重要作用。大众生活中的光学图像通常只包含 RGB 等少量通道。但对地观测数据可以包含多达数百个通道，同时还有不同空间、时间和语义性质的不同传感器。对这些不同来源和渠道的信息进行融合，会将来源中的不确定性传播到最终预测结果中。此处的挑战在于，开发的方法应当不仅能够估计不确定性，还可以单独估计来自不同来源的贡献量，并学会聚焦给定样本置信度高的数据源 <sup class="refplus-num"><a href="#ref-338">[338]</a></sup> 。</p>
<p><strong>（4）数据采集过程中的不确定性</strong></p>
<p>与图像采集设备靠近拍摄对象的正常计算机视觉场景不同，对地观测卫星距离地面数百公里。传感器的灵敏度、大气吸收特性和表面反射特性都会导致采集数据的不确定性。整合对地观测系统的物理知识，其中还包含有关这些系统中不确定性模型的信息，是另一个重要而未解决的问题。</p>
<p>在对地观测的某一些应用中，对不确定性的度量不仅是一件好事，而且是一个重要要求。例如，来自对地观测数据的地理变量可能被同化为过程模型（ 海洋、水文、天气、气候等 ），而这种同化需要被估计变量的概率分布。</p>
<p><img src="https://xishansnowblog.oss-cn-beijing.aliyuncs.com/images/images/stats-20220329160038-857d.webp" alt=""></p>
<blockquote>
<p>图 12：欧洲航天局 (ESA) 开发的地球观测任务  <sup class="refplus-num"><a href="#ref-339">[339]</a></sup> 。</p>
</blockquote>
<h2 id="8-结论与展望">8 结论与展望</h2>
<h3 id="8-1-结论">8.1 结论</h3>
<p><strong>当前的不确定性估计方法在实际应用中的效果如何呢？</strong></p>
<p>尽管过去几年神经网络的不确定性估计方面取得了许多进展，但它们在实际任务和安全关键应用中的采用仍然有限。造成这种情况的原因有很多，下面一一讨论：</p>
<p><strong>（1）缺少在现实世界问题中对现有方法的验证</strong></p>
<p>尽管深度神经网络已成为解决众多计算机视觉和医学图像处理任务的事实标准，但大多数现有模型无法适当估计其推断方法所固有的不确定性，尤其是在现实世界应用中。</p>
<p>这主要是因为基线模型大多是使用标准数据集开发的，例如 <code>Cifar10/100</code>、<code>ImageNet</code> 或众所周知的回归数据集，这些数据集特定于特定用例，因此不一定适用于复杂的现实世界环境，例如，低分辨率卫星数据或其他受噪声影响的数据源。</p>
<p>尽管来自其他领域的许多研究人员在他们的领域 <sup class="refplus-num"><a href="#ref-21">[21]</a></sup><sup class="refplus-num"><a href="#ref-10">[10]</a></sup><sup class="refplus-num"><a href="#ref-8">[8]</a></sup> 中应用了不确定性估计，但目前还没有基于不同现实世界应用的现有方法的广泛且结构化的评估。 <sup class="refplus-num"><a href="#ref-56">[56]</a></sup> 中的工作已经为现实生活中的验证评估迈出了第一步。</p>
<p><strong>（2）缺乏标准化的评估准则或协议</strong></p>
<p>不确定性估计的现有评估方法，更适合于比较那些基于可测量指标的不确定性估计方法，例如：校准 <sup class="refplus-num"><a href="#ref-340">[340]</a></sup> 或分布外样本检测性能 <sup class="refplus-num"><a href="#ref-32">[32]</a></sup>。如 <code>第 6 节</code> 所述，这些测试是在机器学习社区内的标准集上实施的。此外，这些实验的细节可能因实验设置不同而异 <sup class="refplus-num"><a href="#ref-214">[214]</a></sup>。</p>
<p>至今，仍然缺少一个明确的、标准化的、建立在不确定性估计方法基础上的测试协议。对于其他领域的研究人员来说，他们很难直接找到感兴趣领域的最新不确定性估计技术进展，更不用说关注哪个子领域了。这使得对新方法的直接比较变得困难，也限制了现有不确定性估计方法的接受和采纳程度。</p>
<p><strong>（3）无法评估与某个单一决策相关的不确定性</strong></p>
<p>用于度量不确定性估计性能（例如，校准误差的期望）的现有措施，基本上都是对于整个测试数据集的。与不平衡数据集上的分类任务等效，这意味着与单一样本或一小组样本相关的不确定性，可能会偏向其他数据集的性能。但在实际应用中，相较于利用测试数据建立起来的聚合可靠性而言，对某一次预测置信度的可靠性评估将会提供更多的可能性<sup class="refplus-num"><a href="#ref-341">[341]</a></sup>。特别是对于任务和安全关键型应用，逐点的置信可靠度评估措施可能至关重要，而且是迫切需要的。</p>
<p><strong>（4）缺乏不确定性的真实值</strong></p>
<p>当前方法大多是经验主义评估，其性能往往通过合理和可解释的不确定性值来强调，可用于验证的不确定性真实值通常不可用。此外，即便现有方法在给定数据集上进行了校准，也不能简单地将其结果迁移到任何其他数据集，因为必须意识到数据分布的变化，并且许多领域只能覆盖真实数据环境的一小部分。</p>
<p>在对地观测等应用领域，准备大量训练数据既困难又昂贵，因此可以使用合成数据来训练模型。对于这种人为产生的数据，应考虑标签和数据中的人为不确定性，以便更好地了解不确定性估计性能。真实数据与合成数据之间的差距，或估计的不确定性与真实的不确定性之间的差距，进一步会限制现有不确定性估计方法的采纳程度。</p>
<p><strong>（5）可解释性问题</strong></p>
<p>现有的神经网络不确定性估计方法提供了对确定性的预测，但没有任何关于不确定性产生原因的线索。尽管这些确定性值对于人类观察者来说通常看起来合理，但人们不知道这些不确定性是否实际上是基于人类观测者所做的相同观测到来预测的。在不确定某个不确定性估计的原因和动机的情况下，将方法从一个数据集迁移到另一个数据集，甚至仅仅是域偏移，都很难在保证性能的情况下实现。关于安全关键的现实生活应用，缺乏可解释性使得现有方法的应用变得更加困难。</p>
<p>除了神经网络决策的可解释性之外，现有不确定性估计方法在更高层次上还没有得到很好的理解。例如，对<code>单一确定性方法</code>、<code>集成方法</code>或<code>贝叶斯方法</code> 行为特性的解释是当前的一个研究方向，并且难以把握其中的每个细节 <sup class="refplus-num"><a href="#ref-227">[227]</a></sup>。然而，理解这些方法是如何操作和捕获不确定性的，对于识别优化途径、检测和表征不确定性、故障和重要缺点是至关重要的 <sup class="refplus-num"><a href="#ref-227">[227]</a></sup>。</p>
<h3 id="8-2-展望">8.2 展望</h3>
<p><strong>（1）通用评估框架</strong></p>
<p>正如上面已经讨论过的，不确定性方法的评估仍然存在问题，例如缺乏“基本事实”不确定性、无法在单个实例上进行测试以及标准化的基准测试协议等。为了解决这些问题，提供包含各种具体基线数据集和涵盖所有类型不确定性的评估指标的评估协议无疑将有助于推动不确定性估计研究。此外，还应考虑对风险规避和最坏情况的评估。这意味着，具有非常高的预测不确定性的不确定性预测永远不会失败，例如对红色或绿色交通灯的预测。这种通用协议将使研究人员能够轻松地将不同类型的方法与已建立的基准以及现实世界的数据集进行比较。会议和期刊应鼓励采用这种标准评估协议。</p>
<p><strong>（2）基线的专家系统比较</strong></p>
<p>目前还没有对现实世界应用中不确定性估计的现有方法进行广泛和结构化的比较。在当前的机器学习研究论文中，对现实世界数据的评估甚至不是标准的。</p>
<p>因此，在给定特定应用的情况下，尚不清楚哪种方法的不确定性估计效果最好，以及最新的方法在现实世界的例子中是否也优于旧方法。这也部分是由于其他领域的研究人员使用不确定性估计方法，通常在特定问题或手动数据集上成功应用单一方法。考虑到这一点，有几点可以用来在不同的研究领域进行更好的比较。例如，领域专家还应该相互比较不同的方法，并介绍该领域单一方法的弱点。同样，为了更好地比较多个领域，可以在一个中央平台上收集和交换不同现实世界领域中所有作品的集合。这样的平台还可以帮助机器学习研究人员在现实世界中提供额外的挑战来源，并为广泛突出当前最先进方法的弱点铺平道路。</p>
<p>谷歌关于神经网络不确定性基线的存储库 <sup class="refplus-num"><a href="#ref-340">[340]</a></sup> 可能是这样一个平台，也是朝着实现这一目标迈出的一步。</p>
<p><strong>（3）不确定性的真实值</strong></p>
<p>由于缺乏不确定性的真实值，验证现有方法仍然很困难。可以以类似 ImageNet 的方式比较方法的实际不确定性真实值，将使对单个样本的预测进行评估成为可能。为此，可能会更详细地研究对数据生成过程和出现的不确定性来源（例如标记过程）的评估。</p>
<p><strong>（4）可解释性和物理模型</strong></p>
<p>了解产生错误的高确定性或低确定性的真是原因，会使各种方法在现实生活中应用变得更加容易，并增加人们对这些方法的信任度。最近，<code>Antoran</code> 等 <sup class="refplus-num"><a href="#ref-342">[342]</a></sup> 声称已经发表了关于可解释不确定性估计的第一篇著作。一般来说，不确定性估计是迈向可解释人工智能的重要一步。可解释的不确定性估计将更深入地理解神经网络的决策过程，在深度神经网络的实际部署中，该决策过程应在保持现实世界适用性同时，包含期望的风险规避能力（尤其是安全关键应用程序）。</p>
<p>此外，基于物理的论点在提高可解释性方面具有巨大潜力。虽然深度神经网络非常灵活和高效，但它们并不直接嵌入大多数<code>可用</code>且<code>能够用数学或物理模型描述</code>的领域专家知识，例如地球系统科学问题 <sup class="refplus-num"><a href="#ref-343">[343]</a></sup>。这种物理指导的模型提供了将<code>明确的知识</code>和<code>实际的不确定性表征</code>纳入深度学习框架的更多可能性 <sup class="refplus-num"><a href="#ref-344">[344]</a></sup><sup class="refplus-num"><a href="#ref-345">[345]</a></sup>。</p>
<br>
<h2 id="参考文献">参考文献</h2>
<ul id="refplus"><li id="ref-1" data-num="1">[1]  T. Nair, D. Precup, D. L. Arnold, and T. Arbel, “Exploring uncertainty measures in deep networks for multiple sclerosis lesion detection and segmentation,” Medical image analysis, vol. 59, p. 101557, 2020.</li><li id="ref-2" data-num="2">[2]  A. G. Roy, S. Conjeti, N. Navab, C. Wachinger, A. D. N. Initiative et al., “Bayesian quicknat: Model uncertainty in deep whole-brain segmentation for structure-wise quality control,” NeuroImage, vol. 195, pp. 11–22, 2019.</li><li id="ref-3" data-num="3">[3]  P. Seeb ̈ock, J. I. Orlando, T. Schlegl, S. M. Waldstein, H. Bogunovi ́c, S. Klimscha, G. Langs, and U. Schmidt-Erfurth, “Exploiting epistemic uncertainty of anatomy segmentation for anomaly detection in retinal oct,” IEEE transactions on medical imaging, vol. 39, no. 1, pp. 87–98, 2019.</li><li id="ref-4" data-num="4">[4]  T. LaBonte, C. Martinez, and S. A. Roberts, “We know where we don’t know: 3d bayesian cnns for credible geometric uncertainty,” arxiv preprint arXiv:1910.10793, 2019.</li><li id="ref-5" data-num="5">[5]  J. C. Reinhold, Y. He, S. Han, Y. Chen, D. Gao, J. Lee, J. L. Prince, and A. Carass, “Validating uncertainty in medical image translation,” in 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI). IEEE, 2020, pp. 95–98.</li><li id="ref-6" data-num="6">[6]  S. Eggenreich, C. Payer, M. Urschler, and D. ˇStern, “Variational inference and bayesian cnns for uncertainty estimation in multi-factorial bone age prediction,” arxiv preprint arXiv:2002.10819, 2020.</li><li id="ref-7" data-num="7">[7]  D. Feng, L. Rosenbaum, and K. Dietmayer, “Towards safe autonomous driving: Capture uncertainty in the deep neural network for lidar 3d vehicle detection,” in 2018 21st International Conference on Intelligent Transportation Systems (ITSC). IEEE, 2018, pp. 3266–3273. https://github.com/google/uncertainty-baselines .</li><li id="ref-8" data-num="8">[8]  J. Choi, D. Chun, H. Kim, and H.-J. Lee, “Gaussian yolov3: An accurate and fast object detector using localization uncertainty for autonomous driving,” in Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 502–511.</li><li id="ref-9" data-num="9">[9]  A. Amini, A. Soleimany, S. Karaman, and D. Rus, “Spatial uncertainty sampling for end-to-end control,” arxiv preprint arXiv:1805.04829, 2018.</li><li id="ref-10" data-num="10">[10]  A. Loquercio, M. Segu, and D. Scaramuzza, “A general framework for uncertainty estimation in deep learning,” IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 3153–3160, 2020.</li><li id="ref-11" data-num="11">[11]  K. Lee, H. Lee, K. Lee, and J. Shin, “Training confidence-calibrated classifiers for detecting out-of-distribution samples,” in International Conference on Learning Representations, 2018.</li><li id="ref-12" data-num="12">[12]  J. Mitros and B. Mac Namee, “On the validity of bayesian neural networks for uncertainty estimation,” arxiv preprint arXiv:1912.01530, 2019.</li><li id="ref-13" data-num="13">[13]  Y. Ovadia, E. Fertig, J. Ren, Z. Nado, D. Sculley, S. Nowozin, J. Dillon, B. Lakshminarayanan, and J. Snoek, “Can you trust your model’s uncertainty? evaluating predictive uncertainty under dataset shift,” in Advances in Neural Information Processing Systems, 2019, pp. 13 991– 14 002.</li><li id="ref-14" data-num="14">[14]  M. S. Ayhan and P. Berens, “Test-time data augmentation for estimation of heteroscedastic aleatoric uncertainty in deep neural networks,” in Medical Imaging with Deep Learning Conference, 2018.</li><li id="ref-15" data-num="15">[15]  C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, “On calibration of modern neural networks,” in International Conference on Machine Learning. PMLR, 2017, pp. 1321–1330.</li><li id="ref-16" data-num="16">[16]  A. G. Wilson and P. Izmailov, “Bayesian deep learning and a probabilistic perspective of generalization,” in Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, Eds., vol. 33, 2020, pp. 4697–4708.</li><li id="ref-17" data-num="17">[17]  M. Rawat, M. Wistuba, and M.-I. Nicolae, “Harnessing model uncertainty for detecting adversarial examples,” in NIPS Workshop on Bayesian Deep Learning, 2017.</li><li id="ref-18" data-num="18">[18]  A. C. Serban, E. Poll, and J. Visser, “Adversarial examples-a complete characterisation of the phenomenon,” arxiv preprint arXiv:1810.01185, 2018.</li><li id="ref-19" data-num="19">[19]  L. Smith and Y. Gal, “Understanding measures of uncertainty for adversarial example detection,” in Proceesings of the Conference on Uncertainty in Artificial Intelligence, 2018, pp. 560–569.</li><li id="ref-20" data-num="20">[20]  Y. Gal and Z. Ghahramani, “Dropout as a bayesian approximation: Representing model uncertainty in deep learning,” in international conference on machine learning, 2016, pp. 1050–1059.</li><li id="ref-21" data-num="21">[21]  M. Rußwurm, S. M. Ali, X. X. Zhu, Y. Gal, and M. K ̈orner, “Model and data uncertainty for satellite time series forecasting with deep recurrent models,” in 2020 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2020.</li><li id="ref-22" data-num="22">[22]  J. Gawlikowski, S. Saha, A. Kruspe, and X. X. Zhu, “Out-of-distribution detection in satellite image classification,” in RobustML workshop at ICLR 2021. ICRL, 2021, pp. 1–5.</li><li id="ref-23" data-num="23">[23]  Y. Gal, R. Islam, and Z. Ghahramani, “Deep bayesian active learning with image data,” in International Conference on Machine Learning. PMLR, 2017, pp. 1183–1192.</li><li id="ref-24" data-num="24">[24]  K. Chitta, J. M. Alvarez, and A. Lesnikowski, “Large-scale visual active learning with deep probabilistic ensembles,” arxiv preprint arXiv:1811.03575, 2018.</li><li id="ref-25" data-num="25">[25]  J. Zeng, A. Lesnikowski, and J. M. Alvarez, “The relevance of bayesian layer positioning to model uncertainty in deep bayesian active learning,” arxiv preprint arXiv:1811.12535, 2018.</li><li id="ref-26" data-num="26">[26]  V.-L. Nguyen, S. Destercke, and E. H ̈ullermeier, “Epistemic uncertainty sampling,” in International Conference on Discovery Science. Springer, 2019, pp. 72–86.</li><li id="ref-27" data-num="27">[27]  W. Huang, J. Zhang, and K. Huang, “Bootstrap estimated uncertainty of the environment model for model-based reinforcement learning,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 33, 2019, pp. 3870–3877.</li><li id="ref-28" data-num="28">[28]  G. Kahn, A. Villaflor, V. Pong, P. Abbeel, and S. Levine, “Uncertainty-aware reinforcement learning for collision avoidance,” arxiv preprint arXiv:1702.01182, 2017.</li><li id="ref-29" data-num="29">[29]  B. Lotjens, M. Everett, and J. P. How, “Safe reinforcement learning with model uncertainty estimates,” in 2019 International Conference on Robotics and Automation (ICRA). IEEE, 2019, pp. 8662–8668.</li><li id="ref-30" data-num="30">[30]  C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wierstra, “Weight uncertainty in neural networks,” in Proceedings of the 32nd International Conference on International Conference on Machine LearningVolume 37, 2015, pp. 1613–1622.</li><li id="ref-31" data-num="31">[31]  B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Simple and scalable predictive uncertainty estimation using deep ensembles,” in Advances in neural information processing systems, 2017, pp. 6402–6413.</li><li id="ref-32" data-num="32">[32]  A. Malinin and M. Gales, “Predictive uncertainty estimation via prior networks,” in Advances in Neural Information Processing Systems, 2018, pp. 7047–7058.</li><li id="ref-33" data-num="33">[33]  X. Zhao, Y. Ou, L. Kaplan, F. Chen, and J.-H. Cho, “Quantifying classification uncertainty using regularized evidential neural networks,” arxiv preprint arXiv:1910.06864, 2019.</li><li id="ref-34" data-num="34">[34]  Q. Wu, H. Li, W. Su, L. Li, and Z. Yu, “Quantifying intrinsic uncertainty in classification via deep dirichlet mixture networks,” arxiv preprint arXiv:1906.04450, 2019.</li><li id="ref-35" data-num="35">[35]  J. Van Amersfoort, L. Smith, Y. W. Teh, and Y. Gal, “Uncertainty estimation using a single deep deterministic neural network,” in Proceedings of the 37th International Conference on Machine Learning. PMLR, 2020, pp. 9690–9700.</li><li id="ref-36" data-num="36">[36]  T. Ramalho and M. Miranda, “Density estimation in representation space to predict model uncertainty,” in Engineering Dependable and Secure Machine Learning Systems: Third International Workshop, EDSMLS 2020, New York City, NY, USA, February 7, 2020, Revised Selected Papers, vol. 1272. Springer Nature, 2020, p. 84.</li><li id="ref-37" data-num="37">[37]  A. Mobiny, H. V. Nguyen, S. Moulik, N. Garg, and C. C. Wu, “Dropconnect is effective in modeling uncertainty of bayesian deep networks,” arxiv preprint arXiv:1906.04569, 2019.</li><li id="ref-38" data-num="38">[38]  D. Krueger, C.-W. Huang, R. Islam, R. Turner, A. Lacoste, and A. Courville, “Bayesian hypernetworks,” arxiv preprint arXiv:1710.04759, 2017.</li><li id="ref-39" data-num="39">[39]  M. Valdenegro-Toro, “Deep sub-ensembles for fast uncertainty estimation in image classification,” in Bayesian Deep Learning Workshop at Neural Information Processing Systems 2019, 2019.</li><li id="ref-40" data-num="40">[40]  Y. Wen, D. Tran, and J. Ba, “Batchensemble: an alternative approach to efficient ensemble and lifelong learning,” in 8th International Conference on Learning Representations, 2020.</li><li id="ref-41" data-num="41">[41]  C. Shorten and T. M. Khoshgoftaar, “A survey on image data augmentation for deep learning,” Journal of Big Data, vol. 6, no. 1, pp. 1–48, 2019.</li><li id="ref-42" data-num="42">[42]  Q. Wen, L. Sun, X. Song, J. Gao, X. Wang, and H. Xu, “Time series data augmentation for deep learning: A survey,” arxiv preprint arXiv:2002.12478, 2020.</li><li id="ref-43" data-num="43">[43]  T. Tsiligkaridis, “Information robust dirichlet networks for predictive uncertainty estimation,” arxiv preprint arXiv:1910.04819, 2019.</li><li id="ref-44" data-num="44">[44]  M. Sensoy, L. Kaplan, and M. Kandemir, “Evidential deep learning to quantify classification uncertainty,” in Advances in Neural Information Processing Systems, 2018, pp. 3179–3189.</li><li id="ref-45" data-num="45">[45]  A. Malinin, B. Mlodozeniec, and M. Gales, “Ensemble distribution distillation,” in 8th International Conference on Learning Representations, 2020.</li><li id="ref-46" data-num="46">[46]  M. Raghu, K. Blumer, R. Sayres, Z. Obermeyer, B. Kleinberg, S. Mullainathan, and J. Kleinberg, “Direct uncertainty prediction for medical second opinions,” in International Conference on Machine Learning. PMLR, 2019, pp. 5281–5290.</li><li id="ref-47" data-num="47">[47]  J. Wenger, H. Kjellstr ̈om, and R. Triebel, “Non-parametric calibration for classification,” in International Conference on Artificial Intelligence and Statistics, 2020, pp. 178–190.</li><li id="ref-48" data-num="48">[48]  J. Zhang, B. Kailkhura, and T. Y.-J. Han, “Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning,” in International Conference on Machine Learning. PMLR, 2020, pp. 11 117–11 128.</li><li id="ref-49" data-num="49">[49]  R. Ghanem, D. Higdon, and H. Owhadi, Handbook of uncertainty quantification. Springer, 2017, vol. 6.</li><li id="ref-50" data-num="50">[50]  Y. Gal, “Uncertainty in deep learning,” Ph.D. dissertation, University of Cambridge, 2016.</li><li id="ref-51" data-num="51">[51]  A. G. Kendall, “Geometry and uncertainty in deep learning for computer vision,” Ph.D. dissertation, University of Cambridge, 2019.</li><li id="ref-52" data-num="52">[52]  A. Malinin, “Uncertainty estimation in deep learning with application to spoken language assessment,” Ph.D. dissertation, University of Cambridge, 2019.</li><li id="ref-53" data-num="53">[53]  H. Wang and D.-Y. Yeung, “Towards bayesian deep learning: A framework and some xiting methods,” IEEE Transactions on Knowledge and Data Engineering, vol. 28, no. 12, pp. 3395–3408, 2016.</li><li id="ref-54" data-num="54">[54]  ——, “A survey on bayesian deep learning,” ACM Computing Surveys (CSUR), vol. 53, no. 5, pp. 1–37, 2020.</li><li id="ref-55" data-num="55">[55]  N. St ̊ahl, G. Falkman, A. Karlsson, and G. Mathiason, “Evaluation of uncertainty quantification in deep learning,” in Information Processing and Management of Uncertainty in Knowledge-Based Systems. Springer International Publishing, 2020, pp. 556–568.</li><li id="ref-56" data-num="56">[56]  F. K. Gustafsson, M. Danelljan, and T. B. Schon, “Evaluating scalable bayesian deep learning methods for robust computer vision,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2020, pp. 318–319.</li><li id="ref-57" data-num="57">[57]  E. H ̈ullermeier and W. Waegeman, “Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods,” Machine Learning, vol. 110, no. 3, pp. 457–506, 2021.</li><li id="ref-58" data-num="58">[58]  M. Abdar, F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu, M. Ghavamzadeh, P. Fieguth, X. Cao, A. Khosravi, U. R. Acharya et al., “A review of uncertainty quantification in deep learning: Techniques, applications and challenges,” Information Fusion, 2021.</li><li id="ref-59" data-num="59">[59]  P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi, M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner et al., “Relational inductive biases, deep learning, and graph networks,” arxiv preprint arXiv:1806.01261, 2018.</li><li id="ref-60" data-num="60">[60]  A. Kendall and Y. Gal, “What uncertainties do we need in bayesian deep learning for computer vision?” in Advances in neural information processing systems, 2017, pp. 5574–5584.</li><li id="ref-61" data-num="61">[61]  Y. Gal and Z. Ghahramani, “Bayesian convolutional neural networks with bernoulli apprxiate variational inference,” arxiv preprint arXiv:1506.02158, 2015.</li><li id="ref-62" data-num="62">[62]  C. Bishop, Pattern Recognition and Machine Learning. Springer Verlag New York, 2006.</li><li id="ref-63" data-num="63">[63]  H. Ritter, A. Botev, and D. Barber, “A scalable laplace approximation for neural networks,” in 6th International Conference on Learning Representations, vol. 6. International Conference on Representation Learning, 2018.</li><li id="ref-64" data-num="64">[64]  J. Nandy, W. Hsu, and M. L. Lee, “Towards maxizing the representation gap between in-domain; out-of-distribution examples,” in Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, Eds., 2020, pp. 9239–9250.</li><li id="ref-65" data-num="65">[65]  A. Ashukha, A. Lyzhov, D. Molchanov, and D. Vetrov, “Pitfalls of in-domain uncertainty estimation and ensembling in deep learning,” in International Conference on Learning Representations, 2020.</li><li id="ref-66" data-num="66">[66]  T. DeVries and G. W. Taylor, “Improved regularization of convolutional neural networks with cutout,” arxiv preprint arXiv:1708.04552, 2017.</li><li id="ref-67" data-num="67">[67]  D. Hendrycks and K. Gimpel, “A baseline for detecting misclassified and out-of-distribution examples in neural networks,” in 5th International Conference on Learning Representations, 2017.</li><li id="ref-68" data-num="68">[68]  S. Liang, Y. Li, and R. Srikant, “Enhancing the reliability of out-of-distribution image detection in neural networks,” in 6th International Conference on Learning Representations, 2018.</li><li id="ref-69" data-num="69">[69]  A. Shafaei, M. Schmidt, and J. J. Little, “A less biased evaluation of out-of-distribution sample detectors,” in British Machine Vision Conference 2019, 2019.</li><li id="ref-70" data-num="70">[70]  M. Mundt, I. Pliushch, S. Majumder, and V. Ramesh, “Open set recognition through deep neural network uncertainty: Does out-of-distribution detection require generative classifiers?” in Proceedings of the IEEE International Conference on Computer Vision Workshops, 2019.</li><li id="ref-71" data-num="71">[71]  P. Oberdiek, M. Rottmann, and H. Gottschalk, “Classification uncertainty of deep neural networks based on gradient information,” in IAPR Workshop on Artificial Neural Networks in Pattern Recognition. Springer, 2018, pp. 113–125.</li><li id="ref-72" data-num="72">[72]  J. Lee and G. AlRegib, “Gradients as a measure of uncertainty in neural networks,” in 2020 IEEE International Conference on Image Processing. IEEE, 2020, pp. 2416–2420.</li><li id="ref-73" data-num="73">[73]  G. E. Hinton and D. Van Camp, “Keeping the neural networks simple by minimizing the description length of the weights,” in Proceedings of the sixth annual conference on Computational learning theory, 1993, pp. 5–13.</li><li id="ref-74" data-num="74">[74]  D. Barber and C. M. Bishop, “Ensemble learning in bayesian neural networks,” Nato ASI Series F Computer and Systems Sciences, vol. 168, pp. 215–238, 1998.</li><li id="ref-75" data-num="75">[75]  A. Graves, “Practical variational inference for neural networks,” in Advances in neural information processing systems, 2011, pp. 2348– 2356.</li><li id="ref-76" data-num="76">[76]  C. Louizos, K. Ullrich, and M. Welling, “Bayesian compression for deep learning,” in Advances in neural information processing systems, 2017, pp. 3288–3298.</li><li id="ref-77" data-num="77">[77]  D. Rezende and S. Mohamed, “Variational inference with normalizing flows,” in International Conference on Machine Learning, 2015, pp.1530–1538.</li><li id="ref-78" data-num="78">[78]  R. M. Neal, “Bayesian training of backpropagation networks by the hybrid monte carlo method,” Citeseer, Tech. Rep., 1992.</li><li id="ref-79" data-num="79">[79]  ——, “An improved acceptance procedure for the hybrid monte carlo algorithm,” Journal of Computational Physics, vol. 111, no. 1, pp. 194– 203, 1994.</li><li id="ref-80" data-num="80">[80]  ——, “Bayesian learning for neural networks,” Ph.D. dissertation, University of Toronto, 1995.</li><li id="ref-81" data-num="81">[81]  M. Welling and Y. W. Teh, “Bayesian learning via stochastic gradient langevin dynamics,” in Proceedings of the 28th international conference on machine learning, 2011, pp. 681–688.</li><li id="ref-82" data-num="82">[82]  C. Nemeth and P. Fearnhead, “Stochastic gradient markov chain monte carlo,” Journal of the American Statistical Association, pp. 1–18, 2020.</li><li id="ref-83" data-num="83">[83]  T. Salimans and D. P. Kingma, “Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks,” in Advances in Neural Information Processing Systems 29. Curran Associates, Inc., 2016, pp. 901–909.</li><li id="ref-84" data-num="84">[84]  J. Lee, M. Humt, J. Feng, and R. Triebel, “Estimating model uncertainty of neural networks in sparse information form,” in International Conference on Machine Learning. PMLR, 2020, pp. 5702–5713.</li><li id="ref-85" data-num="85">[85]  O. Achrack, O. Barzilay, and R. Kellerman, “Multi-loss sub-ensembles for accurate classification with uncertainty estimation,” arxiv preprint arXiv:2010.01917, 2020.</li><li id="ref-86" data-num="86">[86]  G. Huang, Y. Li, G. Pleiss, Z. Liu, J. E. Hopcroft, and K. Q. Weinberger, “Snapshot ensembles: Train 1, get m for free,” in International conference on learning representations, 2017.</li><li id="ref-87" data-num="87">[87]  G. D. Cavalcanti, L. S. Oliveira, T. J. Moura, and G. V. Carvalho, “Combining diversity measures for ensemble pruning,” Pattern Recognition Letters, vol. 74, pp. 38–45, 2016.</li><li id="ref-88" data-num="88">[88]  H. Guo, H. Liu, R. Li, C. Wu, Y. Guo, and M. Xu, “Margin &amp; diversity based ordering ensemble pruning,” Neurocomputing, vol. 275, pp. 237– 246, 2018.</li><li id="ref-89" data-num="89">[89]  W. G. Martinez, “Ensemble pruning via quadratic margin maxization,” IEEE Access, vol. 9, pp. 48 931–48 951, 2021.</li><li id="ref-90" data-num="90">[90]  J. Lindqvist, A. Olmin, F. Lindsten, and L. Svensson, “A general framework for ensemble distribution distillation,” in 2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP). IEEE, 2020, pp. 1–6.</li><li id="ref-91" data-num="91">[91]  D. Molchanov, A. Lyzhov, Y. Molchanova, A. Ashukha, and D. Vetrov, “Greedy policy search: A simple baseline for learnable test-time augmentation,” arxiv preprint arXiv:2002.09103, vol. 2, no. 7, 2020.</li><li id="ref-92" data-num="92">[92]  M. Mo ̇zejko, M. Susik, and R. Karczewski, “Inhibited softmax for uncertainty estimation in neural networks,” arxiv preprint arXiv:1810.01861, 2018.</li><li id="ref-93" data-num="93">[93]  L. Oala, C. Heiß, J. Macdonald, M. M ̈arz, W. Samek, and G. Kutyniok, “Interval neural networks: Uncertainty scores,” arxiv preprint arXiv:2003.11566, 2020.</li><li id="ref-94" data-num="94">[94]  A. Malinin and M. Gales, “Reverse kl-divergence training of prior networks: Improved uncertainty and adversarial robustness,” in Advances in Neural Information Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d ́Alch ́e-Buc, E. Fox, and R. Garnett, Eds., 2019, pp. 14 547–14 558.</li><li id="ref-95" data-num="95">[95]  V. T. Vasudevan, A. Sethy, and A. R. Ghias, “Towards better confidence estimation for neural models,” in ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019, pp. 7335–7339.</li><li id="ref-96" data-num="96">[96]  M. Hein, M. Andriushchenko, and J. Bitterwolf, “Why relu networks y_ield high-confidence predictions far away from the training data and how to mitigate the problem,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 41–50.</li><li id="ref-97" data-num="97">[97]  T. Joo, U. Chung, and M.-G. Seo, “Being bayesian about categorical probability,” in International Conference on Machine Learning. PMLR, 2020, pp. 4950–4961.</li><li id="ref-98" data-num="98">[98]  T. Tsiligkaridis, “Failure prediction by confidence estimation of uncertainty-aware dirichlet networks,” in 2021 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2021, pp. 3525–3529.</li><li id="ref-99" data-num="99">[99]  ——, “Information robust dirichlet networks for predictive uncertainty estimation,” arxiv preprint arXiv:1910.04819, 2019.</li><li id="ref-100" data-num="100">[100]  A. P. Dempster, “A generalization of bayesian inference,” Journal of the Royal Statistical Society: Series B (Methodological), vol. 30, no. 2, pp. 205–232, 1968.</li><li id="ref-101" data-num="101">[101]  A. Amini, W. Schwarting, A. Soleimany, and D. Rus, “Deep evidential regression,” in Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, Eds., vol. 33. Curran Associates, Inc., 2020, pp. 14 927–14 937.</li><li id="ref-102" data-num="102">[102]  B. Charpentier, D. Z ̈ugner, and S. G ̈unnemann, “Posterior network: Uncertainty estimation without ood samples via density-based pseudocounts,” in Advances in Neural Information Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, Eds., vol. 33, 2020, pp. 1356–1367.</li><li id="ref-103" data-num="103">[103]  N. Tagasovska and D. Lopez-Paz, “Single-model uncertainties for deep learning,” in Advances in Neural Information Processing Systems, 2019, pp. 6417–6428.</li><li id="ref-104" data-num="104">[104]  T. Kawashima, Q. Yu, A. Asai, D. Ikami, and K. Aizawa, “The aleatoric uncertainty estimation using a separate formulation with virtual residuals,” in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021, pp. 1438–1445.</li><li id="ref-105" data-num="105">[105]  Y.-C. Hsu, Y. Shen, H. Jin, and Z. Kira, “Generalized odin: Detecting out-of-distribution image without learning from out-of-distribution data,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 10 951–10 960.</li><li id="ref-106" data-num="106">[106]  J. Denker, D. Schwartz, B. Wittner, S. Solla, R. Howard, L. Jackel, and J. Hopfield, “Large automatic learning, rule extraction, and generalization,” Complex systems, vol. 1, no. 5, pp. 877–922, 1987.</li><li id="ref-107" data-num="107">[107]  N. Tishby, E. Levin, and S. A. Solla, “Consistent inference of probabilities in layered networks: Predictions and generalization,” in International Joint Conference on Neural Networks, vol. 2, 1989, pp. 403–409.</li><li id="ref-108" data-num="108">[108]  W. L. Buntine and A. S. Weigend, “Bayesian back-propagation,” Complex systems, vol. 5, no. 6, pp. 603–643, 1991.</li><li id="ref-109" data-num="109">[109]  D. J. C. MacKay, “Bayesian model comparison and backprop nets,” in Advances in neural information processing systems, 1992, pp. 839–846.</li><li id="ref-110" data-num="110">[110]  M.-A. Sato, “Online model selection based on the variational bayes,” Neural computation, vol. 13, no. 7, pp. 1649–1681, 2001.</li><li id="ref-111" data-num="111">[111]  A. Corduneanu and C. M. Bishop, “Variational bayesian model selection for mixture distributions,” in Artificial intelligence and Statistics, vol. 2001. Morgan Kaufmann Waltham, MA, 2001, pp. 27–34.</li><li id="ref-112" data-num="112">[112]  S. Ghosh, J. Yao, and F. Doshi-Velez, “Model selection in bayesian neural networks via horseshoe priors,” Journal of Machine Learning Research, vol. 20, no. 182, pp. 1–46, 2019.</li><li id="ref-113" data-num="113">[113]  M. Federici, K. Ullrich, and M. Welling, “Improved bayesian compression,” arxiv preprint arXiv:1711.06494, 2017.</li><li id="ref-114" data-num="114">[114]  J. Achterhold, J. M. Koehler, A. Schmeink, and T. Genewein, “Variational network quantization,” in International Conference on Learning Representations, 2018.</li><li id="ref-115" data-num="115">[115]  D. J. MacKay, “Information-based objective functions for active data selection,” Neural computation, vol. 4, no. 4, pp. 590–604, 1992.</li><li id="ref-116" data-num="116">[116]  A. Kirsch, J. van Amersfoort, and Y. Gal, “Batchbald: Efficient and diverse batch acquisition for deep bayesian active learning,” in Advances in Neural Information Processing Systems, 2019, pp. 7026– 7037.</li><li id="ref-117" data-num="117">[117]  C. V. Nguyen, Y. Li, T. D. Bui, and R. E. Turner, “Variational continual learning,” in International Conference on Learning Representations, 2018.</li><li id="ref-118" data-num="118">[118]  S. Ebrahimi, M. Elhoseiny, T. Darrell, and M. Rohrbach, “Uncertainty-guided continual learning with bayesian neural networks,” in International Conference on Learning Representations, 2020.</li><li id="ref-119" data-num="119">[119]  S. Farquhar and Y. Gal, “A unifying bayesian view of continual learning,” arxiv preprint arXiv:1902.06494, 2019.</li><li id="ref-120" data-num="120">[120]  H. Li, P. Barnaghi, S. Enshaeifar, and F. Ganz, “Continual learning using bayesian neural networks,” IEEE Transactions on Neural Networks and Learning Systems, 2020.</li><li id="ref-121" data-num="121">[121]  M. E. E. Khan, A. Immer, E. Abedi, and M. Korzepa, “Apprxiate inference turns deep networks into gaussian processes,” in Advances in neural information processing systems, 2019, pp. 3094–3104.</li><li id="ref-122" data-num="122">[122]  J. S. Denker and Y. LeCun, “Transforming neural-net output levels to probability distributions,” in Advances in neural information processing systems, 1991, pp. 853–859.</li><li id="ref-123" data-num="123">[123]  D. J. MacKay, “A practical bayesian framework for backpropagation networks,” Neural computation, vol. 4, no. 3, pp. 448–472, 1992.</li><li id="ref-124" data-num="124">[124]  J. Hernandez-Lobato, Y. Li, M. Rowland, T. Bui, D. Hern ́andezLobato, and R. Turner, “Black-box alpha divergence minimization,” in International Conference on Machine Learning, 2016, pp. 1511–1520.</li><li id="ref-125" data-num="125">[125]  Y. Li and Y. Gal, “Dropout inference in bayesian neural networks with alpha-divergences,” in International Conference on Machine Learning, 2017, pp. 2052–2061.</li><li id="ref-126" data-num="126">[126]  T. Minka et al., “Divergence measures and message passing,” Technical report, Microsoft Research, Tech. Rep., 2005.</li><li id="ref-127" data-num="127">[127]  T. P. Minka, “Expectation propagation for apprxiate bayesian inference,” in Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence, 2001, pp. 362–369.</li><li id="ref-128" data-num="128">[128]  J. Zhao, X. Liu, S. He, and S. Sun, “Probabilistic inference of bayesian neural networks with generalized expectation propagation,” Neurocomputing, vol. 412, pp. 392–398, 2020.</li><li id="ref-129" data-num="129">[129]  J. M. Hern ́andez-Lobato and R. Adams, “Probabilistic backpropagation for scalable learning of bayesian neural networks,” in International Conference on Machine Learning, 2015, pp. 1861–1869.</li><li id="ref-130" data-num="130">[130]  D. Tran, A. Kucukelbir, A. B. Dieng, M. Rudolph, D. Liang, and D. M. Blei, “Edward: A library for probabilistic modeling, inference, and criticism,” arxiv preprint arXiv:1610.09787, 2016.</li><li id="ref-131" data-num="131">[131]  D. Tran, M. D. Hoffman, R. A. Saurous, E. Brevdo, K. Murphy, and D. M. Blei, “Deep probabilistic programming,” in International Conference on Machine Learning, 2016.</li><li id="ref-132" data-num="132">[132]  E. Bingham, J. P. Chen, M. Jankowiak, F. Obermeyer, N. Pradhan, T. Karaletsos, R. Singh, P. Szerlip, P. Horsfall, and N. D. Goodman, “Pyro: Deep universal probabilistic programming,” The Journal of Machine Learning Research, vol. 20, no. 1, pp. 973–978, 2019.</li><li id="ref-133" data-num="133">[133]  R. Caba ̃nas, A. Salmer ́on, and A. R. Masegosa, “Inferpy: Probabilistic modeling with tensorflow made easy,” Knowledge-Based Systems, vol. 168, pp. 25–27, 2019.</li><li id="ref-134" data-num="134">[134]  Y. Ito, C. Srinivasan, and H. Izumi, “Bayesian learning of neural networks adapted to changes of prior probabilities,” in International Conference on Artificial Neural Networks. Springer, 2005, pp. 253– 259.</li><li id="ref-135" data-num="135">[135]  S. Sun, G. Zhang, J. Shi, and R. Grosse, “Functional variational bayesian neural networks,” in International Conference on Learning Representations, 2018.</li><li id="ref-136" data-num="136">[136]  S. Depeweg, J. M. Hern ́andez-Lobato, S. Udluft, and T. Runkler, “Sensitivity analysis for predictive uncertainty in bayesian neural networks,” arxiv preprint arXiv:1712.03605, 2017.</li><li id="ref-137" data-num="137">[137]  S. Farquhar, L. Smith, and Y. Gal, “Try depth instead of weight correlations: Mean-field is a less restrictive assumption for deeper networks,” arxiv preprint arXiv:2002.03704, 2020.</li><li id="ref-138" data-num="138">[138]  J. Postels, F. Ferroni, H. Coskun, N. Navab, and F. Tombari, “Sampling-free epistemic uncertainty estimation using approximated variance propagation,” in Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 2931–2940.</li><li id="ref-139" data-num="139">[139]  J. Gast and S. Roth, “Lightweight probabilistic deep networks,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 3369–3378.</li><li id="ref-140" data-num="140">[140]  S. Depeweg, J.-M. Hernandez-Lobato, F. Doshi-Velez, and S. Udluft, “Decomposition of uncertainty in bayesian deep learning for efficient and risk-sensitive learning,” in International Conference on Machine Learning. PMLR, 2018, pp. 1184–1193.</li><li id="ref-141" data-num="141">[141]  ——, “Decomposition of uncertainty in Bayesian deep learning for efficient and risk-sensitive learning,” in Proceedings of the 35th International Conference on Machine Learning, ser. Proceedings of Machine Learning Research, J. Dy and A. Krause, Eds., vol. 80. PMLR, 10–15 Jul 2018, pp. 1184–1193.</li><li id="ref-142" data-num="142">[142]  D. P. Kingma, T. Salimans, and M. Welling, “Variational Dropout and the local reparameterization trick,” in Advances in neural information processing systems, 2015, pp. 2575–2583.</li><li id="ref-143" data-num="143">[143]  A. Wu, S. Nowozin, E. Meeds, R. Turner, J. Hern ́andez-Lobato, and A. Gaunt, “Deterministic variational inference for robust bayesian neural networks,” in 7th International Conference on Learning Representations, ICLR 2019, 2019.</li><li id="ref-144" data-num="144">[144]  C. Louizos and M. Welling, “Structured and efficient variational deep learning with matrix gaussian posteriors,” in International Conference on Machine Learning, 2016, pp. 1708–1716.</li><li id="ref-145" data-num="145">[145]  G. Zhang, S. Sun, D. Duvenaud, and R. Grosse, “Noisy natural gradient as variational inference,” in International Conference on Machine Learning, 2018, pp. 5852–5861.</li><li id="ref-146" data-num="146">[146]  S. Sun, C. Chen, and L. Carin, “Learning structured weight uncertainty in bayesian neural networks,” in Artificial Intelligence and Statistics, 2017, pp. 1283–1292.</li><li id="ref-147" data-num="147">[147]  J. Bae, G. Zhang, and R. Grosse, “Eigenvalue corrected noisy natural gradient,” arxiv preprint arXiv:1811.12565, 2018.</li><li id="ref-148" data-num="148">[148]  A. Mishkin, F. Kunstner, D. Nielsen, M. Schmidt, and M. E. Khan, “Slang: Fast structured covariance approximations for bayesian deep learning with natural gradient,” in Advances in Neural Information Processing Systems, 2018, pp. 6245–6255.</li><li id="ref-149" data-num="149">[149]  C. Louizos and M. Welling, “Multiplicative normalizing flows for variational bayesian neural networks,” in International Conference on Machine Learning, 2017, pp. 2218–2227.</li><li id="ref-150" data-num="150">[150]  K. Osawa, S. Swaroop, M. E. E. Khan, A. Jain, R. Eschenhagen, R. E. Turner, and R. Yokota, “Practical deep learning with bayesian principles,” in Advances in neural information processing systems, 2019, pp. 4287–4299.</li><li id="ref-151" data-num="151">[151]  Y. Gal, J. Hron, and A. Kendall, “Concrete Dropout,” in Advances in neural information processing systems, 2017, pp. 3581–3590.</li><li id="ref-152" data-num="152">[152]  Z. Eaton-Rosen, F. Bragman, S. Bisdas, S. Ourselin, and M. J. Cardoso, “Towards safe deep learning: accurately quantifying biomarker uncertainty in neural network predictions,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2018, pp. 691–699.</li><li id="ref-153" data-num="153">[153]  C. R. N. Tassi, “Bayesian convolutional neural network: Robustly quantify uncertainty for misclassifications detection,” in Mediterranean Conference on Pattern Recognition and Artificial Intelligence. Springer, 2019, pp. 118–132.</li><li id="ref-154" data-num="154">[154]  P. McClure and N. Kriegeskorte, “Robustly representing uncertainty through sampling in deep neural networks,” arxiv preprint arXiv:1611.01639, 2016.</li><li id="ref-155" data-num="155">[155]  M. Khan, D. Nielsen, V. Tangkaratt, W. Lin, Y. Gal, and A. Srivastava, “Fast and scalable bayesian deep learning by weight-perturbation in adam,” in International Conference on Machine Learning. PMLR, 2018, pp. 2611–2620.</li><li id="ref-156" data-num="156">[156]  M. E. Khan, Z. Liu, V. Tangkaratt, and Y. Gal, “Vprop: Variational inference using rmsprop,” in Advances in neural information processing systems, 2017, pp. 3288–3298.</li><li id="ref-157" data-num="157">[157]  A. Atanov, A. Ashukha, D. Molchanov, K. Neklyudov, and D. Vetrov, “Uncertainty estimation via stochastic batch normalization,” in International Symposium on Neural Networks. Springer, 2019, pp. 261–269.</li><li id="ref-158" data-num="158">[158]  S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth, “Hybrid monte carlo,” Physics letters B, vol. 195, no. 2, pp. 216–222, 1987.</li><li id="ref-159" data-num="159">[159]  R. M. Neal et al., “Mcmc using hamiltonian dynamics,” Handbook of markov chain monte carlo, vol. 2, no. 11, p. 2, 2011.</li><li id="ref-160" data-num="160">[160]  K. A. Dubey, S. J. Reddi, S. A. Williamson, B. Poczos, A. J. Smola, and E. P. x_ing, “Variance reduction in stochastic gradient langevin dynamics,” in Advances in neural information processing systems, 2016, pp. 1154–1162.</li><li id="ref-161" data-num="161">[161]  B. Leimkuhler and S. Reich, Simulating hamiltonian dynamics. Cambridge university press, 2004, vol. 14.</li><li id="ref-162" data-num="162">[162]  P. J. Rossky, J. Doll, and H. Friedman, “Brownian dynamics as smart monte carlo simulation,” The Journal of Chemical Physics, vol. 69, no. 10, pp. 4628–4633, 1978.</li><li id="ref-163" data-num="163">[163]  G. O. Roberts and O. Stramer, “Langevin diffusions and metropolis-hastings algorithms,” Methodology and computing in applied probability, vol. 4, no. 4, pp. 337–357, 2002.</li><li id="ref-164" data-num="164">[164]  H. Kushner and G. G. y_in, Stochastic approximation and recursive algorithms and applications. Springer Science &amp; Business Media, 2003, vol. 35.</li><li id="ref-165" data-num="165">[165]  I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio, Deep learning. MIT press Cambridge, 2016, vol. 1, no. 2.</li><li id="ref-166" data-num="166">[166]  Y.-A. Ma, T. Chen, and E. Fox, “A complete recipe for stochastic gradient mcmc,” in Advances in Neural Information Processing Systems, 2015, pp. 2917–2925.</li><li id="ref-167" data-num="167">[167]  G. Marceau-Caron and Y. Ollivier, “Natural langevin dynamics for neural networks,” in International Conference on Geometric Science of Information. Springer, 2017, pp. 451–459.</li><li id="ref-168" data-num="168">[168]  Z. Nado, J. Snoek, R. B. Grosse, D. Duvenaud, B. Xu, and J. Martens, “Stochastic gradient langevin dynamics that exploit neural network structure,” in International Conference on Learning Representations (Workshop), 2018.</li><li id="ref-169" data-num="169">[169]  U. Simsekli, R. Badeau, A. T. Cemgil, and G. Richard, “Stochastic quasi-newton langevin monte carlo,” in Proceedings of the 33rd International Conference on International Conference on Machine Learning-Volume 48, 2016, pp. 642–651.</li><li id="ref-170" data-num="170">[170]  Y. Zhang and C. A. Sutton, “Quasi-newton methods for markov chain monte carlo,” in Advances in Neural Information Processing Systems, 2011, pp. 2393–2401.</li><li id="ref-171" data-num="171">[171]  T. Fu, L. Luo, and Z. Zhang, “Quasi-newton hamiltonian monte carlo.” in Conference on Uncertainty in Artificial Intelligence, 2016.</li><li id="ref-172" data-num="172">[172]  C. Li, C. Chen, D. Carlson, and L. Carin, “Preconditioned stochastic gradient langevin dynamics for deep neural networks,” in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. AAAI Press, 2016, pp. 1788–1794.</li><li id="ref-173" data-num="173">[173]  S. Ahn, A. K. Balan, and M. Welling, “Bayesian posterior sampling via stochastic gradient fisher scoring,” in International Conference on Learning Representations, 2012.</li><li id="ref-174" data-num="174">[174]  S. Patterson and Y. W. Teh, “Stochastic gradient riemannian langevin dynamics on the probability simplex,” in Advances in neural information processing systems, 2013, pp. 3102–3110.</li><li id="ref-175" data-num="175">[175]  N. Ye and Z. Zhu, “Stochastic fractional hamiltonian monte carlo,” in IJCAI, 2018, pp. 3019–3025.</li><li id="ref-176" data-num="176">[176]  N. Ding, Y. Fang, R. Babbush, C. Chen, R. D. Skeel, and H. Neven, “Bayesian sampling using stochastic gradient thermostats,” in Advances in neural information processing systems, 2014, pp. 3203–3211.</li><li id="ref-177" data-num="177">[177]  X. Shang, Z. Zhu, B. Leimkuhler, and A. J. Storkey, “Covariance-controlled adaptive langevin thermostat for large-scale bayesian sampling,” in Advances in Neural Information Processing Systems, 2015, pp. 37–45.</li><li id="ref-178" data-num="178">[178]  B. Leimkuhler and X. Shang, “Adaptive thermostats for noisy gradient systems,” SIAM Journal on Scientific Computing, vol. 38, no. 2, pp. A712–A736, 2016.</li><li id="ref-179" data-num="179">[179]  S. Ahn, B. Shahbaba, and M. Welling, “Distributed stochastic gradient mcmc,” in International conference on machine learning, 2014, pp. 1044–1052.</li><li id="ref-180" data-num="180">[180]  K.-C. Wang, P. Vicol, J. Lucas, L. Gu, R. Grosse, and R. Zemel, “Adversarial distillation of bayesian neural network posteriors,” in International Conference on Machine Learning, 2018, pp. 5190–5199.</li><li id="ref-181" data-num="181">[181]  A. K. Balan, V. Rathod, K. P. Murphy, and M. Welling, “Bayesian dark knowledge,” in Advances in Neural Information Processing Systems, 2015, pp. 3438–3446.</li><li id="ref-182" data-num="182">[182]  D. Zou, P. Xu, and Q. Gu, “Stochastic variance-reduced hamilton monte carlo methods,” in International Conference on Machine Learning, 2018, pp. 6028–6037.</li><li id="ref-183" data-num="183">[183]  A. Durmus, U. Simsekli, E. Moulines, R. Badeau, and G. Richard, “Stochastic gradient richardson-romberg markov chain monte carlo,” in Advances in Neural Information Processing Systems, 2016, pp. 2047– 2055.</li><li id="ref-184" data-num="184">[184]  A. Durmus, E. Moulines et al., “High-dimensional bayesian inference via the unadjusted langevin algorithm,” Bernoulli, vol. 25, no. 4A, pp. 2854–2882, 2019.</li><li id="ref-185" data-num="185">[185]  I. Sato and H. Nakagawa, “Apprxiation analysis of stochastic gradient langevin dynamics by using fokker-planck equation and ito process,” in International Conference on Machine Learning, 2014, pp. 982–990.</li><li id="ref-186" data-num="186">[186]  C. Chen, N. Ding, and L. Carin, “On the convergence of stochastic gradient mcmc algorithms with high-order integrators,” in Advances in Neural Information Processing Systems, 2015, pp. 2278–2286.</li><li id="ref-187" data-num="187">[187]  Y. W. Teh, A. H. Thiery, and S. J. Vollmer, “Consistency and fluctuations for stochastic gradient langevin dynamics,” The Journal of Machine Learning Research, vol. 17, no. 1, pp. 193–225, 2016.</li><li id="ref-188" data-num="188">[188]  C. Li, A. Stevens, C. Chen, Y. Pu, Z. Gan, and L. Carin, “Learning weight uncertainty with stochastic gradient mcmc for shape classification,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016, pp. 5666–5675.</li><li id="ref-189" data-num="189">[189]  F. Wenzel, K. Roth, B. Veeling, J. Swiatkowski, L. Tran, S. Mandt, J. Snoek, T. Salimans, R. Jenatton, and S. Nowozin, “How good is the bayes posterior in deep neural networks really?” in International Conference on Machine Learning. PMLR, 2020, pp. 10 248–10 259.</li><li id="ref-190" data-num="190">[190]  N. Ye, Z. Zhu, and R. K. Mantiuk, “Langevin dynamics with continuous tempering for training deep neural networks,” in Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017, pp. 618–626.</li><li id="ref-191" data-num="191">[191]  R. Chandra, K. Jain, R. V. Deo, and S. Cripps, “Langevin-gradient parallel tempering for bayesian neural learning,” Neurocomputing, vol. 359, pp. 315–326, 2019.</li><li id="ref-192" data-num="192">[192]  A. Botev, H. Ritter, and D. Barber, “Practical gauss-newton optimisation for deep learning,” in Proceedings of the 34th International Conference on Machine Learning-Volume 70, 2017, pp. 557–565.</li><li id="ref-193" data-num="193">[193]  J. Martens and R. Grosse, “Optimizing neural networks with kroneckerfactored apprxiate curvature,” in Proceeding of the 32nd International conference on machine learning, 2015, pp. 2408–2417.</li><li id="ref-194" data-num="194">[194]  S. Becker and Y. LeCun, “Improving the convergence of back-propagation learning with second-order methods,” in Proceedings of the 1988 Connectionist Models Summer School, San Mateo, D. Touretzky, G. Hinton, and T. Sejnowski, Eds. Morgan Kaufmann, 1989, pp. 29–37.</li><li id="ref-195" data-num="195">[195]  D. C. Liu and J. Nocedal, “On the limited memory bfgs method for large scale optimization,” Mathematical Programming, vol. 45, pp. 503–528, 08 1989.</li><li id="ref-196" data-num="196">[196]  P. Hennig, “Fast probabilistic optimization from noisy gradients,” in Proceedings of the 30th International Conference on Machine Learning, vol. 28-1. PMLR, 2013, pp. 62–70.</li><li id="ref-197" data-num="197">[197]  N. L. Roux and A. W. Fitzgibbon, “A fast natural newton method,” in Proceedings of the International Conference on Machine Learning, 2010.</li><li id="ref-198" data-num="198">[198]  R. B. Grosse and J. Martens, “A kronecker-factored apprxiate fisher matrix for convolution layers,” in Proceedings of the 33nd International Conference on Machine Learning, 2016, pp. 573–582.</li><li id="ref-199" data-num="199">[199]  S.-W. Chen, C.-N. Chou, and E. Chang, “Bda-pch: Block-diagonal approximation of positive-curvature hessian for training neural networks,” CoRR, abs/1802.06502, 2018.</li><li id="ref-200" data-num="200">[200]  J. Ba, R. Grosse, and J. Martens, “Distributed second-order optimization using kronecker-factored approximations,” in International Conference on Learning Representations, 2017.</li><li id="ref-201" data-num="201">[201]  T. George, C. Laurent, X. Bouthillier, N. Ballas, and P. Vincent, “Fast apprxiate natural gradient descent in a kronecker factored eigenbasis,” in Advances in Neural Information Processing Systems, 2018, pp. 9573–9583.</li><li id="ref-202" data-num="202">[202]  Y. LeCun, J. S. Denker, and S. A. Solla, “Optimal brain damage,” in Advances in Neural Information Processing Systems 2, 1990, pp. 598–605.</li><li id="ref-203" data-num="203">[203]  J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska et al., “Overcoming catastrophic forgetting in neural networks,” Proceedings of the national academy of sciences, vol. 114, no. 13, pp. 3521–3526, 2017.</li><li id="ref-204" data-num="204">[204]  A. Kristiadi, M. Hein, and P. Hennig, “Being bayesian, even just a bit, fixes overconfidence in relu networks,” in International Conference on Machine Learning. PMLR, 2020, pp. 5436–5446.</li><li id="ref-205" data-num="205">[205]  M. Humt, J. Lee, and R. Triebel, “Bayesian optimization meets laplace approximation for robotic introspection,” arxiv preprint arXiv:2010.16141, 2020.</li><li id="ref-206" data-num="206">[206]  A. Kristiadi, M. Hein, and P. Hennig, “Learnable uncertainty under laplace approximations,” arxiv preprint arXiv:2010.02720, 2020.</li><li id="ref-207" data-num="207">[207]  K. Shinde, J. Lee, M. Humt, A. Sezgin, and R. Triebel, “Learning multiplicative interactions with bayesian neural networks for visual inertial odometry,” in Workshop on AI for Autonomous Driving at the 37th International Conference on Machine Learning, 2020.</li><li id="ref-208" data-num="208">[208]  J. Feng, M. Durner, Z.-C. Marton, F. Balint-Benczedi, and R. Triebel, “Introspective robot perception using smoothed predictions from bayesian neural networks,” in International Symposium on Robotics Research, 2019.</li><li id="ref-209" data-num="209">[209]  A. Y. Foong, Y. Li, J. M. Hern ́andez-Lobato, and R. E. Turner, “’inbetween’ uncertainty in bayesian neural networks,” arxiv preprint arXiv:1906.11537, 2019.</li><li id="ref-210" data-num="210">[210]  A. Immer, M. Korzepa, and M. Bauer, “Improving predictions of bayesian neural nets via local linearization,” in Proceedings of The 24th International Conference on Artificial Intelligence and Statistics. PMLR, 2021, pp. 703–711.</li><li id="ref-211" data-num="211">[211]  M. Hobbhahn, A. Kristiadi, and P. Hennig, “Fast predictive uncertainty for classification with bayesian deep networks,” arxiv preprint arXiv:2003.01227, 2020.</li><li id="ref-212" data-num="212">[212]  E. Daxberger, E. Nalisnick, J. U. Allingham, J. Antor ́an, and J. M. Hern ́andez-Lobato, “Expressive yet tractable bayesian deep learning via subnetwork inference,” arxiv preprint arXiv:2010.14689, 2020.</li><li id="ref-213" data-num="213">[213]  W. J. Maddox, P. Izmailov, T. Garipov, D. P. Vetrov, and A. G. Wilson, “A simple baseline for bayesian uncertainty in deep learning,” in Advances in Neural Information Processing Systems, 2019, pp. 13 153– 13 164.</li><li id="ref-214" data-num="214">[214]  J. Mukhoti, P. Stenetorp, and Y. Gal, “On the importance of strong baselines in bayesian deep learning,” arxiv preprint arXiv:1811.09385, 2018.</li><li id="ref-215" data-num="215">[215]  A. Filos, S. Farquhar, A. N. Gomez, T. G. Rudner, Z. Kenton, L. Smith, M. Alizadeh, A. de Kroon, and Y. Gal, “A systematic comparison of bayesian deep learning robustness in diabetic retinopathy tasks,” arxiv preprint arXiv:1912.10481, 2019.</li><li id="ref-216" data-num="216">[216]  J. Mukhoti and Y. Gal, “Evaluating bayesian deep learning methods for semantic segmentation,” arxiv preprint arXiv:1811.12709, 2018.</li><li id="ref-217" data-num="217">[217]  O. Sagi and L. Rokach, “Ensemble learning: A survey,” WIREs Data Mining and Knowledge Discovery, vol. 8, no. 4, p. e1249, 2018.</li><li id="ref-218" data-num="218">[218]  L. K. Hansen and P. Salamon, “Neural network ensembles,” IEEE transactions on pattern analysis and machine intelligence, vol. 12, no. 10, pp. 993–1001, 1990.</li><li id="ref-219" data-num="219">[219]  Y. Cao, T. A. Geddes, J. Y. H. Yang, and P. Yang, “Ensemble deep learning in bioinformatics,” Nature Machine Intelligence, pp. 1–9, 2020.</li><li id="ref-220" data-num="220">[220]  L. Nannia, S. Ghidoni, and S. Brahnam, “Ensemble of convolutional neural networks for bioimage classification,” Applied Computing and Informatics, 2020.</li><li id="ref-221" data-num="221">[221]  L. Wei, S. Wan, J. Guo, and K. K. Wong, “A novel hierarchical selective ensemble classifier with bioinformatics application,” Artificial intelligence in medicine, vol. 83, pp. 82–90, 2017.</li><li id="ref-222" data-num="222">[222]  F. Lv, M. Han, and T. Qiu, “Remote sensing image classification based on ensemble extreme learning machine with stacked autoencoder,” IEEE Access, vol. 5, pp. 9021–9031, 2017.</li><li id="ref-223" data-num="223">[223]  X. Dai, X. Wu, B. Wang, and L. Zhang, “Semisupervised scene classification for remote sensing images: A method based on convolutional 39 neural networks and ensemble learning,” IEEE Geoscience and Remote Sensing Letters, vol. 16, no. 6, pp. 869–873, 2019.</li><li id="ref-224" data-num="224">[224]  E. Marushko and A. Doudkin, “Methods of using ensembles of heterogeneous models to identify remote sensing objects,” Pattern Recognition and Image Analysis, vol. 30, no. 2, pp. 211–216, 2020.</li><li id="ref-225" data-num="225">[225]  T. Kurutach, I. Clavera, Y. Duan, A. Tamar, and P. Abbeel, “Model-ensemble trust-region policy optimization,” in International Conference on Learning Representations, 2018.</li><li id="ref-226" data-num="226">[226]  A. Rajeswaran, S. Ghotra, B. Ravindran, and S. Levine, “Epopt: Learning robust neural network policies using model ensembles,” in International Conference on Learning Representations, 2017.</li><li id="ref-227" data-num="227">[227]  S. Fort, H. Hu, and B. Lakshminarayanan, “Deep ensembles: A loss landscape perspective,” arxiv preprint arXiv:1912.02757, 2019.</li><li id="ref-228" data-num="228">[228]  A. Renda, M. Barsacchi, A. Bechini, and F. Marcelloni, “Comparing ensemble strategies for deep learning: An application to facial expression recognition,” Expert Systems with Applications, vol. 136, pp. 1–11, 2019.</li><li id="ref-229" data-num="229">[229]  E. J. Herron, S. R. Young, and T. E. Potok, “Ensembles of networks produced from neural architecture search,” in International Conference on High Performance Computing. Springer, 2020, pp. 223–234.</li><li id="ref-230" data-num="230">[230]  S. Lee, S. Purushwalkam, M. Cogswell, D. Crandall, and D. Batra, “Why m heads are better than one: Training a diverse ensemble of deep networks,” arxiv preprint arXiv:1511.06314, 2015.</li><li id="ref-231" data-num="231">[231]  I. E. Livieris, L. Iliadis, and P. Pintelas, “On ensemble techniques of weight-constrained neural networks,” Evolving Systems, pp. 1–13, 2020.</li><li id="ref-232" data-num="232">[232]  L. Nanni, S. Brahnam, and G. Maguolo, “Data augmentation for building an ensemble of convolutional neural networks,” in Innovation in Medicine and Healthcare Systems, and Multimedia. Singapore: Springer Singapore, 2019, pp. 61–69.</li><li id="ref-233" data-num="233">[233]  J. Guo and S. Gould, “Deep cnn ensemble with data augmentation for object detection,” arxiv preprint arXiv:1506.07224, 2015.</li><li id="ref-234" data-num="234">[234]  R. Rahaman and A. H. Thiery, “Uncertainty quantification and deep ensembles,” stat, vol. 1050, p. 20, 2020.</li><li id="ref-235" data-num="235">[235]  Y. Wen, G. Jerfel, R. Muller, M. W. Dusenberry, J. Snoek, B. Lakshminarayanan, and D. Tran, “Combining ensembles and data augmentation can harm your calibration,” in International Conference on Learning Representations, 2021.</li><li id="ref-236" data-num="236">[236]  W. Kim, B. Goyal, K. Chawla, J. Lee, and K. Kwon, “Attention-based ensemble for deep metric learning,” in Proceedings of the European Conference on Computer Vision, 2018.</li><li id="ref-237" data-num="237">[237]  J. Yang and F. Wang, “Auto-ensemble: An adaptive learning rate scheduling based deep learning model ensembling,” IEEE Access, vol. 8, pp. 217 499–217 509, 2020.</li><li id="ref-238" data-num="238">[238]  M. Leutbecher and T. N. Palmer, “Ensemble forecasting,” Journal of computational physics, vol. 227, no. 7, pp. 3515–3539, 2008.</li><li id="ref-239" data-num="239">[239]  W. S. Parker, “Ensemble modeling, uncertainty and robust predictions,” Wiley Interdisciplinary Reviews: Climate Change, vol. 4, no. 3, pp. 213–223, 2013.</li><li id="ref-240" data-num="240">[240]  W. H. Beluch, T. Genewein, A. N ̈urnberger, and J. M. K ̈ohler, “The power of ensembles for active learning in image classification,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 9368–9377.</li><li id="ref-241" data-num="241">[241]  A. Vyas, N. Jammalamadaka, X. Zhu, D. Das, B. Kaul, and T. L. Willke, “Out-of-distribution detection using an ensemble of self supervised leave-out classifiers,” in Proceedings of the European Conference on Computer Vision, 2018, pp. 550–564.</li><li id="ref-242" data-num="242">[242]  J. Koci ́c, N. Joviˇci ́c, and V. Drndarevi ́c, “An end-to-end deep neural network for autonomous driving designed for embedded automotive platforms,” Sensors, vol. 19, no. 9, p. 2064, 2019.</li><li id="ref-243" data-num="243">[243]  G. Mart ́ınez-Mu ̃noz, D. Hern ́andez-Lobato, and A. Su ́arez, “An analysis of ensemble pruning techniques based on ordered aggregation,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 31, no. 2, pp. 245–259, 2008.</li><li id="ref-244" data-num="244">[244]  C. Buciluˇa, R. Caruana, and A. Niculescu-Mizil, “Model compression,” in Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, 2006, pp. 535–541.</li><li id="ref-245" data-num="245">[245]  G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural network,” stat, vol. 1050, p. 9, 2015.</li><li id="ref-246" data-num="246">[246]  E. Englesson and H. Azizpour, “Efficient evaluation-time uncertainty estimation by improved distillation,” in Workshop on Uncertainty and Robustness in Deep Learning at International Conference on Machine Learning, 2019.</li><li id="ref-247" data-num="247">[247]  S. Reich, D. Mueller, and N. Andrews, “Ensemble distillation for structured prediction: Calibrated, accurate, fast—choose three,” in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2020, pp. 5583–5595.</li><li id="ref-248" data-num="248">[248]  G. Wang, W. Li, S. Ourselin, and T. Vercauteren, “Automatic brain tumor segmentation using convolutional neural networks with test-time augmentation,” in International MICCAI Brainlesion Workshop. Springer, 2018, pp. 61–72.</li><li id="ref-249" data-num="249">[249]  G. Wang, W. Li, M. Aertsen, J. Deprest, S. Ourselin, and T. Vercauteren, “Aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks,” Neurocomputing, vol. 338, pp. 34–45, 2019.</li><li id="ref-250" data-num="250">[250]  N. Moshkov, B. Mathe, A. Kertesz-Farkas, R. Hollandi, and P. Horvath, “Test-time augmentation for deep learning-based cell segmentation on microscopy images,” Scientific reports, vol. 10, no. 1, pp. 1–7, 2020.</li><li id="ref-251" data-num="251">[251]  O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference on Medical image computing and computer-assisted intervention. Springer, 2015, pp. 234–241.</li><li id="ref-252" data-num="252">[252]  D. Shanmugam, D. Blalock, G. Balakrishnan, and J. Guttag, “When and why test-time augmentation works,” arxiv preprint arXiv:2011.11156, 2020.</li><li id="ref-253" data-num="253">[253]  I. Kim, Y. Kim, and S. Kim, “Learning loss for test-time augmentation,” in Advances in Neural Information Processing Systems, 2020, pp. 4163–4174.</li><li id="ref-254" data-num="254">[254]  Q. Yu and K. Aizawa, “Unsupervised out-of-distribution detection by mxium classifier discrepancy,” in Proceedings of the IEEE International Conference on Computer Vision, 2019, pp. 9518–9526.</li><li id="ref-255" data-num="255">[255]  J. Ren, P. J. Liu, E. Fertig, J. Snoek, R. Poplin, M. Depristo, J. Dillon, and B. Lakshminarayanan, “Likelihood ratios for out-of-distribution detection,” in Advances in Neural Information Processing Systems, 2019, pp. 14 707–14 718.</li><li id="ref-256" data-num="256">[256]  J. Yao, W. Pan, S. Ghosh, and F. Doshi-Velez, “Quality of uncertainty quantification for bayesian neural network inference,” arxiv preprint arXiv:1906.09686, 2019.</li><li id="ref-257" data-num="257">[257]  X. Huang, J. Yang, L. Li, H. Deng, B. Ni, and Y. Xu, “Evaluating and Boosting uncertainty quantification in classification,” arxiv preprint arXiv:1909.06030, 2019.</li><li id="ref-258" data-num="258">[258]  J. Davis and M. Goadrich, “The relationship between precision-recall and roc curves,” in Proceedings of the 23rd international conference on Machine learning, 2006, pp. 233–240.</li><li id="ref-259" data-num="259">[259]  T. Pearce, A. Brintrup, M. Zaki, and A. Neely, “High-quality prediction intervals for deep learning: A distribution-free, ensembled approach,” in International Conference on Machine Learning. PMLR, 2018, pp. 4075–4084.</li><li id="ref-260" data-num="260">[260]  D. Su, Y. Y. Ting, and J. Ansel, “Tight prediction intervals using expanded interval minimization,” arxiv preprint arXiv:1806.11222, 2018.</li><li id="ref-261" data-num="261">[261]  P. McClure, N. Rho, J. A. Lee, J. R. Kaczmarzyk, C. Y. Zheng, S. S. Ghosh, D. M. Nielson, A. G. Thomas, P. Bandettini, and F. Pereira, “Knowing what you know in brain segmentation using bayesian deep neural networks,” Frontiers in neuroinformatics, vol. 13, p. 67, 2019.</li><li id="ref-262" data-num="262">[262]  A. P. Soleimany, H. Suresh, J. J. G. Ortiz, D. Shanmugam, N. Gural, J. Guttag, and S. N. Bhatia, “Image segmentation of liver stage malaria infection with spatial uncertainty sampling,” arxiv preprint arXiv:1912.00262, 2019.</li><li id="ref-263" data-num="263">[263]  R. D. Soberanis-Mukul, N. Navab, and S. Albarqouni, “Uncertainty-based graph convolutional networks for organ segmentation refinement,” in Medical Imaging with Deep Learning. PMLR, 2020, pp. 755–769.</li><li id="ref-264" data-num="264">[264]  P. Seebock, J. I. Orlando, T. Schlegl, S. M. Waldstein, H. Bogunovic, S. Klimscha, G. Langs, and U. Schmidt-Erfurth, “Exploiting epistemic uncertainty of anatomy segmentation for anomaly detection in retinal oct,” IEEE Transactions on Medical Imaging, vol. 39, p. 87–98, 2020.</li><li id="ref-265" data-num="265">[265]  V. Kuleshov, N. Fenner, and S. Ermon, “Accurate uncertainties for deep learning using calibrated regression,” in International Conference on Machine Learning. PMLR, 2018, pp. 2796–2804.</li><li id="ref-266" data-num="266">[266]  S. Seo, P. H. Seo, and B. Han, “Learning for single-shot confidence calibration in deep neural networks through stochastic inferences,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2019, pp. 9030–9038.</li><li id="ref-267" data-num="267">[267]  Z. Li and D. Hoiem, “Improving confidence estimates for unfamiliar examples,” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2020, pp. 2686–2695.</li><li id="ref-268" data-num="268">[268]  C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, “Rethinking the inception architecture for computer vision,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 2818–2826.</li><li id="ref-269" data-num="269">[269]  G. Pereyra, G. Tucker, J. Chorowski, Ł. Kaiser, and G. Hinton, “Regularizing neural networks by penalizing confident output distributions,” arxiv preprint arXiv:1701.06548, 2017.</li><li id="ref-270" data-num="270">[270]  R. M ̈uller, S. Kornblith, and G. E. Hinton, “When does label smoothing help?” in Advances in Neural Information Processing Systems, 2019, pp. 4694–4703.</li><li id="ref-271" data-num="271">[271]  B. Venkatesh and J. J. Thiagarajan, “Heteroscedastic calibration of uncertainty estimators in deep learning,” arxiv preprint arXiv:1910.14179, 2019.</li><li id="ref-272" data-num="272">[272]  P. Izmailov, W. J. Maddox, P. Kirichenko, T. Garipov, D. Vetrov, and A. G. Wilson, “Subspace inference for bayesian deep learning,” in Uncertainty in Artificial Intelligence. PMLR, 2020, pp. 1169–1179.</li><li id="ref-273" data-num="273">[273]  Z. Zhang, A. V. Dalca, and M. R. Sabuncu, “Confidence calibration for convolutional neural networks using structured Dropout,” arxiv preprint arXiv:1906.09551, 2019.</li><li id="ref-274" data-num="274">[274]  M.-H. Laves, S. Ihler, K.-P. Kortmann, and T. Ortmaier, “Well-calibrated model uncertainty with temperature scaling for Dropout variational inference,” arxiv preprint arXiv:1909.13550, 2019.</li><li id="ref-275" data-num="275">[275]  A. Mehrtash, W. M. Wells, C. M. Tempany, P. Abolmaesumi, and T. Kapur, “Confidence calibration and predictive uncertainty estimation for deep medical image segmentation,” IEEE Transactions on Medical Imaging, 2020.</li><li id="ref-276" data-num="276">[276]  B. Zadrozny and C. Elkan, “Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers,” in International Conference on Machine Learning, vol. 1. Citeseer, 2001, pp. 609– 616.</li><li id="ref-277" data-num="277">[277]  D. Hendrycks, M. Mazeika, and T. Dietterich, “Deep anomaly detection with outlier exposure,” in International Conference on Learning Representations, 2019.</li><li id="ref-278" data-num="278">[278]  S. Thulasidasan, G. Chennupati, J. A. Bilmes, T. Bhattacharya, and S. Michalak, “On mixup training: Improved calibration and predictive uncertainty for deep neural networks,” in Advances in Neural Information Processing Systems, 2019, pp. 13 888–13 899.</li><li id="ref-279" data-num="279">[279]  J. Maro ̃nas, D. Ramos, and R. Paredes, “Improving calibration in mixup-trained deep neural networks through confidence-based loss functions,” arxiv preprint arXiv:2003.09946, 2020.</li><li id="ref-280" data-num="280">[280]  K. Patel, W. Beluch, D. Zhang, M. Pfeiffer, and B. Yang, “On-manifold adversarial data augmentation improves uncertainty calibration,” in 2020 25th International Conference on Pattern Recognition (ICPR). IEEE, 2021, pp. 8029–8036.</li><li id="ref-281" data-num="281">[281]  D. Comaniciu, V. Ramesh, and P. Meer, “Real-time tracking of non-rigid objects using mean shift,” in Proceedings IEEE Conference on Computer Vision and Pattern Recognition, vol. 2. IEEE, 2000, pp. 142–149.</li><li id="ref-282" data-num="282">[282]  H. Zhang, M. Cisse, Y. N. Dauphin, and D. Lopez-Paz, “mixup: Beyond empirical risk minimization,” in International Conference on Learning Representations, 2018.</li><li id="ref-283" data-num="283">[283]  M. P. Naeini, G. F. Cooper, and M. Hauskrecht, “Obtaining well calibrated probabilities using bayesian binning,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 2015, 2015, p. 2901.</li><li id="ref-284" data-num="284">[284]  M. Kull, M. Perell ́o-Nieto, M. K ̈angsepp, T. de Menezes e Silva Filho, H. Song, and P. A. Flach, “Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration,” in Advances in Neural Information Processing Systems, 2019, pp. 12 295– 12 305.</li><li id="ref-285" data-num="285">[285]  D. Levi, L. Gispan, N. Giladi, and E. Fetaya, “Evaluating and calibrating uncertainty prediction in regression tasks,” arxiv preprint arXiv:1905.11659, 2019.</li><li id="ref-286" data-num="286">[286]  J. Vaicenavicius, D. Widmann, C. Andersson, F. Lindsten, J. Roll, and T. Sch ̈on, “Evaluating model calibration in classification,” in The 22nd International Conference on Artificial Intelligence and Statistics. PMLR, 2019, pp. 3459–3467.</li><li id="ref-287" data-num="287">[287]  M. H. DeGroot and S. E. Fienberg, “The comparison and evaluation of forecasters,” Journal of the Royal Statistical Society: Series D (The Statistician), vol. 32, no. 1-2, pp. 12–22, 1983.</li><li id="ref-288" data-num="288">[288]  J. Nixon, M. W. Dusenberry, L. Zhang, G. Jerfel, and D. Tran, “Measuring calibration in deep learning,” in CVPR Workshops, 2019, pp. 38–41.</li><li id="ref-289" data-num="289">[289]  A. Ghandeharioun, B. Eoff, B. Jou, and R. Picard, “Characterizing sources of uncertainty to proxy calibration and disambiguate annotator and data bias,” in 2019 IEEE/CVF International Conference on Computer Vision Workshop. IEEE, 2019, pp. 4202–4206.</li><li id="ref-290" data-num="290">[290]  F. J. Pulgar, A. J. Rivera, F. Charte, and M. J. del Jesus, “On the impact of imbalanced data in convolutional neural networks performance,” in International Conference on Hybrid Artificial Intelligence Systems. Springer, 2017, pp. 220–232.</li><li id="ref-291" data-num="291">[291]  K. Lee, K. Lee, H. Lee, and J. Shin, “A simple unified framework for detecting out-of-distribution samples and adversarial attacks,” in Advances in Neural Information Processing Systems, 2018, pp. 7167– 7177.</li><li id="ref-292" data-num="292">[292]  M. L. Iuzzolino, T. Umada, N. R. Ahmed, and D. A. Szafir, “In automation we trust: Investigating the role of uncertainty in active learning systems,” arxiv preprint arXiv:2004.00762, 2020.</li><li id="ref-293" data-num="293">[293]  B. Settles, “Active learning literature survey,” University of Wisconsin-Madison Department of Computer Sciences, Tech. Rep., 2009.</li><li id="ref-294" data-num="294">[294]  R. Pop and P. Fulop, “Deep ensemble bayesian active learning: Addressing the mode collapse issue in monte carlo Dropout via ensembles,” arxiv preprint arXiv:1811.03897, 2018.</li><li id="ref-295" data-num="295">[295]  M. Ghavamzadeh, S. Mannor, J. Pineau, and A. Tamar, “Bayesian reinforcement learning: A survey,” Foundations and Trends® in Machine Learning, vol. 8, no. 5-6, pp. 359–483, 2015.</li><li id="ref-296" data-num="296">[296]  S. Hu, D. Worrall, S. Knegt, B. Veeling, H. Huisman, and M. Welling, “Supervised uncertainty quantification for segmentation with multiple annotations,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2019, pp. 137–145.</li><li id="ref-297" data-num="297">[297]  F. C. Ghesu, B. Georgescu, E. Gibson, S. Guendel, M. K. Kalra, R. Singh, S. R. Digumarthy, S. Grbic, and D. Comaniciu, “Quantifying and leveraging classification uncertainty for chest radiograph assessment,” in International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2019, pp. 676–684.</li><li id="ref-298" data-num="298">[298]  M. S. Ayhan, L. Kuehlewein, G. Aliyeva, W. Inhoffen, F. Ziemssen, and P. Berens, “Expert-validated estimation of diagnostic uncertainty for deep neural networks in diabetic retinopathy detection,” Medical Image Analysis, p. 101724, 2020.</li><li id="ref-299" data-num="299">[299]  N. Sunderhauf, O. Brock, W. Scheirer, R. Hadsell, D. Fox, J. Leitner, B. Upcroft, P. Abbeel, W. Burgard, M. Milford et al., “The limits and potentials of deep learning for robotics,” The International Journal of Robotics Research, vol. 37, no. 4-5, pp. 405–420, 2018.</li><li id="ref-300" data-num="300">[300]  S. Thrun, “Probabilistic robotics,” Communications of the ACM, vol. 45, no. 3, pp. 52–57, 2002.</li><li id="ref-301" data-num="301">[301]  D. Fox, “Markov localization-a probabilistic framework for mobile robot localization and navigation.” Ph.D. dissertation, Citeseer, 1998.</li><li id="ref-302" data-num="302">[302]  D. Fox, W. Burgard, H. Kruppa, and S. Thrun, “A probabilistic approach to collaborative multi-robot localization,” Autonomous robots, vol. 8, no. 3, pp. 325–344, 2000.</li><li id="ref-303" data-num="303">[303]  S. Thrun, D. Fox, W. Burgard, and F. Dellaert, “Robust monte carlo localization for mobile robots,” Artificial intelligence, vol. 128, no. 1-2, pp. 99–141, 2001.</li><li id="ref-304" data-num="304">[304]  H. Durrant-Whyte and T. Bailey, “Simultaneous localization and mapping: part i,” IEEE robotics &amp; automation magazine, vol. 13, no. 2, pp. 99–110, 2006.</li><li id="ref-305" data-num="305">[305]  T. Bailey and H. Durrant-Whyte, “Simultaneous localization and mapping (slam): Part ii,” IEEE robotics &amp; automation magazine, vol. 13, no. 3, pp. 108–117, 2006.</li><li id="ref-306" data-num="306">[306]  M. Montemerlo, S. Thrun, D. Koller, and B. Wegbreit, “Fastslam: A factored solution to the simultaneous localization and mapping problem,” Aaai/iaai, vol. 593598, 2002.</li><li id="ref-307" data-num="307">[307]  M. Kaess, V. Ila, R. Roberts, and F. Dellaert, “The bayes tree: An algorithmic foundation for probabilistic robot mapping,” in Algorithmic Foundations of Robotics IX. Springer, 2010, pp. 157–173.</li><li id="ref-308" data-num="308">[308]  F. Dellaert and M. Kaess, “Factor graphs for robot perception,” Foundations and Trends in Robotics, vol. 6, no. 1-2, pp. 1–139, 2017.</li><li id="ref-309" data-num="309">[309]  H. A. Loeliger, “An introduction to factor graphs,” IEEE Signal Processing Magazine, vol. 21, no. 1, pp. 28–41, 2004.</li><li id="ref-310" data-num="310">[310]  D. Silver and J. Veness, “Monte-carlo planning in large pomdps,” in Advances in Neural Information Processing Systems, 2010.</li><li id="ref-311" data-num="311">[311]  S. Ross, J. Pineau, S. Paquet, and B. Chaib-Draa, “Online planning algorithms for pomdps,” Journal of Artificial Intelligence Research, vol. 32, pp. 663–704, 2008.</li><li id="ref-312" data-num="312">[312]  S. M. Richards, F. Berkenkamp, and A. Krause, “The lyapunov neural network: Adaptive stability certification for safe learning of dynamical systems,” in Conference on Robot Learning. PMLR, 2018, pp. 466– 476.</li><li id="ref-313" data-num="313">[313]  F. Berkenkamp, A. P. Schoellig, and A. Krause, “Safe controller optimization for quadrotors with gaussian processes,” in 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2016, pp. 491–496.</li><li id="ref-314" data-num="314">[314]  F. Berkenkamp, M. Turchetta, A. P. Schoellig, and A. Krause, “Safe model-based reinforcement learning with stability guarantees,” in Advances in Neural Information Processing Systems, 2017.</li><li id="ref-315" data-num="315">[315]  H. Grimmett, R. Triebel, R. Paul, and I. Posner, “Introspective classification for robot perception,” The International Journal of Robotics Research, vol. 35, no. 7, pp. 743–762, 2016.</li><li id="ref-316" data-num="316">[316]  R. Bajcsy, “Active perception,” Proceedings of the IEEE, vol. 76, no. 8, pp. 966–1005, 1988.</li><li id="ref-317" data-num="317">[317]  R. Triebel, H. Grimmett, R. Paul, and I. Posner, “Driven learning for driving: How introspection improves semantic mapping,” in Robotics Research. Springer, 2016, pp. 449–465.</li><li id="ref-318" data-num="318">[318]  A. Narr, R. Triebel, and D. Cremers, “Stream-based active learning for efficient and adaptive classification of 3d objects,” in 2016 IEEE International Conference on Robotics and Automation. IEEE, 2016, pp. 227–233.</li><li id="ref-319" data-num="319">[319]  D. A. Cohn, Z. Ghahramani, and M. I. Jordan, “Active learning with statistical models,” Journal of artificial intelligence research, vol. 4, pp. 129–145, 1996.</li><li id="ref-320" data-num="320">[320]  A. Nguyen, J. Yosinski, and J. Clune, “Deep neural networks are easily fooled: High confidence predictions for unrecognizable images,” in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 427–436.</li><li id="ref-321" data-num="321">[321]  K. Wong, S. Wang, M. Ren, M. Liang, and R. Urtasun, “Identifying unknown instances for autonomous driving,” in Conference on Robot Learning. PMLR, 2020, pp. 384–393.</li><li id="ref-322" data-num="322">[322]  W. Boerdijk, M. Sundermeyer, M. Durner, and R. Triebel, “”What’s this?”–learning to segment unknown objects from manipulation sequences,” in Intern. Conf. on Robotics and Automation, 2021.</li><li id="ref-323" data-num="323">[323]  C. Richter and N. Roy, “Safe visual navigation via deep learning and novelty detection,” Robotics: Science and Systems Foundation, 2017.</li><li id="ref-324" data-num="324">[324]  V. Peretroukhin, M. Giamou, D. M. Rosen, W. N. Greene, N. Roy, and J. Kelly, “A smooth representation of belief over so (3) for deep rotation learning with uncertainty,” arxiv preprint arXiv:2006.01031, 2020.</li><li id="ref-325" data-num="325">[325]  B. L ̈utjens, M. Everett, and J. P. How, “Safe reinforcement learning with model uncertainty estimates,” in 2019 International Conference on Robotics and Automation. IEEE, 2019, pp. 8662–8668.</li><li id="ref-326" data-num="326">[326]  G. Kahn, A. Villaflor, B. Ding, P. Abbeel, and S. Levine, “Self-supervised deep reinforcement learning with generalized computation graphs for robot navigation,” in 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2018, pp. 5129–5136.</li><li id="ref-327" data-num="327">[327]  F. Stulp, E. Theodorou, J. Buchli, and S. Schaal, “Learning to grasp under uncertainty,” in 2011 IEEE International Conference on Robotics and Automation. IEEE, 2011, pp. 5703–5708.</li><li id="ref-328" data-num="328">[328]  V. Tchuiev and V. Indelman, “Inference over distribution of posterior class probabilities for reliable bayesian classification and object-level perception,” IEEE Robotics and Automation Letters, vol. 3, no. 4, pp. 4329–4336, 2018.</li><li id="ref-329" data-num="329">[329]  Y. Feldman and V. Indelman, “Bayesian viewpoint-dependent robust classification under model and localization uncertainty,” in 2018 IEEE International Conference on Robotics and Automation. IEEE, 2018, pp. 3221–3228.</li><li id="ref-330" data-num="330">[330]  N. Yang, L. von Stumberg, R. Wang, and D. Cremers, “D3vo: Deep depth, deep pose and deep uncertainty for monocular visual odometry,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020, pp. 1281–1292.</li><li id="ref-331" data-num="331">[331]  S. Wang, R. Clark, H. Wen, and N. Trigoni, “Deepvo: Towards end-to-end visual odometry with deep recurrent convolutional neural networks,” in 2017 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2017, pp. 2043–2050.</li><li id="ref-332" data-num="332">[332]  C. Gur ̆au, C. H. Tong, and I. Posner, “Fit for purpose? predicting perception performance based on past experience,” in International Symposium on Experimental Robotics. Springer, 2016, pp. 454–464.</li><li id="ref-333" data-num="333">[333]  S. Daftry, S. Zeng, J. A. Bagnell, and M. Hebert, “Introspective perception: Learning to predict failures in vision systems,” in 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2016, pp. 1743–1750.</li><li id="ref-334" data-num="334">[334]  M. Netzband, W. L. Stefanov, and C. Redman, Applied remote sensing for urban planning, governance and sustainability. Springer Science &amp; Business Media, 2007.</li><li id="ref-335" data-num="335">[335]  C. Giardino, M. Bresciani, P. Villa, and A. Martinelli, “Application of remote sensing in water resource management: the case study of lake trasimeno, italy,” Water resources management, vol. 24, no. 14, pp. 3885–3899, 2010.</li><li id="ref-336" data-num="336">[336]  C. J. Van Westen, “Remote sensing for natural disaster management,” International archives of photogrammetry and remote sensing, vol. 33, no. B7/4; PART 7, pp. 1609–1617, 2000.</li><li id="ref-337" data-num="337">[337]  X. X. Zhu, D. Tuia, L. Mou, G.-S. x_ia, L. Zhang, F. Xu, and F. Fraundorfer, “Deep learning in remote sensing: A comprehensive review and list of resources,” IEEE Geoscience and Remote Sensing Magazine, vol. 5, no. 4, pp. 8–36, 2017.</li><li id="ref-338" data-num="338">[338]  J. Gawlikowski, M. Schmitt, A. Kruspe, and X. X. Zhu, “On the fusion strategies of sentinel-1 and sentinel-2 data for local climate zone classification,” in IEEE International Geoscience and Remote Sensing Symposium, 2020, pp. 2081–2084.</li><li id="ref-339" data-num="339">[339]  ESA, “European space agency (esa) developed earth observation satellites,” 2019. Available: http://www.esa.int:8080/ESA Multimedia/Images/2019/05/ESA-developed Earth observation missions.</li><li id="ref-340" data-num="340">[340]  Z. Nado, N. Band, M. Collier, J. Djolonga, M. W. Dusenberry, S. Farquhar, A. Filos, M. Havasi, R. Jenatton, G. Jerfel et al., “Uncertainty baselines: Benchmarks for uncertainty &amp; robustness in deep learning,” arxiv preprint arXiv:2106.04015, 2021.</li><li id="ref-341" data-num="341">[341]  M. Kull and P. A. Flach, “Reliability maps: a tool to enhance probability estimates and improve classification accuracy,” in Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 2014, pp. 18–33.</li><li id="ref-342" data-num="342">[342]  J. Antor ́an, U. Bhatt, T. Adel, A. Weller, and J. M. Hern ́andez-Lobato, “Getting a clue: A method for explaining uncertainty estimates,” in International Conference on Learning Representations, 2021.</li><li id="ref-343" data-num="343">[343]  M. Reichstein, G. Camps-Valls, B. Stevens, M. Jung, J. Denzler, and N. Carvalhais, “Deep learning and process understanding for data-driven earth system science,” Nature, vol. 566, no. 7743, pp. 195–204, 2019.</li><li id="ref-344" data-num="344">[344]  J. Willard, X. Jia, S. Xu, M. Steinbach, and V. Kumar, “Integrating physics-based modeling with machine learning: A survey,” arxiv preprint arXiv:2003.04919, 2020.</li><li id="ref-345" data-num="345">[345]  E. De B ́ezenac, A. Pajot, and P. Gallinari, “Deep learning for physical processes: Incorporating prior scientific knowledge,” Journal of Statistical Mechanics: Theory and Experiment, vol. 2019, no. 12, p. 124009, 2019.</li></ul>

    <style>
    #refplus, #refplus li{ 
        padding:0;
        margin:0;
        list-style:none;
    }；
    </style>
    <script src="https://unpkg.com/@popperjs/core@2"></script>
    <script src="https://unpkg.com/tippy.js@6"></script>
    <script>
    document.querySelectorAll(".refplus-num").forEach((ref) => {
        let refid = ref.firstChild.href.replace(location.origin+location.pathname,'');
        let refel = document.querySelector(refid);
        let refnum = refel.dataset.num;
        let ref_content = refel.innerText.replace(`[${refnum}]`,'');
        tippy(ref, {
            content: ref_content,
        });
    });
    </script>
    </article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://xishansnow.github.io">西山晴雪</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://xishansnow.github.io/posts/926f8964.html">http://xishansnow.github.io/posts/926f8964.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://xishansnow.github.io" target="_blank">西山晴雪的知识笔记</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">贝叶斯神经网络</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E9%9B%86%E6%88%90/">深度集成</a><a class="post-meta__tags" href="/tags/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">不确定性神经网络</a><a class="post-meta__tags" href="/tags/%E5%8D%95%E4%B8%80%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">单一确定性神经网络</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/">数据增强</a><a class="post-meta__tags" href="/tags/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E6%A0%A1%E5%87%86/">不确定性校准</a><a class="post-meta__tags" href="/tags/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E8%AF%84%E6%B5%8B/">不确定性评测</a><a class="post-meta__tags" href="/tags/%E6%A6%82%E8%A7%88/">概览</a></div><div class="post_share"><div class="social-share" data-image="/img/coffe_13.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/bb4aaeec.html"><img class="prev-cover" src="/img/book_03.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">可扩展性--分布式机器学习系统</div></div></a></div><div class="next-post pull-right"><a href="/posts/15a1fc08.html"><img class="next-cover" src="/img/book_03.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">常见概率分布</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/32c5c644.html" title="🔥  神经网络泛化的贝叶斯概率视角"><img class="cover" src="/img/book_09.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-10-03</div><div class="title">🔥  神经网络泛化的贝叶斯概率视角</div></div></a></div><div><a href="/posts/813881a.html" title="深度集成方法(Deep Ensembles)"><img class="cover" src="/img/book_12.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-31</div><div class="title">深度集成方法(Deep Ensembles)</div></div></a></div><div><a href="/posts/2965212d.html" title="从损失景观视角看深度集成"><img class="cover" src="/img/003.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-01</div><div class="title">从损失景观视角看深度集成</div></div></a></div><div><a href="/posts/6ee49852.html" title="批量集成方法（Batch Ensemble）"><img class="cover" src="/img/book_14.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-02</div><div class="title">批量集成方法（Batch Ensemble）</div></div></a></div><div><a href="/posts/8701752.html" title="深度密度网络"><img class="cover" src="/img/book_03.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-02</div><div class="title">深度密度网络</div></div></a></div><div><a href="/posts/f2a62e9c.html" title="谱归一化高斯过程 （SNGP ）"><img class="cover" src="/img/book_05.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-02</div><div class="title">谱归一化高斯过程 （SNGP ）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A6%82%E8%BF%B0"><span class="toc-text">1 概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">2 深度神经网络的不确定性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E9%A2%84%E6%B5%8B%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%9D%A5%E6%BA%90"><span class="toc-text">2.1 预测不确定性的来源</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E7%8E%AF%E8%8A%82"><span class="toc-text">2.1.1 数据采集环节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E7%8E%AF%E8%8A%82"><span class="toc-text">2.1.2 模型构建环节</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-3-%E9%A2%84%E6%B5%8B%E6%8E%A8%E6%96%AD%E7%8E%AF%E8%8A%82"><span class="toc-text">2.1.3 预测推断环节</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E9%A2%84%E6%B5%8B%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%9E%84%E6%88%90"><span class="toc-text">2.2 预测不确定性的构成</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-%E6%95%B0%E6%8D%AE%E4%B8%8E%E6%A8%A1%E5%9E%8B%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">2.2.1 数据与模型不确定性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-%E5%88%86%E5%B8%83%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">2.2.2 分布不确定性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E6%8C%89%E7%85%A7%E8%BE%93%E5%85%A5%E5%88%86%E5%B8%83%E5%9F%9F%E5%81%9A%E5%88%86%E7%B1%BB"><span class="toc-text">2.3 按照输入分布域做分类</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-1-%E5%9F%9F%E5%86%85%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">2.3.1 域内不确定性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-2-%E5%9F%9F%E5%81%8F%E7%A7%BB%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">2.3.2 域偏移不确定性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-3-%E5%9F%9F%E5%A4%96%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">2.3.3 域外不确定性</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E9%A2%84%E6%B5%8B%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95"><span class="toc-text">3 预测不确定性的估计方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%8D%95%E4%B8%80%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%96%B9%E6%B3%95"><span class="toc-text">3.1 单一确定性神经网络方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-%E5%86%85%E8%95%B4%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E4%BC%B0%E8%AE%A1%E6%B3%95"><span class="toc-text">3.1.1 内蕴不确定性估计法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-%E5%A4%96%E6%8E%A5%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E4%BC%B0%E8%AE%A1%E6%B3%95"><span class="toc-text">3.1.2 外接不确定性估计法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-3-%E5%B0%8F%E7%BB%93"><span class="toc-text">3.1.3 小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%96%B9%E6%B3%95"><span class="toc-text">3.2 贝叶斯神经网络方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD"><span class="toc-text">3.2.1 变分推断</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95"><span class="toc-text">3.2.2 采样方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-3-%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E8%BF%91%E4%BC%BC"><span class="toc-text">3.2.3 拉普拉斯近似</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-4-%E5%B0%8F%E7%BB%93"><span class="toc-text">3.2.4 小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%B7%B1%E5%BA%A6%E9%9B%86%E6%88%90%E7%BD%91%E7%BB%9C"><span class="toc-text">3.3 深度集成网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-1-%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-text">3.3.1 基本原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-2-%E5%8D%95%E5%B3%B0%E5%92%8C%E5%A4%9A%E5%B3%B0%E5%88%86%E5%B8%83"><span class="toc-text">3.3.2 单峰和多峰分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-3-%E6%88%90%E5%91%98%E7%9A%84%E5%A4%9A%E6%A0%B7%E6%80%A7%E9%97%AE%E9%A2%98"><span class="toc-text">3.3.3 成员的多样性问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-4-%E9%9B%86%E6%88%90%E4%B8%8E%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E4%BC%B0%E8%AE%A1%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-text">3.3.4 集成与不确定性估计的关系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-5-%E5%89%AA%E6%9E%9D%E4%B8%8E%E8%92%B8%E9%A6%8F"><span class="toc-text">3.3.5 剪枝与蒸馏</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-6-%E5%B0%8F%E7%BB%93"><span class="toc-text">3.3.6 小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E6%B5%8B%E8%AF%95%E6%97%B6%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95"><span class="toc-text">3.4 测试时增强方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-text">3.5 方法对比与应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%B5%8B%E5%BA%A6"><span class="toc-text">4 不确定性的测度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E8%AF%84%E4%BC%B0%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">4.1 评估分类任务中的不确定性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-1-%E6%95%B0%E6%8D%AE%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%B5%8B%E5%BA%A6%E6%8C%87%E6%A0%87"><span class="toc-text">4.1.1 数据不确定性的测度指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-%E6%A8%A1%E5%9E%8B%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%B5%8B%E5%BA%A6%E6%8C%87%E6%A0%87"><span class="toc-text">4.1.2 模型不确定性的测度指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-%E5%88%86%E5%B8%83%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E5%BA%A6%E9%87%8F"><span class="toc-text">4.1.3 分布不确定性的度量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-4-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95%E7%9A%84%E6%80%BB%E4%BD%93%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BC%B0"><span class="toc-text">4.1.4 不确定估计方法的总体质量评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E8%AF%84%E4%BC%B0%E5%9B%9E%E5%BD%92%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">4.2 评估回归任务中的不确定性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-%E6%95%B0%E6%8D%AE%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%B5%8B%E5%BA%A6%E6%8C%87%E6%A0%87"><span class="toc-text">4.2.1 数据不确定性的测度指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-%E6%A8%A1%E5%9E%8B%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%B5%8B%E5%BA%A6%E6%8C%87%E6%A0%87"><span class="toc-text">4.2.2 模型不确定性的测度指标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E8%AF%84%E4%BC%B0%E5%88%86%E5%89%B2%E4%BB%BB%E5%8A%A1%E4%B8%AD%E7%9A%84%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7"><span class="toc-text">4.3 评估分割任务中的不确定性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%AF%B9%E9%A2%84%E6%B5%8B%E7%BD%AE%E4%BF%A1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%A0%A1%E5%87%86"><span class="toc-text">5 对预测置信度进行校准</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E6%A0%A1%E5%87%86%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-text">5.1 校准的定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%A0%A1%E5%87%86%E6%96%B9%E6%B3%95"><span class="toc-text">5.2 校准方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-1-%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95"><span class="toc-text">5.2.1 正则化方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-2-%E5%90%8E%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95"><span class="toc-text">5.2.2 后处理方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-3-%E4%BD%BF%E7%94%A8%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E4%BC%B0%E8%AE%A1%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E6%A0%A1%E5%87%86"><span class="toc-text">5.2.3 使用不确定性估计方法进行校准</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E6%A0%A1%E5%87%86%E6%95%88%E6%9E%9C%E7%9A%84%E8%AF%84%E4%BC%B0"><span class="toc-text">5.3 校准效果的评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E5%9F%BA%E7%BA%BF"><span class="toc-text">6 数据集与基线</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E4%B8%BB%E8%A6%81%E4%BB%BB%E5%8A%A1"><span class="toc-text">6.1 主要任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E4%B8%BB%E8%A6%81%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">6.2 主要数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-%E4%B8%BB%E8%A6%81%E5%9F%BA%E7%BA%BF"><span class="toc-text">6.3 主要基线</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E4%BC%B0%E8%AE%A1%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-text">7 不确定性估计的应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E4%B8%BB%E5%8A%A8%E5%AD%A6%E4%B9%A0"><span class="toc-text">7.1 主动学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-text">7.2 强化学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8"><span class="toc-text">7.3 不确定性的实际应用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-1-%E5%8C%BB%E5%AD%A6%E5%88%86%E6%9E%90"><span class="toc-text">7.3.1 医学分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-2-%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-text">7.3.2 机器人</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-3-%E5%AF%B9%E5%9C%B0%E8%A7%82%E6%B5%8B"><span class="toc-text">7.3.3 对地观测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E7%BB%93%E8%AE%BA%E4%B8%8E%E5%B1%95%E6%9C%9B"><span class="toc-text">8 结论与展望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-%E7%BB%93%E8%AE%BA"><span class="toc-text">8.1 结论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-%E5%B1%95%E6%9C%9B"><span class="toc-text">8.2 展望</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-text">参考文献</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By 西山晴雪</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? '' : ''

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script></div></body></html>